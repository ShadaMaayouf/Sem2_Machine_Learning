{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd5d136-be08-4dfc-8ad9-5a5fa1c85e54",
   "metadata": {},
   "source": [
    "# Cheatsheet\n",
    ">## <ins>Table of contents</ins> <a name=\"up\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    ">* [**1. Allgemein**](#1.)\n",
    ">* [**K2. Überwachtes Lernen**](#K2)\n",
    "    * [**2.1. Lineare Regression**](#2.1.)\n",
    "    * [**2.2. logistische Regression**](#2.2.)\n",
    "    * [**2.3. SVM**](#2.3.)\n",
    "    * [**2.4. Nächste Nachbaren klassifikation**](#2.4.)\n",
    "    * [**2.5. Bayes klassifikator**](#2.5.)\n",
    "    * [**2.6. Entscheidungsbäume**](#2.6.)\n",
    "\n",
    ">* [**K3. Motivation und Grundlagen**](#K3)\n",
    ">* [**K4. Motivation und Grundlagen**](#K4)\n",
    ">* [**K5. Motivation und Grundlagen**](#K5)\n",
    "    * [**5.1. RNN**](#5.1.)\n",
    "       * [**5.1. RNN**](#5.1.)\n",
    "    * [**5.3. RNN**](#5.3.)\n",
    "       * [**spaltenweise Konkatenation zweier Matrizen**](#5.3.1.)\n",
    "       * [**One-Hot-Codierung**](#5.3.2.)\n",
    "       * [**Berechnungsgraphen**](#5.3.3.)\n",
    "\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bea975-c801-440d-bc50-cab55291db0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1. Lineare Regression <a name=2.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137527c9-be80-4b3e-971c-49a4da408a7b",
   "metadata": {},
   "source": [
    "- simpleste Form des machinellen Lernens.\n",
    "- Wird als statistische MEthdoe betrachtet.\n",
    "\n",
    "**Problem der linearen Regression:** die optimale Anpassung einer Gerade an einer gegebene Menge von Punkten. \n",
    "\n",
    "Hier besonders $\\longrightarrow$ Anwendung der linearen Regression ür die Funktionsapproximation, d.h. der Vorhersage des Funktionswerts einer Instanz gegeben gewisser Merkmalsausprägungen der Instanzen.\n",
    "\n",
    "<ins>die Aufgabe des zu erlernenden Modells</ins> ist die Vorhersage des Funktionswertes **$y \\in \\mathbb{R}$** zu einem beliebigen Datenpunkt $x \\in \\mathbb{R}^n$. Wir nehmen dazu an, dass die zu suchende Funktion ähnlich zu der Funktion ist, die einen gegebenen Trainingsdatensatz **D** generiert hat. \n",
    "\n",
    "Bei der linearen Regression nehmen wir zusa¨tzlich an, dass der Zusammenhang zwischen x und y (die Zielvariable) **linear** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb587b6c-cf99-4be4-92c9-e354d43aa898",
   "metadata": {},
   "source": [
    "- Ein Datenpunkt $x = (x_1, ...., x_n)^T$ ist ein Punkt $x \\in \\mathbb{R}^n$, wobei n ist die Dimension, $i = 1, ..., n$ ist ein Merkmal/feature und $x_i$ ist die Ausprägung des Merkmals i.\n",
    "- Ein Tupel $(x,y)$ ist ein Beispiel und die Beispielsmenge $D = \\{ (x^1,y^1), .... , (x^m,y^m)\\}$ ist ine Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de1d40-15b6-4dd9-844b-713f2a753b36",
   "metadata": {},
   "source": [
    "Ein lineares Modell $h_{\\theta}$ ist definiert als: $$h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n$$\n",
    "\n",
    "wobei $\\theta = \\theta_0, ..., \\theta_n$ sind die Parameter des Modells $h_{\\theta}$.\n",
    "\n",
    "D.h. wir müssen nun konkrete Werte für die Parameter $\\theta$ zu finden, so dass $h_{\\theta}(x^i) \\approx y^i$. Das kann als ein **Optimierungsproblem** modelliert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d0c3c-1720-4fcd-a090-64992b391ad2",
   "metadata": {},
   "source": [
    "Um das Optimierungsproblem modellieren zu können wählt man zunächst ein geeignetes **Abstandsmaß** (oder Fehlermaß \n",
    "oder Kostenfunktion), das bewertet, wie nah eine Funktion an die Beispiele D angepasst is $\\longrightarrow$  der** quadratische Fehle**.\n",
    "\n",
    "> **Definition 3.** Der quadratische Fehler $L(D,f)$\n",
    ">\n",
    "> Sei D ein Datensatz und $ f : \\mathbb{R}^n → \\mathbb{R} $ eine beliebige Funktion. \n",
    "Der quadratische Fehler L von f bzgl. D ist definiert durch\n",
    "$$L(D, f) = \\sum_{i=1}^m (f(x^{(i)})−y^{(i)})^2$$\n",
    "Ist $f = h_θ$ eine lineare Funktion $$ hθ $$ mit Parametern θ, so ist dies äquivalent zu\n",
    "$$L(D, f) = \\lVert X_D θ - y_D \\rVert ^2$$\n",
    "wobei $\\lVert . \\rVert$ die Euklidische Norm ist.r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fafcdc-d5b4-46c8-bf3d-574306087712",
   "metadata": {},
   "source": [
    "- Damit $h_θ$ die Beispiele in $D$ bestmöglich approximiert, suchen wir Parameter $θ$, die den quadratischen Fehler $L$ bzgl. $D$ **minimieren**, d h., wir suchen eine Lösung für das folgende Optimierungsproblem:\n",
    "$$min_θ L(D,θ) = min_θ \\lVert X_D θ - y_D \\rVert ^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eff6da-6eb0-49e5-8f17-89cb141b5c22",
   "metadata": {},
   "source": [
    "- Für lineare Regression ist das obige Optimierungsproblem stets **eindeutig lösbar**, d.h., <ins>ein lokales Minimum ist stets das globale Minimum</ins>.\n",
    "\n",
    "- Eine geeignite Methode ist **Gradient Descent**, besonders bei <ins>großen Trainingsdatensätzen</ins> oder <ins>viele MErkmale</ins>.\n",
    "\n",
    "- Gerade bei **großen** Werten für m und n ist die Verwendung von **numerischen Optimierungsmethoden** (wie Gradient Descent) zu bevorzugen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0ea8b-c068-4630-9353-34c9bbbcae51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "Die Evaluation ist die Analyse und Feststellung, wie gut eine bestimmte Methode ein spezifisches Problem löst --> und somit die beste Methode wählen.\n",
    "\n",
    "**Schritte der Evaluation:**\n",
    "→ Aufteilung der Daten in:\n",
    "- einen **Trainingsdatensatz**, der verwendet wird, um das Modell zu trainieren.\n",
    "- und einen **Testdatensatz** der dazu dient, die Leistung des Modells auf neuen, zuvor ungesehenen Daten zu bewerten. Dies gibt uns eine Vorstellung davon, wie gut das gelernte Modell auf zuvor ungesehenen Daten generalisiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349e7f2-3924-4643-b545-d88ea21f7906",
   "metadata": {},
   "source": [
    "Den **Evaluationsmaß**, den wir hier verwenden ist das **Bestimmtheitsmaß**, auch bekannt als **R<sup>2</sup>-Wert**\n",
    "- Es ist eine normalisierte Variante des quadratischen Fehlers.\n",
    "- gibt an, welcher Anteil der Varianz in den abhängigen Variablen durch das Modell erklärt wird.\n",
    "\n",
    "Sei $D = {(x^1, y^1),...,(x^m, y^m)}$ ein Datensatz und $f : \\mathbb{R}^n → \\mathbb{R}$ eine beliebige Funktion. Das **Bestimmtheitsmaß R<sup>2</sup>-Wert** von f bzgl. D ist definiert durch\n",
    "$$ R^2(D, f) = (1− \\frac{L(D,f)}{\\sum_{i=1}^m (y^{(i)}− \\tilde{y})^2}) = (1− \\frac{\\sum_{i=1}^m (f(x^{(i)})− y^{(i)})^2}{\\sum_{i=1}^m (y^{(i)}− \\tilde{y})^2})$$\n",
    "\n",
    "wobei der Mittelwert von $y^i$ ist:\n",
    "$$ \\tilde{y} = \\frac{1}{m} \\sum_{i=1}^m y^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc834061-a323-43e1-8c87-821f505be943",
   "metadata": {},
   "source": [
    "- Der Wert $R^2(D,f)$ kann maximal 1 betragen.\n",
    "- Je kleiner der Wert $R^2(D,f)$, desto schlechter die Vorhersagequalität von f bbeü¨glich  ist.D\n",
    "- **$R^2$-Wert = 1** $\\longrightarrow$  das Modell erklärt die Daten perfekt, d.h. $f(x^i) = y^i$ \n",
    "- **$R^2$-Wert = 0** $\\longrightarrow$ das Modell erklärt die Daten nicht besser als ein einfaches Modell, das nur den Durchschnitt der Daten verwendet D.h. ein naives Modell $f_{naive}$, dass stets den Mittelwert $\\tilde{y}$ vorhersagen würde, hätten wir $R^2(D,f_{naive}) = 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575e86c-05a1-4f1b-9147-6602bb1e4714",
   "metadata": {},
   "source": [
    "- Dieses Problem der variierenden Abstände zwischen Bestimmtheit der Trainings- und Testdaten zu adressieren, benutzt man oft die sogenannte **Kreuzvalidierung (engl. cross validation)**.\n",
    "\n",
    "- Die grundlegende Idee der Kreuzvalidierung besteht darin, die ursprünglichen Daten in ungefähr gleichgroße zwei Teile zu teilen: einen Trainingsdatensatz und einen Validierungsdatensatz. Das Modell wird auf dem Trainingsdatensatz trainiert und dann auf dem Validierungsdatensatz getestet. Dieser Prozess wird mehrmals wiederholt, wobei verschiedene Teile der Daten als Trainings- und Validierungsdatensatz verwendet werden. Am Ende wird der Durchschnitt der Modellleistung über alle Durchläufe berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff99e3f-52f7-427d-b33e-42ff6a89fc7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Nichtlineare Modelle\n",
    "- Lineare Regression ist durch die Linearitätsannahme in ihrer Anwendbarkeit eingeschränkt.\n",
    "\n",
    "- Die Einbeziehung nichtlinearer Zusammenhänge zwischen Merkmalen und der Zielvariablen kann bei der linearen\r\n",
    "Regression realisiert werden, indem in einem Vorbereitungsschritt die Beispiele um zuä¨tzliche (nichtlineare) Merk\u0002male erännzt werden, die aus den schon existierenden Merkmalen berechnet werde $longrightarrow$ Polynomiale Regression.\n",
    "\n",
    "Polynomiale Regression kann verwendet werden, um komplexere, nichtlineare Beziehungen zwischen Variablen zu modellieren, die nicht durch lineare Regression erfasst werden können.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484070b-7484-4f1f-85e6-a345e3b05211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Über und Unteranpassung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5920bad-cb49-47c5-85db-d13aff0611c4",
   "metadata": {},
   "source": [
    "**Warum nimmt man statt eines linearen Modells nicht direkt ein maximal komplexes Modell , das damit auch beliebig genau an den Trainingsdatensatz angepasst werden kann?**\n",
    "\n",
    "Es gibt mehrere Gründe:\n",
    "* Zuna¨chst ergeben sich dadurch **ressourcenspezifische Probleme**, da das Lernen unter Umständen signifikant mehr Zeit benötigt.\n",
    "* **Überanpassung** (engl. overfitting), tritt auf, wenn ein Modell die Trainingsdaten zu gut lernt und dabei auch das Rauschen in den Daten erfasst. Dies führt dazu, dass das Modell auf den Trainingsdaten sehr gut, aber auf den Testdaten schlecht abschneidet. d. h., das gelernte Modell ist aufgrund seiner Komplexität so stark an die Trainingsdaten angepasst, dass es nicht mehr gut auf ungesehene Daten generalisiert.\n",
    "* **Unteranpassung** (engl. Underfitting) tritt auf, wenn ein Modell nicht genügend Muster aus den Daten lernt. Dies führt dazu, dass das Modell sowohl auf den Trainingsdaten als auch auf den Testdaten schlecht abschneidet. In anderen Worten: ein zu einfaches, nicht-ausdrucksstarkes Modell kann sowohl die Trainings- als auch die Testdaten nicht ausreichend gut modellieren, was zu schlechten Vorhersagen führt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca88f0-2eee-4a2d-8b04-abd3947acb64",
   "metadata": {},
   "source": [
    "#### Die Verzerrung-Varianz-Dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbffaec4-c2d2-4c6f-96c5-84dc32e1aac2",
   "metadata": {},
   "source": [
    "- **Verzerrungsfehler (Bias Error)**: Dieser Fehler entsteht, wenn ein Modell zu einfache Annahmen über die Datenstruktur trifft. Ein Modell mit hohem Bias neigt dazu, die Daten zu \"unterschätzen\", was bedeutet, dass es die Komplexität der Daten nicht vollständig erfasst. Dies führt zu einer schlechten Leistung sowohl auf den Trainings- als auch auf den Testdaten, ein Phänomen, das als \"Unteranpassung\" (Underfitting) bezeichnet wird.\n",
    "\n",
    "- **Varianzfehler (Variance Error)**: Dieser Fehler entsteht, wenn ein Modell zu komplexe Annahmen über die Datenstruktur trifft. Ein Modell mit hoher Varianz \"überinterpretiert\" die Daten, indem es auch das Rauschen oder die zufälligen Schwankungen in den Trainingsdaten lernt. Dies führt zu einer guten Leistung auf den Trainingsdaten, aber zu einer schlechten Leistung auf den Testdaten, ein Phänomen, das als \"Überanpassung\" (Overfitting) bezeichnet wird.\n",
    "\n",
    "Das Ziel ist es, ein Gleichgewicht zwischen **Verzerrung** und **Varianz** zu finden, um ein Modell zu erhalten, das weder unterangepasst noch überangepasst ist. Es hilft, die Verläufe der Kostenfunktionswerte (oder des Bestimmtheitsmaßes) bei Trainings- und Testdaten mit steigender Modellkomplexität zu betrachten.\n",
    "\n",
    "\n",
    "**Bei Trainingsdaten:**\n",
    "- nimmt die Bestimmtheit eines Modells mit steigender Komplexität auf den Trainingsdaten zu.\n",
    "- **Das bedeutet -->** je ausdrucksstärker das Modell ist (d.h., je mehr es in der Lage ist, komplexe Muster in den Daten zu erfassen), desto besser wird es an die Trainingsdaten angepasst.\n",
    "\n",
    "**Bei Testdaten** ist der Verlauf etwas komplexer:\n",
    "- Weil ein komplexeres Modell in der Lage ist, die zugrunde liegenden Muster in den Daten besser zu erfassen, nimmt die Bestimmtheit zunächst zu: solange das Modell unteranpasst ist, können weder Trainings- noch Testdaten gut modelliert werden, aber je näher man an das ”korrekte“ Modell kommt, desto besser werden insbesondere auch die Vorhersagen auf den Testdaten.\n",
    "- Steigt die Modellkomplexität aber weiter, kann das Modell beginnen, das Rauschen in den Trainingsdaten zu lernen, so wird das Modell überangepasst und die Vorhersagequalität auf den Testdaten sinkt wieder.\n",
    "\n",
    "\n",
    "#### Aber was ist den die optimale Modellkomplexität?\n",
    "\n",
    "Im Grunde liegt die optimale Modellkomplexität <ins>am Scheitelpunkt der Kurve der Testdaten.</ins> An diesem Punkt ist die Bestimmtheit (ein Maß für die Anpassungsgüte des Modells) sowohl bei den Trainings- als auch bei den Testdaten relativ hoch, was darauf hindeutet, dass das Modell gut auf neue, unbekannte Daten generalisiert.\n",
    "\n",
    ">Modelle, deren Komplexität links von diesem Punkt liegt, sind unterangepasst.\n",
    "\n",
    ">Modelle, die rechts von diesem Punkt liegen, überangepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ff47b-5991-49be-9e9f-a5fe90bab2a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Regularisierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdba2a6-93c0-4543-bcc9-c2a0ffe0d5a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b62653a-36e2-4ef2-8bf7-930e73397f6f",
   "metadata": {},
   "source": [
    "Regularisierung ist eine Technik, die verwendet wird, um das Verzerrung-Varianz-Dilemma zu lösen bzw. um Überanpassung zu verhindern, indem eine Strafterm zur Verlustfunktion hinzugefügt wird, um:\n",
    "- die Komplexität des Modells zu begrenzen\n",
    "- und somit Overfitting zu verhindern\n",
    "\n",
    "$\\longrightarrow$ das Modell optimieren.\n",
    "\n",
    "Es gibt verschiedene Arten von Regularisierungstechniken wie z.B.:\n",
    "- L1-Regularisierung (Lasso),\n",
    "- L2-Regularisierung (Ridge)\n",
    "- und Elastic Net, die eine Kombination aus L1 und L2 ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0d1bc-352a-4853-81ae-57ffe0dca82f",
   "metadata": {},
   "source": [
    "Die mit *R* und *λ* **regularisierte Kostenfunktion** ist $$L_{R,λ} (D, f) = L(D, f) + λR(f)$$\n",
    "\n",
    "Es besteht aus zwei Teilen:\n",
    "- **dem ursprünglichen Verlust L(D,f)**: misst, wie gut das Modell die Trainingsdaten anpasst.\n",
    "- **dem Regularisierungsterm λR(f)**: verhindert, dass das Modell zu komplex wird und overfittet.\n",
    "\n",
    "Die Funktion **R(f)** ist der **Regularisierer**, misst die Komplexität des Modells f, dabei bestimmt der **Regularisierungsparameter λ** das Ausmaß der Regularisierung.\n",
    "\n",
    "λ muss > 0 sein.\n",
    "\n",
    "Ein höherer Wert von **Der Regularisierungsparameter λ** bedeutet mehr Regularisierung und ein einfacheres Modell, während ein niedrigerer Wert von **λ** weniger Regularisierung und ein komplexeres Modell bedeutet. \n",
    "\n",
    "#### Ridge-Regression\n",
    "Die lineare Regression mit Kostenfunktion **L<sub>T</sub>** nennt man allgemein auch **Ridge-Regression** (engl. ridge regression). \n",
    "Die regularisierte Kostenfunktion\n",
    "$$L_T(D,\\theta) = \\lVert X D\\theta - y D\\rVert ^2 + \\lambda \\sum_{i=1}^{n} \\theta_i^2 $$\n",
    "besteht aus der Kostenfunktion $$ L(D,θ)=∥XDθ−yD∥^2 $$ und dem **Tikhonov-Regularisierer** $$ R_T​(θ_1​, … ,θ_n​) = \\sum_{i=1}^{n} \\theta_i^2 $$ der **Tikhonov-Regularisierer** ist eine Technik zur Vermeidung von Überanpassung, indem es eine Strafe für große Werte der Parameter **θ<sub>i</sub>** eingeführt wird.\n",
    "\n",
    "Der Parameter **λ** bestimmt, wie stark die Regularisierung ist. Ein größerer Wert von **λ** führt zu stärkerer Regularisierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb8722-6f82-47a1-a923-a72d1366e288",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## 5.3. RNN <a name=5.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef20847-f681-44dc-b13e-90ebbe01e9db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3.1. spaltenweise Konkatenation zweier Matrizen <a name=5.3.1.><a>\n",
    "\n",
    "Sei $A \\in \\mathbb{R}^{n \\times m}$ und $B \\in \\mathbb{R}^{n \\times m'}$ zwei Matrizen mit gleicher Anzahl an Zeilen, so ist $A \\circ B \\in \\mathbb{R}^{n \\times (m + m')}$ die entsprechende Konkatenation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917a1c0-3a58-4129-ab00-d9cde58459eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen Sie die Matrizen A und B mit Dummy-Zahlen\n",
    "A = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "\n",
    "B = np.array([[10, 11, 12], \n",
    "              [13, 14, 15], \n",
    "              [16, 17, 18]])\n",
    "\n",
    "# Führen Sie die Konkatenation durch\n",
    "AB = np.concatenate((A, B), axis=1)\n",
    "print(AB)\n",
    "\n",
    "# Erstellen Sie die Vektoren v und w mit Dummy-Zahlen\n",
    "v = np.array([1, 2, 3])  # v = (v1, ..., vm)^T\n",
    "w = np.array([4, 5, 6])  # w = (w1, ..., wm')^T\n",
    "\n",
    "# Führen Sie die Konkatenation durch\n",
    "vw = np.concatenate((v, w))\n",
    "print(\"v ◦ w =\", vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe44ddc-6fc8-47a8-9048-bdad3c010d90",
   "metadata": {},
   "source": [
    "Vergewissern Sie sich, dass für die obigen Definition gilt $(A \\circ B)(v \\circ w) = Av + Bw$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bf573-d301-4809-866e-9711d253597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = np.dot(AB,vw)\n",
    "result2 = np.dot(A,v) + np.dot(B,w)\n",
    "print(result1 == result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51772525-0900-4237-bb78-faa53dd26d72",
   "metadata": {},
   "source": [
    "### 5.3.2. One-Hot-Codierung <a name=5.3.2.><a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6195b0-7376-4847-8bd3-254cc55853f2",
   "metadata": {},
   "source": [
    "Sei ein Alphabet gegeben durch\n",
    "\n",
    "Σ={a,e,s,t}\n",
    "\n",
    "1. Bestimmen Sie eine One-Hot-Codierung für Σ\n",
    ". (Anwortformat '(1,2,3,4,5,6)', Vektorlänge ist selbst zu wä\n",
    "2. Wie ist demnach das Wort test\n",
    " codiert \n",
    "\n",
    "(Anwortformat '((1,2,3,4,5,6),(7,8,9))')\n",
    "#### Lösung\n",
    "- a: (1, 0, 0, 0)\n",
    "- e: (0, 1, 0, 0)\n",
    "- s: (0, 0, 1, 0)\n",
    "- t: (0, 0, 0, 1)\n",
    "\n",
    "Unter Verwendung der zuvor definierten One-Hot-Codierung für das Alphabet Σ={a,e,s,t}, wird das Wort \"test\" wie folgt codiert:\n",
    "\n",
    "- t: (0, 0, 0, 1)\n",
    "- e: (0, 1, 0, 0)\n",
    "- s: (0, 0, 1, 0)\n",
    "- t: (0, 0, 0, 1)\n",
    "\n",
    "Daher ist die Codierung des Wortes \"test\" in dem von Ihnen angegebenen Antwortformat:\n",
    "\n",
    "((0, 0, 0, 1), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df485f3-6e46-4c86-9452-28009fadc40a",
   "metadata": {},
   "source": [
    "### 5.3.3. Berechnungsgraphen <a name=5.3.3.><a>\n",
    "Im Allgemeinen gilt für eine Eingabe $x = (x^{(1)}, \\ldots, x^{(m)})$:\n",
    "\n",
    "$$\n",
    "h(i) = \\text{act}(Ux^{(i)} + Wh^{(i-1)}) \\quad \\text{(1)}\n",
    "$$ <a name=hi><a>\n",
    "\n",
    "$$\n",
    "o(i) = \\text{act}(Vh^{(i)}) \\quad \\text{(2)}\n",
    "$$<a name=oi><a>\n",
    "\n",
    "für $i = 1, \\ldots, m$. Zu beachten ist, dass diese Netzwerkarchitektur mit Eingaben beliebiger Länge umgehen kann, aber eine fixe Anzahl an Parametern besitzt (in den Matrizen $U$, $V$, $W$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda19404-0a03-4c6c-b27b-c2d4602fbeab",
   "metadata": {},
   "source": [
    "Gegeben sei das abgebildete einfache RNN, wobei\n",
    "\n",
    "$$\\sum = \\{\\text{ist,nichts,niemand}\\} = \\{(1,0,0)^T,(0,1,0)^T,(0,0,1)^T\\}$$\n",
    "$$U= ((0, 0.9, 0.9), (0.5, 0.1, 0), (0.5, 0, 0.1))$$\n",
    "$$W = ((0, 0.45, 0.45), (0.25, 0.05, 0), (0.25, 0, 0.05))$$\n",
    "$$V = ((0.5, 0, 0), (0, 0.5, 0), (0, 0, 0.5))$$\n",
    "$$h_0 = (0,1,1)^T$$\n",
    "\n",
    "und die Aktivierungsfunktion $h^{relu}$ ist. Berechnen Sie die hidden states und die Ausgabe für die Eingabe $x = \\text{'Niemand ist'} = ((0,0,1)^T,(1,0,0)^T)$. \n",
    "(Antwortformat '(1,2,3.456)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04919f-d436-4682-8ff6-3929da2c6e77",
   "metadata": {},
   "source": [
    "### 5.3.4. Long short-term memory-Netzwerke <a name=5.3.4.><a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bce749-40b6-4918-998d-004268a7c519",
   "metadata": {},
   "source": [
    "$$f^{(i)} = h^{logit} (U^f x^{(i)} + W^f h^{(i−1)})$$\n",
    "- Der Vektor $f^{(i)}$ soll steuern, was aus dem Langzeitgedächtnis `s` vergessen werden soll (auch als **forget gate** bezeichnet).\n",
    "\n",
    "$$g^{(i)} = h^{logit} (U^g x^{(i)} + W^g h^{(i−1)})$$\n",
    "$$k^{(i)} = h^{tanh} (U^k x^{(i)} + W^k h^{(i−1)})$$\n",
    "- Der Vektor $g^{(i)}$ (**input gate**) steuert, welche Informationen aus $k^{(i)}$ in das Langzeitgedächtnis aufgenommen werden sollen.\n",
    "$$q^{(i)} = h^{logit} (U^o x^{(i)} + W^o h^{(i−1)})$$\n",
    "- Der Vektor $q^{(i)}$ (**output gate**) steuert, welche Information in die Ausgabe und den nächsten versteckten Zustand $h^{(i)}$ einfließt.\n",
    "\n",
    "- Die Kernidee hinter LSTMs liegt in der Definition des Zellzustands: $$s^{(i)} = f^{(i)} \\cdot s^{(i-1)} + g^{(i)} \\cdot k^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a88a14-5f08-468d-aba0-11eacee21d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
