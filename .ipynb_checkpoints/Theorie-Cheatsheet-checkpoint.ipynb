{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd5d136-be08-4dfc-8ad9-5a5fa1c85e54",
   "metadata": {},
   "source": [
    "# Cheatsheet\n",
    ">## <ins>Table of contents</ins> <a name=\"up\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    ">* [**1. Allgemein**](#1.)\n",
    ">* [**K2. Überwachtes Lernen**](#K2)\n",
    "    * [**2.1. Lineare Regression**](#2.1.)\n",
    "    * [**2.2. logistische Regression**](#2.2.)\n",
    "    * [**2.3. SVM**](#2.3.)\n",
    "    * [**2.4. Nächste Nachbaren klassifikation**](#2.4.)\n",
    "    * [**2.5. Bayes klassifikator**](#2.5.)\n",
    "    * [**2.6. Entscheidungsbäume**](#2.6.)\n",
    "\n",
    ">* [**K3. Motivation und Grundlagen**](#K3)\n",
    ">* [**K4. Motivation und Grundlagen**](#K4)\n",
    ">* [**K5. Motivation und Grundlagen**](#K5)\n",
    "    * [**5.1. RNN**](#5.1.)\n",
    "       * [**5.1. RNN**](#5.1.)\n",
    "    * [**5.3. RNN**](#5.3.)\n",
    "       * [**spaltenweise Konkatenation zweier Matrizen**](#5.3.1.)\n",
    "       * [**One-Hot-Codierung**](#5.3.2.)\n",
    "       * [**Berechnungsgraphen**](#5.3.3.)\n",
    "\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bea975-c801-440d-bc50-cab55291db0a",
   "metadata": {},
   "source": [
    "## 2.1. Lineare Regression <a name=2.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137527c9-be80-4b3e-971c-49a4da408a7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314fc45-a185-450c-8d88-034851addb9f",
   "metadata": {},
   "source": [
    "- simpleste Form des machinellen Lernens.\n",
    "- Wird als statistische MEthdoe betrachtet.\n",
    "\n",
    "**Problem der linearen Regression:** die optimale Anpassung einer Gerade an einer gegebene Menge von Punkten. \n",
    "\n",
    "Hier besonders $\\longrightarrow$ Anwendung der linearen Regression ür die Funktionsapproximation, d.h. der Vorhersage des Funktionswerts einer Instanz gegeben gewisser Merkmalsausprägungen der Instanzen.\n",
    "\n",
    "<ins>die Aufgabe des zu erlernenden Modells</ins> ist die Vorhersage des Funktionswertes **$y \\in \\mathbb{R}$** zu einem beliebigen Datenpunkt $x \\in \\mathbb{R}^n$. Wir nehmen dazu an, dass die zu suchende Funktion ähnlich zu der Funktion ist, die einen gegebenen Trainingsdatensatz **D** generiert hat. \n",
    "\n",
    "Bei der linearen Regression nehmen wir zusa¨tzlich an, dass der Zusammenhang zwischen x und y (die Zielvariable) **linear** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb587b6c-cf99-4be4-92c9-e354d43aa898",
   "metadata": {},
   "source": [
    "- Ein Datenpunkt $x = (x_1, ...., x_n)^T$ ist ein Punkt $x \\in \\mathbb{R}^n$, wobei n ist die Dimension, $i = 1, ..., n$ ist ein Merkmal/feature und $x_i$ ist die Ausprägung des Merkmals i.\n",
    "- Ein Tupel $(x,y)$ ist ein Beispiel und die Beispielsmenge $D = \\{ (x^1,y^1), .... , (x^m,y^m)\\}$ ist ine Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de1d40-15b6-4dd9-844b-713f2a753b36",
   "metadata": {},
   "source": [
    "Ein lineares Modell $h_{\\theta}$ ist definiert als: $$h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n$$\n",
    "\n",
    "wobei $\\theta = \\theta_0, ..., \\theta_n$ sind die Parameter des Modells $h_{\\theta}$.\n",
    "\n",
    "D.h. wir müssen nun konkrete Werte für die Parameter $\\theta$ zu finden, so dass $h_{\\theta}(x^i) \\approx y^i$. Das kann als ein **Optimierungsproblem** modelliert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d0c3c-1720-4fcd-a090-64992b391ad2",
   "metadata": {},
   "source": [
    "Um das Optimierungsproblem modellieren zu können wählt man zunächst ein geeignetes **Abstandsmaß** (oder Fehlermaß \n",
    "oder Kostenfunktion), das bewertet, wie nah eine Funktion an die Beispiele D angepasst is $\\longrightarrow$  der** quadratische Fehle**.\n",
    "\n",
    "> **Definition 3.** Der quadratische Fehler $L(D,f)$\n",
    ">\n",
    "> Sei D ein Datensatz und $ f : \\mathbb{R}^n → \\mathbb{R} $ eine beliebige Funktion. \n",
    "Der quadratische Fehler L von f bzgl. D ist definiert durch\n",
    "$$L(D, f) = \\sum_{i=1}^m (f(x^{(i)})−y^{(i)})^2$$\n",
    "Ist $f = h_θ$ eine lineare Funktion $$ hθ $$ mit Parametern θ, so ist dies äquivalent zu\n",
    "$$L(D, f) = \\lVert X_D θ - y_D \\rVert ^2$$\n",
    "wobei $\\lVert . \\rVert$ die Euklidische Norm ist.r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fafcdc-d5b4-46c8-bf3d-574306087712",
   "metadata": {},
   "source": [
    "- Damit $h_θ$ die Beispiele in $D$ bestmöglich approximiert, suchen wir Parameter $θ$, die den quadratischen Fehler $L$ bzgl. $D$ **minimieren**, d h., wir suchen eine Lösung für das folgende Optimierungsproblem:\n",
    "$$min_θ L(D,θ) = min_θ \\lVert X_D θ - y_D \\rVert ^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eff6da-6eb0-49e5-8f17-89cb141b5c22",
   "metadata": {},
   "source": [
    "- Für lineare Regression ist das obige Optimierungsproblem stets **eindeutig lösbar**, d.h., <ins>ein lokales Minimum ist stets das globale Minimum</ins>.\n",
    "\n",
    "- Eine geeignite Methode ist **Gradient Descent**, besonders bei <ins>großen Trainingsdatensätzen</ins> oder <ins>viele MErkmale</ins>.\n",
    "\n",
    "- Gerade bei **großen** Werten für m und n ist die Verwendung von **numerischen Optimierungsmethoden** (wie Gradient Descent) zu bevorzugen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0ea8b-c068-4630-9353-34c9bbbcae51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c7595-4b24-4d2b-8d82-0a5a3be37bfc",
   "metadata": {},
   "source": [
    "\n",
    "Die Evaluation ist die Analyse und Feststellung, wie gut eine bestimmte Methode ein spezifisches Problem löst --> und somit die beste Methode wählen.\n",
    "\n",
    "**Schritte der Evaluation:**\n",
    "→ Aufteilung der Daten in:\n",
    "- einen **Trainingsdatensatz**, der verwendet wird, um das Modell zu trainieren.\n",
    "- und einen **Testdatensatz** der dazu dient, die Leistung des Modells auf neuen, zuvor ungesehenen Daten zu bewerten. Dies gibt uns eine Vorstellung davon, wie gut das gelernte Modell auf zuvor ungesehenen Daten generalisiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349e7f2-3924-4643-b545-d88ea21f7906",
   "metadata": {},
   "source": [
    "Den **Evaluationsmaß**, den wir hier verwenden ist das **Bestimmtheitsmaß**, auch bekannt als **R<sup>2</sup>-Wert**\n",
    "- Es ist eine normalisierte Variante des quadratischen Fehlers.\n",
    "- gibt an, welcher Anteil der Varianz in den abhängigen Variablen durch das Modell erklärt wird.\n",
    "\n",
    "Sei $D = {(x^1, y^1),...,(x^m, y^m)}$ ein Datensatz und $f : \\mathbb{R}^n → \\mathbb{R}$ eine beliebige Funktion. Das **Bestimmtheitsmaß R<sup>2</sup>-Wert** von f bzgl. D ist definiert durch\n",
    "$$ R^2(D, f) = (1− \\frac{L(D,f)}{\\sum_{i=1}^m (y^{(i)}− \\tilde{y})^2}) = (1− \\frac{\\sum_{i=1}^m (f(x^{(i)})− y^{(i)})^2}{\\sum_{i=1}^m (y^{(i)}− \\tilde{y})^2})$$\n",
    "\n",
    "wobei der Mittelwert von $y^i$ ist:\n",
    "$$ \\tilde{y} = \\frac{1}{m} \\sum_{i=1}^m y^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831f0e4-fbe6-4ef9-a87a-a972aa342b62",
   "metadata": {},
   "source": [
    "- Der Wert $R^2(D,f)$ kann maximal 1 betragen.\n",
    "- Je kleiner der Wert $R^2(D,f)$, desto schlechter die Vorhersagequalität von f bezüglich D ist.\n",
    "- **$R^2$-Wert = 1** $\\longrightarrow$  das Modell erklärt die Daten perfekt, d.h. $f(x^i) = y^i$ \n",
    "- **$R^2$-Wert = 0** $\\longrightarrow$ das Modell erklärt die Daten nicht besser als ein einfaches Modell, das nur den Durchschnitt der Daten verwendet D.h. ein naives Modell $f_{naive}$, dass stets den Mittelwert $\\tilde{y}$ vorhersagen würde, hätten wir $R^2(D,f_{naive}) = 0$.\n",
    "-  bei Überanpassung ist der **$R^2$-Wert** für die **Trainingsdaten** **$R^2(D_{train})$-Wert** relativ hoch, da das Modell die Trainingsdaten sehr genau lernt, während **$R^2(D_{test})$** ist **niedrig** $\\longrightarrow$ Abstand zwischen **$R^2(D_{train})$** und **$R^2(D_{test})$** ist **groß**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575e86c-05a1-4f1b-9147-6602bb1e4714",
   "metadata": {},
   "source": [
    "- Dieses Problem der variierenden Abstände zwischen Bestimmtheit der Trainings- und Testdaten zu adressieren, benutzt man oft die sogenannte **Kreuzvalidierung (engl. cross validation)**.\n",
    "\n",
    "- Die grundlegende Idee der Kreuzvalidierung besteht darin, die ursprünglichen Daten in ungefähr gleichgroße zwei Teile zu teilen: einen Trainingsdatensatz und einen Validierungsdatensatz. Das Modell wird auf dem Trainingsdatensatz trainiert und dann auf dem Validierungsdatensatz getestet. Dieser Prozess wird mehrmals wiederholt, wobei verschiedene Teile der Daten als Trainings- und Validierungsdatensatz verwendet werden. Am Ende wird der Durchschnitt der Modellleistung über alle Durchläufe berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff99e3f-52f7-427d-b33e-42ff6a89fc7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Nichtlineare Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb108d7-23cf-4523-b3fb-37b068aeba49",
   "metadata": {},
   "source": [
    "- Lineare Regression ist durch die Linearitätsannahme in ihrer Anwendbarkeit eingeschränkt.\n",
    "\n",
    "- Die Einbeziehung nichtlinearer Zusammenhänge zwischen Merkmalen und der Zielvariablen kann bei der linearen\n",
    "Regression realisiert werden, indem in einem Vorbereitungsschritt die Beispiele um zuä¨tzliche (nichtlineare) Merk\u0002male erännzt werden, die aus den schon existierenden Merkmalen berechnet werde $\\longrightarrow$ Polynomiale Regression.\n",
    "\n",
    "Polynomiale Regression kann verwendet werden, um komplexere, nichtlineare Beziehungen zwischen Variablen zu modellieren, die nicht durch lineare Regression erfasst werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484070b-7484-4f1f-85e6-a345e3b05211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Über und Unteranpassung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5920bad-cb49-47c5-85db-d13aff0611c4",
   "metadata": {},
   "source": [
    "**Warum nimmt man statt eines linearen Modells nicht direkt ein maximal komplexes Modell , das damit auch beliebig genau an den Trainingsdatensatz angepasst werden kann?**\n",
    "\n",
    "Es gibt mehrere Gründe:\n",
    "* Zuna¨chst ergeben sich dadurch **ressourcenspezifische Probleme**, da das Lernen unter Umständen signifikant mehr Zeit benötigt.\n",
    "* **Überanpassung** (engl. overfitting), tritt auf, wenn ein Modell die Trainingsdaten zu gut lernt und dabei auch das Rauschen in den Daten erfasst. Dies führt dazu, dass das Modell auf den Trainingsdaten sehr gut, aber auf den Testdaten schlecht abschneidet. d. h., das gelernte Modell ist aufgrund seiner Komplexität so stark an die Trainingsdaten angepasst, dass es nicht mehr gut auf ungesehene Daten generalisiert.\n",
    "* **Unteranpassung** (engl. Underfitting) tritt auf, wenn ein Modell nicht genügend Muster aus den Daten lernt. Dies führt dazu, dass das Modell sowohl auf den Trainingsdaten als auch auf den Testdaten schlecht abschneidet. In anderen Worten: ein zu einfaches, nicht-ausdrucksstarkes Modell kann sowohl die Trainings- als auch die Testdaten nicht ausreichend gut modellieren, was zu schlechten Vorhersagen führt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca88f0-2eee-4a2d-8b04-abd3947acb64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Die Verzerrung-Varianz-Dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21dd9b-082a-40e9-8326-efbfc69da234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- **Verzerrungsfehler (Bias Error)**: Dieser Fehler entsteht, wenn ein Modell zu einfache Annahmen über die Datenstruktur trifft. Ein Modell mit hohem Bias neigt dazu, die Daten zu \"unterschätzen\", was bedeutet, dass es die Komplexität der Daten nicht vollständig erfasst. Dies führt zu einer schlechten Leistung sowohl auf den Trainings- als auch auf den Testdaten, ein Phänomen, das als \"Unteranpassung\" (Underfitting) bezeichnet wird.\n",
    "\n",
    "- **Varianzfehler (Variance Error)**: Dieser Fehler entsteht, wenn ein Modell zu komplexe Annahmen über die Datenstruktur trifft. Ein Modell mit hoher Varianz \"überinterpretiert\" die Daten, indem es auch das Rauschen oder die zufälligen Schwankungen in den Trainingsdaten lernt. Dies führt zu einer guten Leistung auf den Trainingsdaten, aber zu einer schlechten Leistung auf den Testdaten, ein Phänomen, das als \"Überanpassung\" (Overfitting) bezeichnet wird.\n",
    "\n",
    "Das Ziel ist es, ein Gleichgewicht zwischen **Verzerrung** und **Varianz** zu finden, um ein Modell zu erhalten, das weder unterangepasst noch überangepasst ist. Es hilft, die Verläufe der Kostenfunktionswerte (oder des Bestimmtheitsmaßes) bei Trainings- und Testdaten mit steigender Modellkomplexität zu betrachten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193c97b-5fb3-4383-9980-31bbb1d91ab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Bei Trainingsdaten:**\n",
    "- nimmt die Bestimmtheit eines Modells mit steigender Komplexität auf den Trainingsdaten zu.\n",
    "- **Das bedeutet -->** je ausdrucksstärker das Modell ist (d.h., je mehr es in der Lage ist, komplexe Muster in den Daten zu erfassen), desto besser wird es an die Trainingsdaten angepasst.\n",
    "\n",
    "**Bei Testdaten** ist der Verlauf etwas komplexer:\n",
    "- Weil ein komplexeres Modell in der Lage ist, die zugrunde liegenden Muster in den Daten besser zu erfassen, nimmt die Bestimmtheit zunächst zu: solange das Modell unteranpasst ist, können weder Trainings- noch Testdaten gut modelliert werden, aber je näher man an das ”korrekte“ Modell kommt, desto besser werden insbesondere auch die Vorhersagen auf den Testdaten.\n",
    "- Steigt die Modellkomplexität aber weiter, kann das Modell beginnen, das Rauschen in den Trainingsdaten zu lernen, so wird das Modell überangepasst und die Vorhersagequalität auf den Testdaten sinkt wieder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0df669-ac82-44f1-b1a0-248d27e03966",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Aber was ist den die optimale Modellkomplexität?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a50c1-812c-42f6-b731-bb8e8cec0449",
   "metadata": {},
   "source": [
    "Im Grunde liegt die optimale Modellkomplexität <ins>am Scheitelpunkt der Kurve der Testdaten.</ins> An diesem Punkt ist die Bestimmtheit (ein Maß für die Anpassungsgüte des Modells) sowohl bei den Trainings- als auch bei den Testdaten relativ hoch, was darauf hindeutet, dass das Modell gut auf neue, unbekannte Daten generalisiert.\n",
    "\n",
    ">Modelle, deren Komplexität links von diesem Punkt liegt, sind unterangepasst.\n",
    "\n",
    ">Modelle, die rechts von diesem Punkt liegen, überangepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ff47b-5991-49be-9e9f-a5fe90bab2a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Regularisierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62653a-36e2-4ef2-8bf7-930e73397f6f",
   "metadata": {},
   "source": [
    "Regularisierung ist eine Technik, die verwendet wird, um das Verzerrung-Varianz-Dilemma zu lösen bzw. um Überanpassung zu verhindern, indem eine Strafterm zur Verlustfunktion hinzugefügt wird, um:\n",
    "- die Komplexität des Modells zu begrenzen\n",
    "- und somit Overfitting zu verhindern\n",
    "\n",
    "$\\longrightarrow$ das Modell optimieren.\n",
    "\n",
    "Es gibt verschiedene Arten von Regularisierungstechniken wie z.B.:\n",
    "- L1-Regularisierung (Lasso),\n",
    "- L2-Regularisierung (Ridge)\n",
    "- und Elastic Net, die eine Kombination aus L1 und L2 ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdba2a6-93c0-4543-bcc9-c2a0ffe0d5a5",
   "metadata": {},
   "source": [
    "Die mit *R* und *λ* **regularisierte Kostenfunktion** ist $$L_{R,λ} (D, f) = L(D, f) + λR(f)$$\n",
    "\n",
    "Es besteht aus zwei Teilen:\n",
    "- **dem ursprünglichen Verlust L(D,f)**: misst, wie gut das Modell die Trainingsdaten anpasst.\n",
    "- **dem Regularisierungsterm λR(f)**: verhindert, dass das Modell zu komplex wird und overfittet.\n",
    "\n",
    "Die Funktion **R(f)** ist der **Regularisierer**, misst die Komplexität des Modells f, dabei bestimmt der **Regularisierungsparameter λ** das Ausmaß der Regularisierung.\n",
    "\n",
    "λ muss > 0 sein.\n",
    "\n",
    "Ein höherer Wert von **Der Regularisierungsparameter λ** bedeutet mehr Regularisierung und ein einfacheres Modell, während ein niedrigerer Wert von **λ** weniger Regularisierung und ein komplexeres Modell bedeutet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0d1bc-352a-4853-81ae-57ffe0dca82f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Ridge-Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750b9a6-f478-4523-b7d3-a101caf84a5b",
   "metadata": {},
   "source": [
    "Die lineare Regression mit Kostenfunktion **L<sub>T</sub>** nennt man allgemein auch **Ridge-Regression** (engl. ridge regression). \n",
    "Die regularisierte Kostenfunktion\n",
    "$$L_T(D,\\theta) = \\lVert X D\\theta - y D\\rVert ^2 + \\lambda \\sum_{i=1}^{n} \\theta_i^2 $$\n",
    "besteht aus der Kostenfunktion $$ L(D,θ)=∥XDθ−yD∥^2 $$ und dem **Tikhonov-Regularisierer** $$ R_T​(θ_1​, … ,θ_n​) = \\sum_{i=1}^{n} \\theta_i^2 $$ der **Tikhonov-Regularisierer** ist eine Technik zur Vermeidung von Überanpassung, indem es eine Strafe für große Werte der Parameter **θ<sub>i</sub>** eingeführt wird.\n",
    "\n",
    "Der Parameter **λ** bestimmt, wie stark die Regularisierung ist. Ein größerer Wert von **λ** führt zu stärkerer Regularisierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82665368-db9f-4ddc-a99b-65428653a9b1",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2. Logistische Regression <a name=2.2.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8436ee-4638-407b-b47f-e5094a1afc98",
   "metadata": {},
   "source": [
    "### Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9c785-8723-45ee-bf8f-9fe6f1f50b0b",
   "metadata": {},
   "source": [
    "- Ist ein Klaasifikationsproblem.\n",
    "- **Prinzip :**\n",
    "    - Ähnlich zur lineare Regression.\n",
    "    - Wir haben ein Trainingsdatensatz mit einer gegebene Menge von Punkten als Eingabe und wir müssen eine Funktion $f$ erlernen, wobei $f(x^i) = y^i$, um die optimale Anpassung einer Gerade an der Punktemenge zu ermöglichen.\n",
    "    - **Aber!** der Wertebereich der Zielvariablen $y^i$ ist <ins>diskret</ins>, üblicherweise sogar <ins>endlich</isn>, und oft auch <isn>binär ($y^i ∈ \\{0,1\\}$)</isn>.\n",
    "- **Ziel der Klassifikation** ist es einen Datenpunkt einer bestimmten Klasse zuzuweisen.\n",
    "\n",
    "-  Die logistischen Regression ist ein Modell zur <ins>binären Klassifikation</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe2191-2d47-4abe-be28-a2aad80d7e86",
   "metadata": {},
   "source": [
    "\r\n",
    "1. **Klassifikationsprobleme**:\r\n",
    "   - Die Ausgabevariable besteht aus diskreten Kategorien oder Klassen.\r\n",
    "   - Die Vorhersage zielt darauf ab, die Klasse oder Kategorie zu bestimmen, zu der eine neue Beobachtung gehört.\r\n",
    "   - Die Klassen haben in der Regel keine (eindeutige) Ordnung. Zum Beispiel können Klassen wie \"Auto\", \"Flugzeug\" und \"Schiff\" sein, die keine natürliche Reihenfolge haben.\r\n",
    "   - Ein klassisches Beispiel ist die binäre Klassifikation, bei der die Beobachtungen in zwei Kategorien unterteilt werden, wie z.B. \"positiv\" und \"negativ\".\r\n",
    "\r\n",
    "2. **Regressionsprobleme**:\r\n",
    "   - Die Ausgabevariable ist kontinuierlich und nimmt einen beliebigen Wert innerhalb eines bestimmten Bereichs an.\r\n",
    "   - Die Vorhersage zielt darauf ab, den numerischen Wert der Ausgabevariable für eine neue Beobachtung vorherzusagen.\r\n",
    "   - Die Werte haben eine natürliche Ordnung. Zum Beispiel könnten sie reale Zahlen wie Größen, Gewichte, Preise usw. sein.\r\n",
    "   - Ein klassisches Beispiel ist die Vorhersage des Preises eines Hauses basierend auf seinen Eigenschaften wie GrößeOrdnung haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835a986-bc2e-4f43-af3f-716254947033",
   "metadata": {},
   "source": [
    "Es gibt 2 Arten von Klassifikationsproblemen:\n",
    "- **Binäre** Klassifizierung\n",
    "- **Mehrklassen**-Klassifizierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48908e-e494-42e1-aecd-6d61390e24e5",
   "metadata": {},
   "source": [
    "#### Sigmoid Funktion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1268e0-7e77-4a26-8e9a-1527f9692588",
   "metadata": {},
   "source": [
    "Das Modell der logistischen Regression verwendet die **Sigmoid-Funktion** (oder Logit-Funktion), die eine kontinuierliche Eingabe nimmt und sie in einen Ausgabewert zwischen 0 und 1 umwandelt, diese wird dann mit dem **Schwellenwert 0,5** verglichen. Dieser Ausgabewert kann als die Wahrscheinlichkeit interpretiert werden, dass eine gegebene Eingabe zu einer bestimmten Klasse gehört.\n",
    "\n",
    " \n",
    "Sei $θ ∈ \\mathbb{R}^{n+1}$. Die Sigmoid-Funktion $h_{logit}^θ$ auf $f : \\mathbb{R}^n \\rightarrow \\{0,1\\}$ ist ein (binärer) **Klassifikator**, dann ist die Funktion $h_{\\text{logit}}^{\\theta} : \\mathbb{R}^{n} \\rightarrow (0,1)$ mit\n",
    "$$\n",
    "h_{\\text{logit}}^{\\theta}(x) = \\frac{1}{1+e^{-(\\theta_{0}+\\theta_{1}x_{1}+...+\\theta_{n}x_{n})}}\n",
    "$$\n",
    "\n",
    "D.h. folgendes passiert:\n",
    "1. wir setzen einen linearen Modell $h_{\\theta}$ in die Funktion $g(z) = \\frac{1}{1+ e^{-z}}$\n",
    "2. dann wir vergleichen das Ergebnis von $g(z)$ mit dem SChwellenwert 0.5 für eine beliebige Funktion $clf_f$ definiert als: $$\n",
    "clf_f(x) = \n",
    "\\begin{cases} \n",
    "1 & \\text{falls } f(x) \\geq 0.5, \\\\\n",
    "0 & \\text{falls } f(x) < 0.5.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7afd0b-36c6-448e-b9c0-f116e86a2963",
   "metadata": {},
   "source": [
    "#### Die logistische Kostenfunktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a426b02-aca7-4261-98aa-0ec8e9aa9dd0",
   "metadata": {},
   "source": [
    "$$\n",
    "L_{\\text{logit}}(D, f) = -\\sum_{i=1}^{m} y(i) \\ln f(x(i)) + (1-y(i)) \\ln(1- f(x(i)))\n",
    "$$\n",
    "\n",
    "Wir suchen ein Parameter θ, so dass $h^{logit}_{\\theta}$ optimal an den Trainingsdatensatz D angepasst ist, d.h. wir suchen eine Lösung für das folgende Optimierungsproblem:\n",
    "$$ min_θ L_{logit}(D,h^θ_{logit}) \\tag(1)$$\n",
    "\n",
    "- Das Optimierungsproblem (1) ist **konvex**, d. h., es verfügt über einer eindeutige Lösung.\n",
    "- Mithilfe numerischer Methoden wie Gradient Descent kann es auch effizient gelöst werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1bc1b-bdb9-4b8c-a220-7432b42c4cad",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f88e59-ebee-4255-a7f5-babc12cc548c",
   "metadata": {},
   "source": [
    "\n",
    "**Schritte der Evaluation:**\n",
    "→ Aufteilung der Daten in:\n",
    "- einen **Trainingsdatensatz**, der verwendet wird, um das Modell für den Klassifikator clf zu trainieren.\n",
    "- und einen **Testdatensatz** der dazu dient, die Leistung des Modells auf neuen, zuvor ungesehenen Daten zu bewerten. Dies gibt uns eine Vorstellung davon, wie gut das gelernte Modell auf zuvor ungesehenen Daten generalisiert.\n",
    "\n",
    "**Evaluationsmaß**\n",
    "- <ins>Die Genauigkeit (accuracy)</ins>:\n",
    "    - Verhältnis der **richtig klassifizierten Instanzen** (sowohl positiv als auch negativ) zur Gesamtzahl der **Instanzen**. Eine gute Maßzahl für die Gesamtgenauigkeit des Klassifikators.\n",
    "    - **Nachteil**: Es kann bei ungleicher Klassenrepräsentation eine falsche Einschätzung\n",
    "der Qualität eines Klassifikators liefern.\n",
    "\n",
    "Deshalb $\\longrightarrow$ **Konfusionsmatrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185445b-aa1f-40e4-ac93-47fd1072c560",
   "metadata": {},
   "source": [
    "#### Konfusionsmatrix (engl. confusion matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d0dde-3103-4d95-97d9-e331f617ec6e",
   "metadata": {},
   "source": [
    "Die Konfusionsmatrix ist ein nützliches Werkzeug, um die Leistung eines Klassifikators zu bewerten, da sie nicht nur die Gesamtgenauigkeit, sondern auch andere Metriken wie <ins>Sensitivität (auch als Recall oder True Positive Rate bekannt), Spezifität, Präzision und F1-Score</ins> berücksichtigt.\n",
    "- insbesondere hilfreich in Szenarien <ins>mit ungleicher Klassenverteilung</ins>. \n",
    "\n",
    "Die Konfusionsmatrix für ein binäres Klassifikationsproblem sieht folgendermaßen aus:\n",
    "\n",
    "| | Vorhersage: Positiv clf=1 | Vorhersage: Negativ clf=0 |\n",
    "|---|---|---|\n",
    "| **Tatsächlich: Positiv** y=1 | True Positive TP(D,clf) | False Negative FN(D,clf) |\n",
    "| **Tatsächlich: Negativ** y=0 | False Positive FP(D,clf) | True Negative TN(D,clf) |\n",
    "\n",
    "\n",
    "wobei:\n",
    "- True Positives (TP): $$TP(D, clf) = |\\{i | y(i) = 1, clf(x(i)) = 1\\}|$$\n",
    "- True Negatives (TN): $$TN(D, clf) = |\\{i | y(i) = 0, clf(x(i)) = 0\\}|$$\n",
    "- False Positives (FP): $$FP(D, clf) = |\\{i | y(i) = 0, clf(x(i)) = 1\\}|$$\n",
    "- False Negatives (FN): $$FN(D, clf) = |\\{i | y(i) = 1, clf(x(i)) = 0\\}|$$\n",
    "\n",
    "in python these values have th following order:\n",
    "| |  |  |\n",
    "|---|---|---|\n",
    "|  | True Negatives **TN** | False Positives **FP** |\n",
    "|  | False Negatives **FN** | True Positives **TP** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d3f90-fe51-4b90-875d-6e04deb097ed",
   "metadata": {},
   "source": [
    "Mit diesen Werten können wir dann verschiedene Metriken berechnen:\n",
    "\n",
    "\n",
    "| Metrik        | Definition  |  Formel  | \n",
    "|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|\n",
    "| **Genauigkeit (Accuracy)**   | Verhältnis der **richtig klassifizierten Instanzen** (sowohl positiv als auch negativ) zur Gesamtzahl der **Instanzen**. Eine gute Maßzahl für die Gesamtgenauigkeit des Klassifikators.                     | $$\\frac{TP + TN}{TP + TN + FP + FN}$$ |\n",
    "| **Sensitivität (Recall)** | Verhältnis der **richtig positiven Vorhersagen** zur Gesamtzahl der **tatsächlich positiven Instanzen**. Es ist eine gute Kennzahl, wenn die Kosten eines falsch negativen Ergebnisses hoch sind.                   | $$rec(D, clf)  = \\frac{TP}{TP + FN}$$|\n",
    "| **Präzision**     | Verhältnis der **richtig positiven Vorhersagen** zur Gesamtzahl der **positiven Vorhersagen**. Es ist eine gute Kennzahl, wenn die Kosten eines falsch positiven Ergebnisses hoch sind.                    | $$prec(D, clf)  = \\frac{TP}{TP + FP}$$ |\n",
    "| **F1-Maß**| Harmonisches Mittel aus Präzision und Recall. Üblicherweise als geeignetes Maß für die Gesamtqualität eines Klassifikators betrachtet.                                                                                                      | $$F1(D, clf)  = 2 \\cdot \\frac{Präzision \\cdot Recall}{Präzision + Recall}$$ |\n",
    "\n",
    "Eine weitere Metrik die nicht in der Konfusionsmatrix berücksichtigt wird ist die **Spezifität**: Spezifität ist das Verhältnis der korrekt als negativ identifizierten Instanzen zur Gesamtzahl der tatsächlich negativen Instanzen. Mit anderen Worten, die Spezifität misst, wie gut der Klassifikator in der Lage ist, nicht positive Instanzen korrekt zu klassifizieren. $$\\frac{TN}{TN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b9fd2-9158-4809-af24-55eefc8e45e4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3. SVM <a name=2.3.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13c7b9-4bfc-46f2-b037-0ea285e537dc",
   "metadata": {},
   "source": [
    "- **Support Vector Machine (SVM)** ist ein häufig verwendete Methode zur Klassifikation.\n",
    "- Die Kernidee von SVMs ist die Bestimmung einer Hyperebene im Merkmalsraum, die die Beispiele der verschiedenen Klassen voneinander trenn>\n",
    "- Im 2-dimensionalen Raum sind Hyperebenen einfache Geraden.\n",
    "- Bei der logistischen Regression werden die Klassifikationsgrenzen nur **implizit** berechnet und der Lernalgorithmus basiert auf der Minimierung der logistischen Kostenfun on.\n",
    "- Im Gegensatz dazu wird bei der SVM die Klassifikationsgrenze **explizit** gelernt.\n",
    "- Bei binärer Klassifikation wird die Hyperebene gesucht, die die beiden Klassen voneinander trennt und dabei den größtmöglichen Abstand zu den Beispielen der beiden Klassen hat.\n",
    "\n",
    "Die **Hyperebene** definiert durch die Gleichung: $$h^{SVM}_{\\theta,b} : \\theta^T x - b = 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a4c3c-220b-41fa-9e07-28294e004c96",
   "metadata": {},
   "source": [
    "Die Klassifikationsfunktion $clf_{\\theta,b}(x)$ ist also wie folgt definiert:\n",
    "\n",
    "$$\n",
    "clf_{\\theta,b}(x) = \\begin{cases}\n",
    "   1 &\\text{falls } \\theta^T x - b ≥ 0 \\\\\n",
    "   0 &\\text{falls } \\theta^T x - b < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Wie zuvor besteht die Lernaufgabe nun darin, die Parameter θ und b so zu ermitteln, dass $h^{SVM}_{\\theta,b}$ (bzw. $clf_{\\theta,b}$) einen gegebenen Datensatz gut erklärt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd421f4e-1c43-480a-88bd-d3e8d905ad8b",
   "metadata": {},
   "source": [
    "### linear-separierbare Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244ff97-c74f-476d-8617-404a99841220",
   "metadata": {},
   "source": [
    "\n",
    "- Wir nehmen zunächst immer an dass die Klassen **linear separierbar** sind, d.h. Es gibt eine Hyperebene, die die Klassen voneinander trennen kann (also **kein Beispiel fehlklassifiziert wird**).\n",
    "- Wenn bei einem binären Klassifikationsproblem die beiden Klassen vollständig durch eine Hyperebene getrennt werden können (d. h. wenn kein Beispiel falsch klassifiziert wird), sind die gegebenen Daten linear separierbar.\n",
    "\n",
    "##### **Hard-Margin** SVM für linear separierbare Daten\n",
    "\n",
    "Die optimalen Parameter $\\theta$ und $b$ werden durch die Lösung des gegebenen Minimierungsproblems bestimmt:\n",
    "$$\\| \\theta \\|$$\n",
    " $$\\text{so dass} \\quad y(\\theta^T x - b) \\geq 1 \\quad \\text{für alle} \\quad (x,1) \\in D \\tag{3}$$ \n",
    "\n",
    ">Bei einer Hard-margin-SVM wird $y(\\theta^T x - b) \\geq 1$ für alle (x,y)∈ D **strikt** gefordert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e0d02-955f-4319-ab12-ac08b536b535",
   "metadata": {},
   "source": [
    "Die optimal angepasste Hyperebene $h_0$ ist definiert durch:\n",
    "\n",
    "$$h_0 = h_{\\text{SVM}}^{\\theta,b} : \\theta^T x - b = 0$$\n",
    "\n",
    "Weiterhin dargestellt sind zwei zu $h_0$ parallele Hyperebenen $h_1$ und $h_{-1}$, die definiert sind durch:\n",
    "\n",
    "$$h_1 : \\theta^T x - b = 1$$\n",
    "$$h_{-1} : \\theta^T x - b = -1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0806b84-7d75-4320-bd7e-45724295e793",
   "metadata": {},
   "source": [
    "**Wichtig**\n",
    "- der Abstand von $h_0$ zum Ursprung ist genau $\\frac{b}{\\|\\theta\\|}$\n",
    "- der Abstand von $h_1$ und $h_{-1}$ zu $h_0$  ist genau $\\frac{1}{\\|\\theta\\|}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53448f55-0041-44d2-9216-649efeacfac2",
   "metadata": {},
   "source": [
    "Ein **Stützvektor** ist ein Datenpunkt, der genau auf den Hyperebenen $h_1$ und $h_{-1}$ liegt und die Lösung des Optimierungsproblems in einer Support Vector Machine bestimmt. \n",
    "bzw. Die Stützvektoren sind Datenpunkte, die auf Hyperebenen liegen, die parallel zur optimal separierenden Hyperebene liegen.\n",
    "\n",
    "Der **Normalenvektor** ist der Parameter $\\theta$ und ist ein Vektor, der senkrecht auf den Hyperebenen $h_0$, $h_1$ und $h_{-1}$ steht und deren Orientierung bestimmt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc232ed0-8d21-40c8-a9dc-1bca86f62f48",
   "metadata": {},
   "source": [
    "### Nicht-linear-separierbare Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae3284-8b60-49a8-8820-53e83c5300dd",
   "metadata": {},
   "source": [
    "##### Die Hinge Kostenfunktion:\n",
    "\n",
    "$$\n",
    "L_{\\text{hinge}}(D, f) = \\sum_{i=1}^{m} \\max\\{0, 1 - y^{(i)}f(x^{(i)})\\}\n",
    "$$\n",
    "\n",
    "Versucht man, eine lineare hard-margin-SVM auf nicht linear separierbaren Daten zu trainieren, besitzt das zugehörige Optimierungsproblem keine zulässige Lösung und die SVM bleibt undefiniert.\n",
    "\n",
    "$\\longrightarrow$ Wir wenden die Hinge-Kostenfunktion auf lineare SVMs an, indem wir sie in die Zielfunktion des Optimierungs\u0002problems (3) aufnehmen (und dafür die harten Nebenbedingungen weglassen) und fügen ein Regularisierungsparameter $C$ ein.\n",
    "\n",
    "##### **Soft-Margin** SVM für Nicht-linear separierbare Daten\n",
    "Für einen gegebenen Datensatz D sind die optimalen Parameter θ und b durch die Lösung des folgenden Minimierungsproblems bestimmt:\n",
    "\n",
    "$$\n",
    "\\min C \\|\\theta\\|^2 + \\frac{1}{m} \\sum_{i=1}^{m} \\max\\{0, 1 - y^{(i)} (\\theta^T x^{(i)} - b)\\}\n",
    "$$\n",
    "wobei Der Term $C \\|\\theta\\|^2$ ist identisch zum Tikhonov-Regularisierer.\n",
    "\n",
    ">Bei einer soft-margin-SVM wird $y(\\theta^T x - b) \\geq 1$\n",
    " für alle (x,y) ∈\r",
    "**\n",
    " nicht stri**kt gefordert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0cc23-cb9b-4dff-b1e0-1126fa75c2fd",
   "metadata": {},
   "source": [
    "### Kernelfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895139e-bf12-49b5-b8f7-a271fae6a676",
   "metadata": {},
   "source": [
    "Bei SVMs können wir einen Trick (den sogenannten **Kernel-Trick**) anwenden <ins>anstelle</ins> der expliziten Merkmalserweiterung.\n",
    "\n",
    "Eine Kernelfunktion $k_{\\phi}$ realisiert das Skalarprodukt im $R^{n'}$:\n",
    "\n",
    "$$\n",
    "k_{\\phi} (x, x') = \\phi(x)^T \\phi(x') = (x^T,x')^2\n",
    "$$\n",
    "wobei $x$ und $x'$ sind verktoren. und $\\phi$ eine beliebgie Funktion ist (Üblicherweise eine Transformation des Merkmalsraums in einen höherdimensionalen Merkmalsraum).\n",
    "\n",
    "Weitere gebräuchliche Kernel-Funktionen wie folgt dargestellt:\n",
    "\n",
    "1. **Homogener polynomieller Kernel zu Grad d > 0:**\n",
    "\n",
    "    Der homogene polynomielle Kernel ist definiert als: $$k_{d, \\text{poly-h}}(x, x') = (x^T x')^d$$\n",
    "   Dieser Kernel eignet sich gut für Daten, die durch eine Polynomfunktion eines bestimmten Grades getrennt werden können. Wenn Ihre Daten auf dem Plot eine klare polynomiale Trennung aufweisen, könnte dies eine gute Wahl sein.\n",
    "\n",
    "3. **Inhomogener polynomieller Kernel zu Grad d > 0 mit r ∈ R:**\n",
    "\n",
    "    Der inhomogene polynomielle Kernel ist definiert als: $$k_{d,r, \\text{poly-i}}(x, x') = (x^T x' + r)^d$$\n",
    "   Dieser Kernel fügt einen Konstanten Term r hinzu, was zu mehr Flexibilität führt. Er kann verwendet werden, wenn die Daten fast durch ein Polynom getrennt werden können, aber eine kleine Verschiebung benötigen.\n",
    "\n",
    "5. **Radiale Basisfunktion mit γ > 0:**\n",
    "\n",
    "    Die radiale Basisfunktion (RBF), auch bekannt als Gaußscher Kernel, ist definiert als: $$k_{\\gamma, \\text{rbf}}(x, x') = e^{-\\gamma \\|x - x'\\|^2}$$\n",
    "   Dieser Kernel ist sehr flexibel und kann komplexe Trennflächen modellieren. Er eignet sich gut für Fälle, in denen die Daten nicht linear oder polynomiell separierbar sind. Wenn Ihre Daten auf dem Plot Cluster bilden oder wenn es keine offensichtliche lineare oder polynomiale Trennung gibt, könnte der RBF-Kernel eine gute Wahl sein.\n",
    "\n",
    "Beachten Sie auch, dass der lineare Kernel ein Spezialfall des homogenen polynomiellen Kernels ist: $k_{\\text{linear}} = k_{1, \\text{poly-h}}$.\n",
    "\n",
    "Der Kernel $k_{\\gamma, \\text{rbf}}$ wird gelegentlich auch Gaußscher Kernel genannt und wird recht oft verwendet, da er in der Lage ist, auch komplexere Klassenunterscheidungen zu modellieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5dbb4-d7d5-41dc-9de9-fbe74d7bb642",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4. KNN <a name=2.4.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd80bf-cf88-4a58-a588-35da1c3d0bbc",
   "metadata": {},
   "source": [
    "### Grundlagen\n",
    "\n",
    "- benötigt keinen Training, kann direkt auf den testdaten benutzt werden.\n",
    "\n",
    "- Die Grundidee des KNN-Algorithmus (k-nearest neighbour) besteht darin, dass zur Vorhersage der Klasse einfach die\n",
    "vorherrschende Klasse der k ∈ N nächsten Nachbarn (aus dem Trainingsdatensatz) im Merkmalsraum gewählt wird.\n",
    "\n",
    "- Definiere: $$clf_{D,k}(x) = maj(nearest_k(D, x))$$\n",
    "\n",
    "- Mit anderen Worten, nearestk(D, x) bestimmt diejenigen k verschiedenen Klassen derjenigen Beispiele des Daten\u0002satzes D, die sich bezüglich der Euklidischen Distanz am nächsten zu x befinden. Die Funktion maj bestimmt dann diejenige Klasse, die unter diesen k nächsten Nachbarn am häufigsten auftaucht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62acf6f-fb7c-452c-976e-0d57ab8b4731",
   "metadata": {},
   "source": [
    "**wichtig**:\n",
    "- wir nehmen für $nearest_k(D, x)$ immer an dass alle Beispiele des Datensatzes D eine unterschiedliche Distanz zu $k$ haben.\n",
    "- Wenn 2 oder mehr BEsipiele die *gleiche* Distanz zu x (und somit wird sie mit den k nächste nachbran gezählt), werden wir trozdem nur k nächste nachbarn wählen und die restlichen identischen beispiele ignorieren.\n",
    "- Für $maj$ nehmen wir an, dass es immer eine eindeutige Klasse in der Mehrheit gibt. Gibt es mehrere maximal\n",
    "vorhandene Klassen, wählen wir eine Klasse zufällig aus.\n",
    "- Diese Definition ist parametrisierbar:\n",
    "    - die BEstimmung der k nächsten Nachbarn muss nicht unbedingt dmit der Euklidischen Norm berechnet werden. Prinzipiell kann hier eine beliebige Norm verwendet werden.\n",
    "    - die Funktion maj kann durch andere Selektionsfunktionen ausgetauscht werden, beispielsweise eine Funktion, die der Klasse der näheren Nachbarn eine höhere Gewichtung gibt.\n",
    "- Typische Werte für k liegen hier im Bereich 1,...,10, wobei:\n",
    "    - <ins>Klassifikatoren mit kleineren Werten für k zu Überanpassung</ins>\n",
    "    - und <ins>höheren Werten für k zu Unteranpassung neigen</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a09c8-4016-4d7d-9e6f-b73c193ed533",
   "metadata": {},
   "source": [
    "### Nächste-Nachbarn-Regression\n",
    "\n",
    "- KNN kann auch für REgressionsprobleme verwendet werden mit einer einfachen modifikation:\n",
    "    - Anstatt als Klasse eines neuen Beispiels die vorherrschende Klasse der Nachbarschaft zu wählen, wird hier als Zielwert **der Mittelwert der Nachbarschaft** gewählt: $$regr_{D,k}(x) = \\frac{\\sum_{y \\in nearest_k(D,x)}y}{k} = \\frac{1}{k}\\sum_{y \\in nearest_k(D,x)} y$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1b696-22b0-4dfa-b3cf-a4560dd96626",
   "metadata": {},
   "source": [
    "### Merkmalskalierung\n",
    "\n",
    "- **Nachteil von KNN**: (insbesondere bei der Verwendung der Euklidischen Norm) ist eine Empfindlichkeit bzgl. verschiedener Skalen der Merkmale.\n",
    "- Dieses Problem taucht auch bei anderen Machinellen Lernen Verfahren.\n",
    "- Deshalb wichtig: **Normierung der Merkmalsausprägung** in der Datenvorverarbeitungsphase.\n",
    "- Es gibt viele Ansätze. Wir zeigen hier: **z-Transformation** (oder einfach nur **\n",
    "Standardisierun**g) vor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4faca0-0774-463b-b6f0-45743b71e7d0",
   "metadata": {},
   "source": [
    "### Merkmalskalierung\n",
    "\n",
    "- **Nachteil von KNN**: (insbesondere bei der Verwendung der Euklidischen Norm) ist eine Empfindlichkeit bzgl. verschiedener Skalen der Merkmale.\n",
    "- Dieses Problem taucht auch bei anderen Machinellen Lernen Verfahren.\n",
    "- Deshalb wichtig: **Normierung der Merkmalsausprägung** in der Datenvorverarbeitungsphase.\n",
    "- Es gibt viele Ansätze. Wir zeigen hier: **z-Transformation** (oder einfach nur **Standardisierung**) vor.\n",
    "\n",
    "**z-Transformation**:\n",
    "\n",
    "Der z-transformierte Datensatz $\\hat{D}$ ist definiert als:\n",
    "\n",
    "- Für jedes Merkmal \\( j \\) und jede Beobachtung \\( i \\), ist der z-transformierte Merkmalswert $\\hat{x}_{ij}$ gegeben durch:\n",
    "\n",
    "$$\n",
    "\\hat{x}_{ij} = \\frac{x_{ij} - \\tilde{x}_j}{\\sigma_j} \\tag{a}\n",
    "$$\n",
    "\n",
    "wo $\\tilde{x}_j$ der Mittelwert und $\\sigma_j$ die Standardabweichung des Merkmals $j$ ist.\n",
    "\n",
    "- Der z-transformierte Zielwert $\\hat{y}_i$ ist gleich dem ursprünglichen Zielwert $y_i$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = y_i\n",
    "$$\n",
    "Nach der **z-Transformation** ist der Erwartungswert (über dem gegebenen Datensatz) jeder Merkmalsausprägung 0 und die Varianz jeder Merkmalsausprägung 1. \n",
    "\n",
    "D.h.: \n",
    "1. Wir berechnen die Mittelwerte der Merkmale von x, d.h. $\\tilde{x}$\n",
    "2. Wir berechnen die Standardabweichungen $\\sigma$ der Merkmale von x.\n",
    "3. dann verwenden wir die Formel (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f41122-1fa8-4067-a138-52cf90c30a95",
   "metadata": {},
   "source": [
    "## 2.5. Bayes <a name=2.5.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de359ed3-2610-4613-b49d-65042cb0535f",
   "metadata": {},
   "source": [
    "- Diese Methode verwendet ebide Konzepte **Modell** und **Wahrscheinlichkeit**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa3c7a-0ce2-4009-86d8-a6635c96c53b",
   "metadata": {},
   "source": [
    "### Das Maximum-Likelihood-Prinzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5412f4-b227-49ff-813c-a87f109504d4",
   "metadata": {},
   "source": [
    "- Hier heißt ein Modell $h$ auch **hypothese**.\n",
    "- Üblicherweise nimmt man an, dass h aus einem gegebenen Hypothesenraum H entstammt (z.B. der Menge aller linearen Funktionen im Fall der linearen Regression)\n",
    "- Sei P die Wahrscheinlichkeitsverteilung.\n",
    "- Optimale Hyptothese h ist die wahrscheinlichste Hypothese h, gegeben dass wir die Trainingsdaten D beobachtet haben.\n",
    "\n",
    "#### Bayes Theorem\n",
    "\n",
    "$$P(h | D) = \\frac{P(D | h)P(h)}{P(D)} \\tag{1}$$ \n",
    "\n",
    "Hierbei ist:\n",
    "- `P(h | D)`:  die **a posteriori Wahrscheinlichkeit** der Hypothese. beschreibt die Wahrscheinlichkeit von h gegeben der Beobachtung D.\n",
    "    - $P(h | D)$ kann nicht direkt bestimmt werden, aber das Bayes-Theorem kann helfen, den Wert anzunäehren.\n",
    "- `P(h)` die **a priori Wahrscheinlichkeit** der Hypothese h.\n",
    "    - Das bedeutet, es ist die Wahrscheinlichkeit, die wir der Hypothese h zuweisen, bevor wir zusätzliche Daten betrachten.\n",
    "    - Diese Wahrscheinlichkeit kann durch vorhandenes Hintergrundwissen beeinflusst werden, das uns eine Vorstellung davon gibt, wie die Hypothese wahrscheinlich aussieht.\n",
    "    - oft besteht unser vollständiges Hintergrundwissen nur aus dem Datensatz D und wir haben keine weiteren Informationen zum Hypothesenraum H.\n",
    "    -  deshalb --> Wir nehmen eine Gleichverteilung auf H an, d.h. alle Hypothesen sind gleich wahrscheinlich.\n",
    "- `P(D)` ist die Wahrscheinlichkeit, dass der Datensatz D beobachtet wurde,\n",
    "- und `P(D | h)` ist die Wahrscheinlichkeit, D zu beobachten, gegeben dass D von h generiert wurde.\n",
    "    - ist einfacher abzuschätzen als  `P(h | D)`, da sie prinzipiell beschreibt, wie gut h den Datensatz D erklärt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f26254-43c2-4b7a-8ad0-8b572fec269f",
   "metadata": {},
   "source": [
    "#### Maximum-A-Posteriori-Hypothese (MAP-Hypothese) h\\*\n",
    "-  wir suchen eine **Hypothese h\\*, die den Wert P(h | D) bzw. (1) maximiert**.\n",
    "\n",
    "$$\n",
    "h* = \\arg\\max_{h \\in H} P(h | D) $$\n",
    "$$h* =  \\arg\\max_{h \\in H} \\frac{P(D | h)P(h)}{P(D)}$$\n",
    "$$h* =  \\arg\\max_{h \\in H} P(D | h)P(h)\n",
    "\\tag{3}$$\n",
    "\n",
    "  weil der Term P(D) für die Maximierung irrelevant ist.\n",
    "\n",
    "#### Maximum-Likelihood-Hypothese (ML-Hypothese) h\\*\n",
    "\n",
    "  wenn $P(h)$ **gleichverteilt,** ist, dann:\n",
    "  $$h* =  \\arg\\max_{h \\in H} P(D | h)\n",
    "\\tag{4}$$\n",
    "- h\\* heißt hier **Maximum-Likelihood-Hypothese** (ML-Hypothese), da sie nur auf der \n",
    "maximalen Wahrscheinlichkeit, die Daten D bzgl. h zu beobachten, basiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f472a-dd7a-49a4-9b67-7bf3f134795a",
   "metadata": {},
   "source": [
    "### Bayes-Klassifikation und lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036358b-2791-4705-9f32-1e99d6e025f3",
   "metadata": {},
   "source": [
    "##### Das originale linearer Regression\n",
    "- Bei linearer REgression suchen wir eine $\\theta^*$ mit $$\\arg\\min_{\\theta} \\sum{i=0}{m}(\\theta^T x^i - y^i)^2 \\tag{5}$$\n",
    "- Das gelernte Modell $h_{\\theta^*}(x) = θ_0^∗ + θ_1^∗x_1 + ::: + θ_n^∗x_n$ ist eine Gerade die den funktionalen Zusammenhang zwischen den Merkmalen x und der Zielvariablen y modelliert.\n",
    "\n",
    "##### Die linearer Regression aus der Perspektive der Bayes’schen Klassifikation\n",
    "- Wir gehen davon aus, dass unser Datensatz D **verrauscht** ist, d. h., es wird keine Gerade geben auf der alle Trainingsbeispiele liegen.\n",
    "    - d.h. die Werte y unseres Datensatzes haben die Form: $$y^i = \\hat{y}^i + ε^i$$ wobei ε der Fehler und $\\hat{y}$ der wahre Wert von y ist.\n",
    "    - **Was für eine Art Fehler?** Eine durchaus übliche Annahme hier ist, dass die Fehlerwerte im Datensatz **normalverteilt** sind.\n",
    "    - Wir gehen davon aus, dass die Fehlerwerte $ε^i$ den Erwartungswert 0 und eine unbekannte Varianz $σ^2$ haben\n",
    "- Wir nehmen initial an, dass  alle Parameter θ gleich wahrscheinlich sind.\n",
    "\n",
    "> die lineare Regression (unter Benutzung des quadratischen Fehlers als Kostenfunktion) eine Maximum-Likelihood-Hypothese bestimmt\n",
    ">\n",
    "> $\\longrightarrow$ die lineare Regression ist also nach Bayes’schen Grundsätzen plausibel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ce31e-a61c-4892-bb65-bfa400c8c32b",
   "metadata": {},
   "source": [
    "### Normaler vs Naive Bayes-Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fd7da-eba3-4e5d-9494-5bc51f9acc0d",
   "metadata": {},
   "source": [
    "Sei $Z_i$ der Merkmalsraum und $Z = {c_1,..., c_k}$ die Menge der Klassen.\n",
    "\n",
    "**Gegeben ein neuer Datenpunkt x, wählen wir diejenige Klasse c ∈ Z, die aufgrund von D am wahrscheinlichsten ist.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3640fb-4c9c-4635-b579-61663986b132",
   "metadata": {},
   "source": [
    "#### Bayes-Klassifikator $clf^{Bayes}_D$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba166fe8-c15f-474f-9ae8-9ca7e6b8250f",
   "metadata": {},
   "source": [
    "\n",
    "$$ clf^{Bayes}_D(x) = \\arg\\max_{c \\in Z} P(c | x,D)$$\n",
    "\n",
    "wobei\n",
    "\n",
    "$$P(c | x,D) = \\frac{|\\{(x, c) \\in D\\}|}{\\sum_{c' \\in Z} |\\{(x, c') \\in D\\}|}$$\n",
    "\n",
    "Mit anderen Worten, einem neuen Datenpunkt x wird diejenige Klasse c ∈ Z zugewiesen, die am ha¨ufigsten x in\n",
    "D zugewiesen wird.\n",
    "\n",
    "**Probleme :**\n",
    "1. wir müssen für jede zu erwartende Merkmalsausprägung $x^∗$ Beispiele im Trainingsdatensatz D haben, um $x^∗$ überhaupt klassifizieren zu können.\n",
    "2. Ein weiteres Problem (das auch prinzipiell schon beim KNN-Algorithmus aufgetreten ist) besteht darin, dass zur Berechnung von $ clf^{Bayes}_D(x)$ stets der gesamte Datensatz $D$ vorgehalten werden muss. Insbesondere bei großen Datensätzen kann dies signifikant zu einer langen Berechnungszeit beitragen.\n",
    "\n",
    "**Lösung $\\longrightarrow$** von der <ins>allgemeinen Bayes-Klassifikation</ins> zur <ins>Naiven Bayes-Klassifikation</ins> wechseln.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e08a5-b888-4924-9f99-c2f3ef3e3708",
   "metadata": {},
   "source": [
    "**Unterschied zwischem der allgmeinen und naiven Bayes-Klassifikation**:\n",
    "\n",
    "Der Unterschied dabei liegt darin, dass wir bei der Berechnung von `P(c | x,D)` eine Unabhängigkeitsannahme u¨ber die Verteilung der einzelnen Merkmale vornehmen und dabei\n",
    "den wahren Wert `P(c | x,D)` nur abscha¨tzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e15d2-e1d5-4521-87dd-7cf0b0166d59",
   "metadata": {},
   "source": [
    "#### Naives Bayes-Klassifikator $clf^{naive}_D$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3daaf8a-10ea-4ca1-a246-a00b21c41d04",
   "metadata": {},
   "source": [
    "- die Verteilungen der Merkmalsausprägungen sind bedingt unabhängig voneinander.\n",
    "\n",
    "$$clf^{naive}_D(x) = \\arg\\max_{c \\in Z} P(c | D)P(x_1 | c,D)P(x_2 | c,D)...P(x_n | c,D) \\tag{8}$$\n",
    "\n",
    "mit\n",
    "\n",
    "$$P(c | D) = \\frac{|{(z, c) \\in D}|}{|D|}$$\n",
    "\n",
    "$$P(x_i | c,D) = \\frac{|{(z', c) \\in D | z' = (z_1,...,z_n),z_i = x_i}|}{|{(z, c) \\in D}|} \\quad \\text{ für } i = 1,...,n$$\n",
    "\n",
    "Im Unterschied zur Bayes-Klassifikation:\n",
    "- muss nicht der gesamte Trainingsdatensatz fu¨r die Klassifikation vorgehalten werden, es genu¨gt hier, die Werte P(c | D) und P(i | c,D) fu¨r alle Kombinationen von Merkmalen xi und Klassen c ∈ Z zu berechnen und einzig diese vorzuhalten\n",
    "- Der Naive Bayes-Klassifikator kann auch Beispiele klassifizieren, die Merkmalsausprägungen aufweisen, die im Trainingsdatensatz nicht explizit vorgekommen sind.\n",
    "\n",
    "$\\longrightarrow$ Speicherplatzvorteil.\n",
    "\n",
    "Gibt es in dem betrachteten Lernszenario eins oder mehrere kontinuierliche Merkmale, so ist die Maschinerie des \n",
    "Naiven Bayes-Klassifikators prinzipiell in gleicher Weise anwendbar \n",
    "\n",
    "**Aber** anstelle einer Wahrscheinlichksvrteilung, eine Wahrscheinlichksdichte anwenden. d.h. in (8) $P(x_i | c,D)$,  $p(x_i | c,D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f2e00-eef2-493d-b983-c696cb8b6440",
   "metadata": {},
   "source": [
    "## 2.6. Entscheidungsäume <a name=2.6.><a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7245b-2707-4e4b-a2f9-7647bb21cc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34fb8722-6f82-47a1-a923-a72d1366e288",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.3. RNN <a name=5.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef20847-f681-44dc-b13e-90ebbe01e9db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3.1. spaltenweise Konkatenation zweier Matrizen <a name=5.3.1.><a>\n",
    "\n",
    "Sei $A \\in \\mathbb{R}^{n \\times m}$ und $B \\in \\mathbb{R}^{n \\times m'}$ zwei Matrizen mit gleicher Anzahl an Zeilen, so ist $A \\circ B \\in \\mathbb{R}^{n \\times (m + m')}$ die entsprechende Konkatenation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917a1c0-3a58-4129-ab00-d9cde58459eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen Sie die Matrizen A und B mit Dummy-Zahlen\n",
    "A = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "\n",
    "B = np.array([[10, 11, 12], \n",
    "              [13, 14, 15], \n",
    "              [16, 17, 18]])\n",
    "\n",
    "# Führen Sie die Konkatenation durch\n",
    "AB = np.concatenate((A, B), axis=1)\n",
    "print(AB)\n",
    "\n",
    "# Erstellen Sie die Vektoren v und w mit Dummy-Zahlen\n",
    "v = np.array([1, 2, 3])  # v = (v1, ..., vm)^T\n",
    "w = np.array([4, 5, 6])  # w = (w1, ..., wm')^T\n",
    "\n",
    "# Führen Sie die Konkatenation durch\n",
    "vw = np.concatenate((v, w))\n",
    "print(\"v ◦ w =\", vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe44ddc-6fc8-47a8-9048-bdad3c010d90",
   "metadata": {},
   "source": [
    "Vergewissern Sie sich, dass für die obigen Definition gilt $(A \\circ B)(v \\circ w) = Av + Bw$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bf573-d301-4809-866e-9711d253597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = np.dot(AB,vw)\n",
    "result2 = np.dot(A,v) + np.dot(B,w)\n",
    "print(result1 == result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51772525-0900-4237-bb78-faa53dd26d72",
   "metadata": {},
   "source": [
    "### 5.3.2. One-Hot-Codierung <a name=5.3.2.><a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6195b0-7376-4847-8bd3-254cc55853f2",
   "metadata": {},
   "source": [
    "Sei ein Alphabet gegeben durch\n",
    "\n",
    "Σ={a,e,s,t}\n",
    "\n",
    "1. Bestimmen Sie eine One-Hot-Codierung für Σ\n",
    ". (Anwortformat '(1,2,3,4,5,6)', Vektorlänge ist selbst zu wä\n",
    "2. Wie ist demnach das Wort test\n",
    " codiert \n",
    "\n",
    "(Anwortformat '((1,2,3,4,5,6),(7,8,9))')\n",
    "#### Lösung\n",
    "- a: (1, 0, 0, 0)\n",
    "- e: (0, 1, 0, 0)\n",
    "- s: (0, 0, 1, 0)\n",
    "- t: (0, 0, 0, 1)\n",
    "\n",
    "Unter Verwendung der zuvor definierten One-Hot-Codierung für das Alphabet Σ={a,e,s,t}, wird das Wort \"test\" wie folgt codiert:\n",
    "\n",
    "- t: (0, 0, 0, 1)\n",
    "- e: (0, 1, 0, 0)\n",
    "- s: (0, 0, 1, 0)\n",
    "- t: (0, 0, 0, 1)\n",
    "\n",
    "Daher ist die Codierung des Wortes \"test\" in dem von Ihnen angegebenen Antwortformat:\n",
    "\n",
    "((0, 0, 0, 1), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df485f3-6e46-4c86-9452-28009fadc40a",
   "metadata": {},
   "source": [
    "### 5.3.3. Berechnungsgraphen <a name=5.3.3.><a>\n",
    "Im Allgemeinen gilt für eine Eingabe $x = (x^{(1)}, \\ldots, x^{(m)})$:\n",
    "\n",
    "$$\n",
    "h(i) = \\text{act}(Ux^{(i)} + Wh^{(i-1)}) \\quad \\text{(1)}\n",
    "$$ <a name=hi><a>\n",
    "\n",
    "$$\n",
    "o(i) = \\text{act}(Vh^{(i)}) \\quad \\text{(2)}\n",
    "$$<a name=oi><a>\n",
    "\n",
    "für $i = 1, \\ldots, m$. Zu beachten ist, dass diese Netzwerkarchitektur mit Eingaben beliebiger Länge umgehen kann, aber eine fixe Anzahl an Parametern besitzt (in den Matrizen $U$, $V$, $W$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda19404-0a03-4c6c-b27b-c2d4602fbeab",
   "metadata": {},
   "source": [
    "Gegeben sei das abgebildete einfache RNN, wobei\n",
    "\n",
    "$$\\sum = \\{\\text{ist,nichts,niemand}\\} = \\{(1,0,0)^T,(0,1,0)^T,(0,0,1)^T\\}$$\n",
    "$$U= ((0, 0.9, 0.9), (0.5, 0.1, 0), (0.5, 0, 0.1))$$\n",
    "$$W = ((0, 0.45, 0.45), (0.25, 0.05, 0), (0.25, 0, 0.05))$$\n",
    "$$V = ((0.5, 0, 0), (0, 0.5, 0), (0, 0, 0.5))$$\n",
    "$$h_0 = (0,1,1)^T$$\n",
    "\n",
    "und die Aktivierungsfunktion $h^{relu}$ ist. Berechnen Sie die hidden states und die Ausgabe für die Eingabe $x = \\text{'Niemand ist'} = ((0,0,1)^T,(1,0,0)^T)$. \n",
    "(Antwortformat '(1,2,3.456)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04919f-d436-4682-8ff6-3929da2c6e77",
   "metadata": {},
   "source": [
    "### 5.3.4. Long short-term memory-Netzwerke <a name=5.3.4.><a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bce749-40b6-4918-998d-004268a7c519",
   "metadata": {},
   "source": [
    "$$f^{(i)} = h^{logit} (U^f x^{(i)} + W^f h^{(i−1)})$$\n",
    "- Der Vektor $f^{(i)}$ soll steuern, was aus dem Langzeitgedächtnis `s` vergessen werden soll (auch als **forget gate** bezeichnet).\n",
    "\n",
    "$$g^{(i)} = h^{logit} (U^g x^{(i)} + W^g h^{(i−1)})$$\n",
    "$$k^{(i)} = h^{tanh} (U^k x^{(i)} + W^k h^{(i−1)})$$\n",
    "- Der Vektor $g^{(i)}$ (**input gate**) steuert, welche Informationen aus $k^{(i)}$ in das Langzeitgedächtnis aufgenommen werden sollen.\n",
    "$$q^{(i)} = h^{logit} (U^o x^{(i)} + W^o h^{(i−1)})$$\n",
    "- Der Vektor $q^{(i)}$ (**output gate**) steuert, welche Information in die Ausgabe und den nächsten versteckten Zustand $h^{(i)}$ einfließt.\n",
    "\n",
    "- Die Kernidee hinter LSTMs liegt in der Definition des Zellzustands: $$s^{(i)} = f^{(i)} \\cdot s^{(i-1)} + g^{(i)} \\cdot k^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a88a14-5f08-468d-aba0-11eacee21d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
