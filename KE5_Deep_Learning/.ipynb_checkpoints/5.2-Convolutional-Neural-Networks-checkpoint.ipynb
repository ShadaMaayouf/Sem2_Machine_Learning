{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T15:05:33.584082Z",
     "start_time": "2024-01-22T15:05:33.537800Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 5.2 Convolutional Neural Networks\n",
    ">## <ins>Table of contents</ins> <a name=\"up\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    ">* [**5.2.1. Faltung**](#5_2_1)\n",
    ">* [**5.2.2. Padding und Stride**](#5_2_2)\n",
    ">* [**5.2.3. Die Pooling-Operation**](#5_2_3)\n",
    ">* [**5.2.4. CNN-Architektur**](#5_2_4)\n",
    ">\n",
    ">## <ins>Beispiele</ins>\n",
    ">* [**Beispiel 1**:Darstellung von AND-, OR- und XOR-Funktionen mit Perzeptronen](#b1)\n",
    ">* [**Beispiel 2**: Backpropagation-Algorithmus$](#b2)\n",
    ">* [**Beispiel 3**: Q-Learning des Staubsaugerproblems](#b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolve(M_I, M_K):\n",
    "    # Höhe und Breite der Eingabematrix\n",
    "    I_H, I_W = M_I.shape\n",
    "\n",
    "    # Höhe und Breite des Kernels\n",
    "    K_H, K_W = M_K.shape\n",
    "\n",
    "    # Höhe und Breite der Ausgabematrix\n",
    "    O_H = I_H - K_H + 1\n",
    "    O_W = I_W - K_W + 1\n",
    "\n",
    "    # Initialisieren Sie die Ausgabematrix mit Nullen\n",
    "    output = np.zeros((O_H, O_W))\n",
    "\n",
    "    # Führen Sie die Faltung durch\n",
    "    for i in range(O_H):\n",
    "        for j in range(O_W):\n",
    "            output[i, j] = np.sum(M_I[i:i+K_H, j:j+K_W] * M_K)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(M, pool_size, stride):\n",
    "    # Höhe und Breite der Eingabematrix\n",
    "    M_H, M_W = M.shape\n",
    "\n",
    "    # Höhe und Breite der Ausgabematrix\n",
    "    O_H = (M_H - pool_size) // stride + 1\n",
    "    O_W = (M_W - pool_size) // stride + 1\n",
    "\n",
    "    # Initialisieren Sie die Ausgabematrix mit Nullen\n",
    "    output = np.zeros((O_H, O_W))\n",
    "\n",
    "    # Führen Sie das Max-Pooling durch\n",
    "    for i in range(O_H):\n",
    "        for j in range(O_W):\n",
    "            output[i, j] = np.max(M[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren Sie die Matrix MK\n",
    "M_K = np.array([\n",
    "    [1/16, 1/16, 1/16],\n",
    "    [1/16, 1/2, 1/16],\n",
    "    [1/16, 1/16, 1/16]\n",
    "])\n",
    "\n",
    "# Definieren Sie die Matrix MI\n",
    "M_I = np.array([\n",
    "    [12, 24, 28, 105, 250, 251],\n",
    "    [54, 43, 43, 42, 221, 241],\n",
    "    [67, 50, 89, 92, 210, 211],\n",
    "    [105, 156, 178, 115, 201, 187],\n",
    "    [19, 78, 125, 108, 52, 188],\n",
    "    [112, 101, 154, 205, 198, 192]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44.  51.  86. 198.]\n",
      " [ 71.  89. 115. 187.]\n",
      " [122. 140. 123. 173.]\n",
      " [ 98. 131. 131. 113.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Führen Sie die Faltung durch\n",
    "#M_J = np.round(convolve2d(M_I, M_K, mode='valid'))\n",
    "M_J = np.round(convolve(M_I, M_K))\n",
    "print(M_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27  x  992  x  992\n"
     ]
    }
   ],
   "source": [
    "def calculate_output_size(W, F, P, S):\n",
    "    \"\"\"\n",
    "    Berechnet die Ausgabegröße einer Faltungsschicht.\n",
    "\n",
    "    Parameter:\n",
    "    W (int): Die Größe der Eingabe (Breite oder Höhe).\n",
    "    F (int): Die Größe des Filters (Breite oder Höhe).\n",
    "    P (int): Das Padding.\n",
    "    S (int): Der Stride.\n",
    "\n",
    "    Rückgabe:\n",
    "    W_out (int): Die Größe der Ausgabe (Breite oder Höhe).\n",
    "    \"\"\"    \n",
    "    W_out = (W - F + P) // S + 1\n",
    "    return W_out\n",
    "\n",
    "W_out = calculate_output_size(994, 3, 0, 1)\n",
    "print((3*9),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27  x  496  x  496\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(992, 3, 2, 2)\n",
    "print((3*9),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189  x  492  x  492\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(496, 5, 0, 1)\n",
    "print((27*7),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189  x  123  x  123\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(492, 5, 4, 4)\n",
    "print((27*7),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.0. Einleitung zum Convolutional Neural Network (CNN)<a name=\"5_1_0\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Convolutional Neural Network (CNN) ist eine spezielle Form eines Feedforward-Netzwerks, das für Daten verwendet wird, die in einer Gitterstruktur angeordnet sind oder bei denen Merkmale in einer räumlichen oder zeitlichen Beziehung zueinander stehen. Es wird häufig in der Bildanalyse eingesetzt, aber auch für Zeitreihen wie Signalmessungen oder natürliche Sprache.\n",
    "\n",
    "#### Anwendungsgebiete von CNNs\n",
    "\n",
    "- **Bilddaten**: Bilder werden als Matrizen interpretiert, wobei jede Zelle den Graustufenwert oder den Farbwert kodiert.\n",
    "- **Zeitreihen**: Zum Beispiel Signalmessungen oder natürliche Sprache.\n",
    "- In diesem Kontext werden wir uns auf die Anwendung in der Bildanalyse konzentrieren, insbesondere auf die Klassifikation von Objekten auf Bildern, wie z.B. die Erkennung von Hunden oder Katzen.\n",
    "\n",
    "#### Herausforderungen bei der Bildanalyse\n",
    "\n",
    "- **Komplexität der Merkmale**: Um Objekte auf Bildern zu klassifizieren, müssen komplexe Merkmale wie Schnurrhaare erkannt werden.\n",
    "- **Variabilität der Position und Orientierung**: Die Merkmale können an verschiedenen Stellen des Bildes auftreten und in verschiedenen Orientierungen vorliegen.\n",
    "\n",
    "#### Motivation für CNNs\n",
    "\n",
    "- Ein herkömmliches Feedforward-Netzwerk würde sehr viele Parameter benötigen, um Merkmale an verschiedenen Stellen des Bildes zu erkennen, was zu Überanpassung führen kann.\n",
    "- Viele Merkmale sind lokalisiert, d.h. bestimmte Bereiche des Bildes sind für die Erkennung bestimmter Merkmale relevant, während andere Bereiche irrelevant sind.\n",
    "\n",
    "#### Zentrale Methode von CNNs: Faltungsoperation\n",
    "\n",
    "- Die Faltungsoperation ist zentral für die Implementierung der Merkmalsextraktion in CNNs.\n",
    "- Sie ermöglicht es, Merkmale wie Schnurrhaare an verschiedenen Positionen und in verschiedenen Orientierungen effizient zu erkennen, ohne dass jede Position separat trainiert werden muss.\n",
    "- Dies reduziert die Anzahl der Parameter und macht das Modell robuster gegenüber Überanpassung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1. Faltung <a name=\"5_2_1\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Die (kontinuierliche) Faltungsoperation $\\ast$ ist im einfachsten Fall eine mathematische Operation, die zwei reellwertige Funktionen $i, k : \\mathbb{R} \\rightarrow \\mathbb{R}$ als Eingabe nimmt und eine reellwertige Funktion als Ausgabe liefert, d. h.,\n",
    "\n",
    "$$\\ast : (\\mathbb{R} \\rightarrow \\mathbb{R}) \\times (\\mathbb{R} \\rightarrow \\mathbb{R}) \\rightarrow (\\mathbb{R} \\rightarrow \\mathbb{R})$$\n",
    "\n",
    "Konkret ist $\\ast$ definiert als\n",
    "\n",
    "$$(i \\ast k)(x) = \\int_{-\\infty}^{\\infty} i(y)k(x-y)dy$$\n",
    "\n",
    "Die Funktion $i$ heißt dabei **Eingabefunktion** und $k$ heißt **Kernelfunktion** (oder auch Filterfunktion). Die Ausgabe $i \\ast k$ heißt (im CNN-Kontext) auch Feature Map von $i$ bzgl. $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Beispiel 1:** Rauschunterdrückung (Denoising) <a name=b1></a>\n",
    "Die Faltungsoperation kann zur Rauschunterdrückung in Signalen verwendet werden. \n",
    "\n",
    "Angenommen, wir haben eine Funktion `i`, die die gemessene Höhe eines Flugzeugs zu jedem Zeitpunkt $x \\in \\mathbb{R}$ angibt. Da unsere Messinstrumente nicht perfekt sind, ist das gemessene Signal verzerrt. \n",
    "\n",
    "Wir definieren eine Funktion $k(x)$, die als Wahrscheinlichkeitsdichte interpretiert werden kann und die Funktionswerte von `i` über die letzten Punkte mittelt durch $i * k$.\n",
    "\n",
    "In anderen Worten, $(i ∗ k)(x)$ ist der Mittelwert der Werte $[i(x − 2),i(x)]$ bzgl. der Gewichtung $k$. Hier gibt k eine stärkere Gewichtung der Punkte nahe x und eine\r\n",
    "absteigende Gewichtung Richtung x−2\n",
    "\n",
    ".Die Ergebnis ist eine entrauschte Version der Funktion `i`.\n",
    "$$k(x) = \n",
    "\\begin{cases} \n",
    "1 - \\frac{1}{2}x & \\text{for } 0 \\leq x \\leq 2 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obige genannte Faltungsoperation ist die **kontinuierliche** Faltungsoperation. <ins>In unserem Kontext der Bildanalyse</ins> ist jedoch die **diskrete** Faltungsoperation relevanter. \n",
    "\n",
    "Gegeben zwei Funktionen $I,K : \\mathbb{Z} → \\mathbb{R}$, dann ist die Faltung $I ∗ K$ definiert durch\n",
    "\n",
    "$$(I ∗K)(n) = \\sum_{m=-∞}^{∞} I(m)K(n−m)$$\n",
    "\n",
    "Für die Bildanalyse mit zweidimensionalen Daten ist die Verallgemeinerung auf zweiwertige Funktionen relevant. Sind Funktionen $I,K : \\mathbb{Z}\\times\\mathbb{Z} → \\mathbb{R}$ gegeben, so ist `I ∗K` definiert durch\n",
    "\n",
    "$$(I ∗K)(n1,n2) = \\sum_{m1=-∞}^{∞} \\sum_{m2=-∞}^{∞} I(m1,m2)K(n1 −m1,n2 −m2) \\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Beispiel 2:** Rauschunterdrückung (Denoising) <a name=b1></a>\n",
    "\n",
    "In der Bildverarbeitung wird die Faltung (1) für den **Gauß-Filter** verwendet, eine Methode zum Weichzeichnen oder Entfernen von Rauschen in einem Bild. Die Kernelfunktion $K$ ist so definiert, dass der neue Pixelwert ein Mittelwert seiner Umgebung ist. Eine konkrete Instanz von $K$ ist definiert durch:\n",
    "\n",
    "$$\n",
    "K(i, j) = \n",
    "\\begin{cases} \n",
    "1/2 & \\text{wenn } i = j = 0 \\\\\n",
    "1/16 & \\text{wenn } i, j \\in \\{-1,0,1\\} \\text{ und nicht } i = j = 0 \\\\\n",
    "0 & \\text{sonst}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "für alle $i, j ∈ \\mathbb{N}$. Diese Kernelfunktion bildet den Helligkeitswert eines Pixels auf einen Mittelwert ab, wobei der aktuelle Pixelwert mit $\\frac{1}{2}$ gewichtet wird und die Werte aller direkt umliegenden Pixel mit jeweils $\\frac{1}{16}$ gewichtet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etrachtet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Die Faltungsoperation ist in der Regel eine \"lokale\" Operation, bei der die Merkmalsbestimmung eines Pixels nur seine Umgebung einbezieht.\n",
    "- Die Funktion $K(i, j)$ ist nur für einige wenige Indizes `i, j` ungleich Null.\n",
    "- `K` und die Eingabefunktion `I` werden üblicherweise durch eine Matrix beschrieben, und die Faltungsoperation kann als Matrixoperation interpretiert werden.\n",
    "- $M_I$, $M_K$ und $M_{I*K}$ sind die Matrixrepräsentationen der Eingabefunktion, Kernelfunktion und der resultierenden Feature Map.\n",
    "- Bei der Darstellung als Matrixoperation gibt es Freiheiten, wie mit den Randpixeln verfahren wird.\n",
    "- Die Ausgabe ist auf solche Pixel beschränkt, bei denen $M_K$ vollständig auf Elemente in `MI` angewendet werden kann.\n",
    "- Wenn $M_I ∈ \\mathbb{R}^{n×m}$ und $M_K ∈ \\mathbb{R}^{n'×m'}$ , dann gilt $$M_{I*K} ∈  \\mathbb{R}^{(n-n'+1)×(m-m'+1)}$$\n",
    "- Dieser Ansatz wird als Faltung ohne Padding oder Faltung mit validem Padding bezeichnet.\n",
    "- Alternativen dazu werden in Abschnitt 5.2.2 betrachtet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispiel 3. \n",
    "\n",
    "Wir führen Beispiel 2 fort. Die Matrixdarstellung $M_K \\in \\mathbb{R}^{3 \\times 3}$ von K und die Eingabefunktion $I$ (d. h., das Eingabebild) charakterisiert durch eine Matrix $M_I \\in \\mathbb{R}^{6 \\times 6}$ sind gegeben durch:\n",
    "\n",
    "$$M_K = \n",
    "\\begin{bmatrix}\n",
    "1/16 & 1/16 & 1/16 \\\\\n",
    "1/16 & 1/2 & 1/16 \\\\\n",
    "1/16 & 1/16 & 1/16 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$M_I =\n",
    "\\begin{bmatrix}\n",
    "12 & 24 & 28 & 105 & 250 & 251 \\\\\n",
    "54 & 43 & 43 & 42 & 221 & 241 \\\\\n",
    "67 & 50 & 89 & 92 & 210 & 211 \\\\\n",
    "105 & 156 & 178 & 115 & 201 & 187 \\\\\n",
    "19 & 78 & 125 & 108 & 52 & 188 \\\\\n",
    "112 & 101 & 154 & 205 & 198 & 192 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren Sie die Matrix MK\n",
    "M_K = np.array([\n",
    "    [1/16, 1/16, 1/16],\n",
    "    [1/16, 1/2, 1/16],\n",
    "    [1/16, 1/16, 1/16]\n",
    "])\n",
    "\n",
    "# Definieren Sie die Matrix MI\n",
    "M_I = np.array([\n",
    "    [12, 24, 28, 105, 250, 251],\n",
    "    [54, 43, 43, 42, 221, 241],\n",
    "    [67, 50, 89, 92, 210, 211],\n",
    "    [105, 156, 178, 115, 201, 187],\n",
    "    [19, 78, 125, 108, 52, 188],\n",
    "    [112, 101, 154, 205, 198, 192]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Feature Map $J = I ∗ K$ kann durch eine Matrix $M_J \\in \\mathbb{R}^{4 \\times 4}$ dargestellt werden (wir benutzen kein Padding). Insbesondere gilt für den Eintrag $(M_J)_{1,1}$, dass sich dieser aus der elementweisen Matrixmultiplikation von $K$ mit der $3 \\times 3$-Untermatrix von $M_I$, die nur aus den ersten drei Zeilen und den ersten drei Spalten besteht, zusammensetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44.  51.  86. 198.]\n",
      " [ 71.  89. 115. 187.]\n",
      " [122. 140. 123. 173.]\n",
      " [ 98. 131. 131. 113.]]\n"
     ]
    }
   ],
   "source": [
    "# Führen Sie die Faltung durch\n",
    "M_J = np.round(convolve(M_I, M_K))\n",
    "print(M_J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der Glättungsfilter ist für die Klassifikation von Bildinhalten weniger wichtig.\n",
    "- **Kernelfunktionen** können so definiert werden, dass sie <ins>die Präsenz von Kanten, Ecken oder komplexeren geometrischen Formen erkennen können.</ins> Die Parameter der Kernelfunktion (d.h., die Matrixeinträge) werden während des Lernens festgelegt.\n",
    "- Eine Faltungsschicht in einem CNN besteht typischerweise aus verschiedenen Kernelfunktionen, die gleichzeitig auf das gesamte Bild angewendet werden und verschiedene Merkmale erkennen können.\n",
    "- Ein **Vorteil** der Verwendung der Faltungsoperation in neuronalen Netzwerken ist <ins>die geringere Anzahl an zu lernenden Parametern</ins>.\n",
    "\n",
    "> **Beispiel**\n",
    ">\n",
    "> Bei einem Eingangsbild von 100×100 Pixeln (in Graustufen) und 10 verschiedenen Kernelfunktionen der Größe 5×5 besteht die zweite Schicht aus 10 Feature Maps der Größe 96×96. Dies führt zu insgesamt 96 * 96 * 10 = 92160 Neuronen in der zweiten Schicht.\n",
    ">\n",
    "> - Bei Verwendung eines vollvernetzten neuronalen Netzwerks gäbe es 10000 * 92160 = 921,600,000 Kanten und damit genau so viele zu lernende Parameter zwischen den beiden Schichten.\n",
    ">\n",
    "> - Bei 10 verschiedenen Kernelfunktionen der Größe 5×5 sind dies im CNN allerdings nur 5 * 5 * 10 = 250 verschiedene zu lernende Parameter.\n",
    ">\n",
    "> - Die genaue Einbettung von Faltungsschichten in die Architektur von CNNs wird in Abschnitt 5.2.4 weiter diskutiert.\n",
    "\n",
    "\n",
    "Zwei weitere Aspekte der Faltung selbst sind das Padding und der Stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "96\n",
      "92160\n",
      "921600000\n",
      "250\n",
      "Anzahl der Neuronen in der zweiten Schicht: 92160\n",
      "Anzahl der zu lernenden Parameter im vollvernetzten neuronalen Netzwerk: 921600000\n",
      "Anzahl der zu lernenden Parameter im CNN: 250\n"
     ]
    }
   ],
   "source": [
    "def calculate_cnn_parameters(input_size, num_kernels, kernel_size):\n",
    "    # Anzahl der Eingangsneuronen\n",
    "    input_neurons = input_size * input_size\n",
    "    print(input_neurons)\n",
    "    # Größe der Feature Maps in der zweiten Schicht\n",
    "    output_size = input_size - kernel_size + 1\n",
    "    print(output_size)\n",
    "\n",
    "    # Anzahl der Neuronen insgesamt in der zweiten Schicht (für alle Feature Maps)\n",
    "    output_neurons = output_size * output_size * num_kernels\n",
    "    print(output_neurons)\n",
    "    # Anzahl der zu lernenden Parameter im vollvernetzten neuronalen Netzwerk\n",
    "    fully_connected_params = input_neurons * output_neurons\n",
    "    print(fully_connected_params)\n",
    "\n",
    "    # Anzahl der zu lernenden Parameter im CNN\n",
    "    cnn_params = kernel_size * kernel_size * num_kernels\n",
    "    print(cnn_params)\n",
    "\n",
    "    return output_neurons, fully_connected_params, cnn_params\n",
    "\n",
    "# Beispielaufruf der Methode\n",
    "input_size = 100\n",
    "num_kernels = 10\n",
    "kernel_size = 5\n",
    "\n",
    "output_neurons, fully_connected_params, cnn_params = calculate_cnn_parameters(input_size, num_kernels, kernel_size)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(\"Anzahl der Neuronen in der zweiten Schicht:\", output_neurons)\n",
    "print(\"Anzahl der zu lernenden Parameter im vollvernetzten neuronalen Netzwerk:\", fully_connected_params)\n",
    "print(\"Anzahl der zu lernenden Parameter im CNN:\", cnn_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2. Padding und Stride <a name=\"5_2_2\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der Ansatz der Faltung durch Matrixoperationen erzeugt eine Feature Map $M_{I∗K}$ aus einer Eingabematrix $M_I$ und einer Kernelmatrix $M_K$. Die **Größe der Feature Map** beträgt $$(n−n′ +1)×(m−m′ +1)$$ wobei n und m relativ groß und n′ und m′ relativ klein sind.\n",
    "- Der Verlust an Auflösung ist bei diesem Ansatz relativ gering, aber es kann wünschenswert sein, die Auflösung zu erhalten oder zu erhöhen.\n",
    "\n",
    "### Padding\n",
    "- Padding-Methoden wie **valides Padding, halbes Padding und vollständiges Padding** können angewendet werden, um die Auflösung zu erhalten und Randpixel besser zu berücksichtigen:\n",
    "  - **Halbes Padding** erweitert die Matrix $M_I$ oben um $⌈\\frac{(n′ − 1)}{2}⌉$ und unten um $⌊(\\frac{(n′ − 1)}{2}⌋$ Zeilen, sowie links um $⌈\\frac{(m′ − 1)}{2}⌉$ und rechts um $⌊\\frac{(m′ − 1)}{2}⌋$ Spalten, um das Format $n×m$ für die Matrix $M_{I*K}$ zu erhalten.\n",
    "\n",
    "  - **Vollständiges Padding** erweitert die Matrix $M_I$ oben und unten um jeweils $n′\n",
    "−1$ Zeilen und rechts und links um jeweils $m′ − 1$ Spalten, um gleiche Anzahlen von Berechnungen für jede Zelle der Matrix $M_{I*K}$ zu gewährleisten (nämlich $m′n′$-oft).\n",
    "      Die resultierende Matrix $M_{I*K}$ hat dann die Dimension $(n+n′ −1)×(m+m′ −1)$.\n",
    "\n",
    "  - **valides Padding** entspricht überhaupt keinem Padding.\n",
    "\n",
    "- Jede dieser Padding-Varianten ist parametrisiert durch die Art, wie die Werte der neuen Zellen bestimmt sind. Dazu gibt es verschiedene Methoden z.B.\n",
    "    - *Zero-Padding*, bei dem alle neuen Zellen den Wert 0 erhalten.\n",
    "    - oder das *Kopieren der Werte aus den Randzeilen und -spalten* und nur die neuen Eckbereiche \n",
    "mit Nullen aufzuü¨llen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride\n",
    "\n",
    "- Der Stride (Schrittweite) einer Faltungsoperation bestimmt, wie weit die Kernelmatrix in jeder Berechnung bewegt wird.\n",
    "    - Bei der normalen Faltungsoperation wird die Matrix $M_K$ bei der Berechnung der einzelnen Zellen von $M_{I*K}$ jeweils um eine Zeile/Spalte in $M_I$ weiterbewegt.\n",
    "    - Ein Stride von $k > 1$ bewegt die Kernelmatrix $M_K$ um k Zeilen und/oder Spalten und führt zu einer kleineren Feature Map $M_{I*K}$.\n",
    "- Üblicherweise wählt man Stride-Werte von 1 oder 2, aber höhere Werte können für ressourcenbeschränkte Aufgaben sinnvoll sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3. Die Pooling-Operation <a name=\"5_2_3\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Das Ergebnis einer Faltungsoperation, MI∗K, wird üblicherweise durch die ReLU-Aktivierungsfunktion hReLU(x) = max{0, x} geleitet, bevor es in einem CNN weitergeleitet wird.\n",
    "- Die ReLU-Funktion wird komponentenweise angewendet und erzeugt eine Matrix MˆI∗K mit identischer Dimension wie MI∗K.\n",
    "- Nach der Anwendung der ReLU-Funktion wird die Matrix in einer Pooling-Schicht weiterverarbeitet, um die Informationen effizienter zu gestalten und redundante Informationen zu entfernen.\n",
    "- Die Pooling-Operation zielt darauf ab, die Auflösung der Ausgabematrix im Vergleich zur Eingabematrix zu reduzieren, indem sie Informationen zusammenfasst.\n",
    "- Eine häufige Form des Poolings ist das Max-Pooling, bei dem über verschiedene Ausschnitte der Eingabematrix gefahren wird und das Maximum berechnet wird.\n",
    "- Typische Parameter für das Max-Pooling sind eine Filtergröße von 2×2 und ein Stride von 2, um eine Invarianz gegenüber kleinen Verschiebungen zu implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4. CNN-Architektur <a name=\"5_2_4\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben nun alle Grundbausteine zusammen, um die Gesamtarchitektur eines CNNs zu diskutieren. Eine einfache typische Beispielarchitektur ist in Abbildung 8 dargestellt.\n",
    "\n",
    "![cnn](cnn.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "- Die Eingabe für das CNN besteht aus einem Farbbild mit 96 × 96 Pixeln. Jeder der Farbkanäle Rot, Grün und Blau hat eine 96 × 96 Pixel große Eingabe.\r\n",
    "- In einem CNN wechseln sich zu Beginn Faltungs- und Poolingschichten ab.\r\n",
    "- Im gegebenen CNN gibt es insgesamt zwei aufeinanderfolgende Faltungs- und Poolingschichten.\r\n",
    "- Es wird halbes Padding verwendet, um die Größe der Eingabe beizubehalten, und der Stride beträgt 1.\r\n",
    "- Die erste Faltungsschicht wendet 4 verschiedene Faltungsoperationen gleichzeitig auf alle drei Eingabematrizen an. Dies resultiert in 12 Feature Maps der Größe 96×96 (entspricht 110592 Neuronen).\r\n",
    "- Anschließend werden alle Werte zunächst durch die ReLU-Funktion und dann an die erste (Max-)Poolingschicht geleitet.\r\n",
    "- Die Poolingschicht hat eine Filtergröße von 2 × 2 und einen Stride von 2. Dies resultiert in derselben Anzahl von Feature Maps (12), die nun aber jeweils eine Größe von 48 × 48 haben.\r\n",
    "- Es folgt eine weitere Faltungsschicht mit 2 verschiedenen Faltungsoperationen. Dies verdoppelt die Anzahl der Feature Maps auf 24, die Auflösung von 48 × 48 bleibt jedoch erhalten (wieder mit halbem Padding und Stride 1).\r\n",
    "- Es folgt eine weitere (Max-)Poolingschicht (inklusive vorgelagerter ReLU-Anwendung) mit Filtergröße 4×4 und Stride 4, dies resultiert in 24 Feature Maps der Größe 12×12 (entspricht insgesamt 3456 Neuronen).\r\n",
    "- Im letzten Teil des CNNs befindet sich ein vollständig vernetztes Feedforward-Netzwerk, das die eigentliche Klassifikationsaufgabe löst (die vorangegangenen Schichten entsprechen prinzipiell nur der Merkmalsextraktion).\r\n",
    "- Es gibt eine Schicht von 12 Neuronen, die mit ihrer Vorgängerschicht und der nachfolgenden Ausgabeschicht voll vernetzt ist.\r\n",
    "- Die Ausgabeschicht in diesem Beispiel ist für die Mehrklassenklassifikation konzipiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  x  96  x  96\n"
     ]
    }
   ],
   "source": [
    "def calculate_output_size(W, F, P, S):\n",
    "    \"\"\"\n",
    "    Berechnet die Ausgabegröße einer Faltungsschicht.\n",
    "\n",
    "    Parameter:\n",
    "    W (int): Die Größe der Eingabe (Breite oder Höhe).\n",
    "    F (int): Die Größe des Filters (Breite oder Höhe).\n",
    "    P (int): Das Padding.\n",
    "    S (int): Der Stride.\n",
    "\n",
    "    Rückgabe:\n",
    "    W_out (int): Die Größe der Ausgabe (Breite oder Höhe).\n",
    "    \"\"\"    \n",
    "    W_out = (W - F + P) // S + 1\n",
    "    return W_out\n",
    "\n",
    "W_out = calculate_output_size(96, 1, 0, 1)\n",
    "print((3*4),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  x  48  x  48\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(96, 2, 0, 2)\n",
    "print((3*4),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24  x  48  x  48\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(48, 1, 0, 1)\n",
    "print((12*2),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24  x  12  x  12\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(48, 4, 0, 4)\n",
    "print((12*2),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Effizienz und Komplexität von CNNs im Vergleich zu vollvernetzten Netzwerken**:\n",
    "   - Realistische CNN-Architekturen umfassen oft zahlreiche Faltungs- und Poolingschichten sowie Schichten im vollvernetzten Teil.\n",
    "   - Trotz dieser Komplexität haben CNNs in der Regel weniger Parameter als vollvernetzte Netzwerke ähnlicher Größe.\n",
    "\n",
    "2. **Gründe für die geringere Parameteranzahl in CNNs**:\n",
    "   - Annahmen zur Nichtlokalität von Merkmalen in Bildern führen zu spezifischen Designentscheidungen für CNNs.\n",
    "   - Im Gegensatz zu vollvernetzten Netzwerken gibt es in CNNs relativ wenige Verbindungen zwischen den Schichten (sparse interaction).\n",
    "   - Jede Faltungsoperation einer Schicht hat eine fixe Anzahl von Parametern, die auf das gesamte Bild angewendet werden (parameter sharing).\n",
    "   - Diese Struktur führt zu einer vergleichsweise geringen Anzahl von Parametern, die während des Trainings angepasst werden müssen.\n",
    "\n",
    "3. **Trainingsprozess von CNNs**:\n",
    "   - Das Lernen der Parameter in CNNs erfolgt ähnlich wie bei Feedforward-Netzwerken unter Verwendung von Algorithmen wie Stochastic Gradient Descent und Backpropagation.\n",
    "   - Es muss darauf geachtet werden, dass die Gewichte von gemeinsam genutzten Kanten während eines Gradient Descent-Schritts nur einmal aktualisiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4. Beispiel <a name=\"5_2_4\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.  11.  -1.]\n",
      " [-16.  15.  17.]\n",
      " [-19.  10.  29.]]\n"
     ]
    }
   ],
   "source": [
    "# Definieren Sie die Matrix MI\n",
    "M_I = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [3, 5, 2, 1, 3],\n",
    "    [5, 7, 10, 2, 7],\n",
    "    [6, 8, 13, 7, 1],\n",
    "    [10, 12, 10, 9, 8],\n",
    "])\n",
    "\n",
    "# Definieren Sie die Matrix MK\n",
    "M_K = np.array([\n",
    "    [1, 0, -1],\n",
    "    [2, 0, -2],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "# Führen Sie die Faltung durch\n",
    "M_J = np.round(convolve(M_I, M_K))\n",
    "print(M_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3. 12.]\n",
      " [ 5.  2.]]\n"
     ]
    }
   ],
   "source": [
    "def max_pooling(M, pool_size, stride):\n",
    "    # Höhe und Breite der Eingabematrix\n",
    "    M_H, M_W = M.shape\n",
    "\n",
    "    # Höhe und Breite der Ausgabematrix\n",
    "    O_H = (M_H - pool_size) // stride + 1\n",
    "    O_W = (M_W - pool_size) // stride + 1\n",
    "\n",
    "    # Initialisieren Sie die Ausgabematrix mit Nullen\n",
    "    output = np.zeros((O_H, O_W))\n",
    "\n",
    "    # Führen Sie das Max-Pooling durch\n",
    "    for i in range(O_H):\n",
    "        for j in range(O_W):\n",
    "            output[i, j] = np.max(M[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size])\n",
    "\n",
    "    return output\n",
    "\n",
    "# Definieren Sie die Matrix M\n",
    "M = np.array([\n",
    "    [1, 3, 4, 10],\n",
    "    [1, 2, 5, 12],\n",
    "    [2, 3, 0, 1],\n",
    "    [4, 5, 2, 1],\n",
    "])\n",
    "\n",
    "# Führen Sie das Max-Pooling durch\n",
    "result = max_pooling(M, 2, 2)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27  x  992  x  992\n"
     ]
    }
   ],
   "source": [
    "def calculate_output_size(W, F, P, S):\n",
    "    \"\"\"\n",
    "    Berechnet die Ausgabegröße einer Faltungsschicht.\n",
    "\n",
    "    Parameter:\n",
    "    W (int): Die Größe der Eingabe (Breite oder Höhe).\n",
    "    F (int): Die Größe des Filters (Breite oder Höhe).\n",
    "    P (int): Das Padding.\n",
    "    S (int): Der Stride.\n",
    "\n",
    "    Rückgabe:\n",
    "    W_out (int): Die Größe der Ausgabe (Breite oder Höhe).\n",
    "    \"\"\"    \n",
    "    W_out = (W - F + P) // S + 1\n",
    "    return W_out\n",
    "\n",
    "W_out = calculate_output_size(994, 3, 0, 1)\n",
    "print((3*9),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27  x  496  x  496\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(992, 3, 2, 2)\n",
    "print((3*9),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189  x  492  x  492\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(496, 5, 0, 1)\n",
    "print((27*7),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189  x  123  x  123\n"
     ]
    }
   ],
   "source": [
    "W_out = calculate_output_size(492, 5, 4, 4)\n",
    "print((27*7),\" x \",W_out, \" x \", W_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"up\"></a>**`[Go Up!^](#up)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sources:\n",
    "\n",
    "(1) Why does Q-Learning use epsilon-greedy during testing?. https://stats.stackexchange.com/questions/270618/why-does-q-learning-use-epsilon-greedy-during-testing.\n",
    "(2) Epsilon-Greedy Q-learning | Baeldung on Computer Science. https://www.baeldung.com/cs/epsilon-greedy-q-learning.\n",
    "(3) Epsilon and learning rate decay in epsilon greedy q learning. https://stackoverflow.com/questions/53198503/epsilon-and-learning-rate-decay-in-epsilon-greedy-q-learning.\n",
    "(4) Exploration in Q learning: Epsilon greedy vs Exploration function. https://datascience.stackexchange.com/questions/94029/exploration-in-q-learning-epsilon-greedy-vs-exploration-function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
