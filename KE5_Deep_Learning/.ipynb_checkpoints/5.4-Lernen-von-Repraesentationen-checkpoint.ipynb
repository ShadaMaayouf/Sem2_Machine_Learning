{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T15:05:33.584082Z",
     "start_time": "2024-01-22T15:05:33.537800Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 5.4 Lernen von Repräsentationen\n",
    ">## <ins>Table of contents</ins> <a name=\"up\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    ">* [**5.4.0. Einleitung**](#5_4_0)\n",
    ">* [**5.4.1 Autoencoder**](#5_4_1)\n",
    ">* [**5.4.2 Generative Adversarial Networks**](#5_4_2)\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.0. Einleitung <a name=\"5_4_0\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "1. **Automatische Merkmalsbestimmung**: Ein großer Vorteil von Deep Learning ist die Fähigkeit, Merkmale automatisch zu bestimmen. Im Gegensatz zu klassischen Ansätzen des maschinellen Lernens, bei denen die Definition der Merkmale eine zentrale Herausforderung darstellt, können tiefe neuronale Netzwerke direkt mit Rohdaten arbeiten und die für das Problem entscheidenden Merkmale selbst während des Lernprozesses bestimmen.\r\n",
    "\r\n",
    "2. **Black Box-Ansätze**: Moderne Deep Learning-Ansätze können weitgehend als Black Box-Ansätze angesehen und angewendet werden, ohne tiefes Expertenwissen im maschinellen Lernen zu besitzen. Dies hat jedoch den Nachteil, dass solche Ansätze im Allgemeinen schwer zu interpretieren sind.\r\n",
    "\r\n",
    "3. **Explainable Artificial Intelligence (XAI)**: Aufgrund der Schwierigkeit, tiefe Netzwerke zu interpretieren, hat sich innerhalb des Forschungsgebiets der Künstlichen Intelligenz eine eigene Bewegung gebildet, die XAI. Diese Bewegung versucht, interpretierbare und erklärliche tiefe Modelle für das maschinelle Lernen zu entwickeln.\r\n",
    "\r\n",
    "4. **Netzwerkarchitekturen**: Der Text erwähnt, dass es einige Netzwerkarchitekturen gibt, die weiteren Nutzen aus der implizit gelernten Repräsentation ziehen. Diese Architekturen werden jedoch nicht im Detail betrachtet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.1. Autoencoder <a name=\"5_3_2\"></a>\n",
    "---\n",
    "\n",
    "> **Definition:** *Autoencoder*\n",
    ">\n",
    "> Ein Autoencoder ist ein Feedforward-Netzwerk, das darauf trainiert wird, die Eingabe zur Ausgabe zu kopieren.\n",
    "\n",
    "\n",
    "1. Ein **Autoencoder** besteht aus drei Komponenten: dem **Kodierer (Encoder)**, dem **Dekodierer (Decoder)** und dem **Flaschenhals (Bottleneck)**.\n",
    "\n",
    "2. Der Kodierer und der Dekodierer sind potentiell mehrschichtige neuronale Netzwerke, die üblicherweise antisymmetrisch aufgebaut sind. Das bedeutet, die Anzahl der Eingabeneuronen $n$ des Kodierers entspricht der Anzahl der Ausgabeneuronen des Dekodierers und umgekehrt.\n",
    "\n",
    "3. Der Flaschenhals besteht aus einer Neuronenschicht, deren Anzahl $\\hat{n}$ üblicherweise geringer ist als die Anzahl der Eingabeneuronen des Kodierers.\n",
    "\n",
    "4. Der Kodierer realisiert eine Funktion $$f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^{\\hat{n}}$$, dessen Ausgabe als Eingabe für die Funktion der Dekodierer $$g : \\mathbb{R}^{\\hat{n}} \\rightarrow \\mathbb{R}^n$$ realisiert. D.h. $$g \\circ f$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gegeben ein Datensatz $D = {x^{(1)}, ..., x^{(m)}}$ mit $x^{(i)} \\in \\mathbb{R}^n$, wird ein Autoencoder darauf trainiert, dass $g \\circ f$ die Identitätsfunktion realisiert, d. h., die Kostenfunktion $L^{auto}$ ist definiert als der quadratische Fehler zwischen dem Abstand von $x \\in D$ und $(g \\circ f)(x)$:\n",
    "\n",
    "$$\n",
    "L_{auto}(D,g \\circ f) = \\sum_{i=1}^{m} ||x^{(i)} -(g \\circ f)(x^{(i)})||^2 \\tag{1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Autoencoder**: Ein Autoencoder besteht aus einem Kodierer und einem Dekodierer, die darauf trainiert werden, eine Eingabe so zu komprimieren, dass sie bestmöglich wieder dekomprimiert werden kann. Die Werte des Flaschenhalses $f(x)$ zu einer Eingabe $x$ nennt man auch den Code von $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Undercomplete und Overcomplete Autoencoder**: Wenn $\\hat{n} < n$, heißt der entsprechende Autoencoder undercomplete. Ein Autoencoder mit $\\hat{n} > n$ heißt overcomplete und kann sinnvoll sein, wenn ein Regularisierungsterm in die Kostenfunktion integriert wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Sparse Autoencoder (SAE)**: Ein SAE ist overcomplete und wird durch Minimierung der Kostenfunktion $$L_{sae}(D,g \\circ f) = L_{auto}(D,g \\circ f)+\\lambda \\sum_{i=1}^{m} ||f(x^{(i)})||$$ trainiert, wobei $\\lambda$ der Regularisierungsparameter ist. SAEs lernen Repräsentationen, die im Flaschenhals nur spärlich besetzt sind, d.h., viele Komponenten in $f(x)$ sind Null oder nahe Null.\n",
    "\n",
    "Eine Variante des SAEs ist der denoising Autoencoder (DAE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Denoising Autoencoder (DAE)**: Ein DAE erhält als Eingabe die verrauschten Daten $\\hat{x}$ und muss das Originaldatum $x$ rekonstruieren. Dies führt dazu, dass der Code $f(x)$ eine nicht-triviale Repräsentation der Verteilung in $D$ darstellt und für Aufgaben wie Klassifikation relevante Merkmale gelernt wurden.\n",
    "\n",
    "5. **Datengenerierung**: Eine weitere wichtige Anwendung von Autoencodern ist die Datengenerierung. Der Dekodierer eines trainierten Autoencoders kann dazu genutzt werden, neue Daten zu generieren, die der Verteilung des Trainingsdatensatzes folgen. Besondere Anwendung findet dies beispielsweise bei der künstlichen Bildgenerierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.2. Generative Adversarial Networks <a name=\"5_4_2\"></a>\n",
    "---\n",
    "\n",
    "1. **Generative Adversarial Networks (GANs)**: Ein GAN besteht aus zwei separaten Feedforward-Netzwerken, dem **Generator** und dem **Diskriminator**. Diese beiden Netzwerke werden simultan trainiert.\n",
    "\n",
    "2. **Generator**: Der Generator nimmt einen relativ niedrig-dimensionalen Vektor zufällig generierter Zahlen als Eingabe und produziert als Ausgabe ein synthetisches Beispiel (z.B. ein Bild).\n",
    "\n",
    "3. **Diskriminator**: Der Diskriminator nimmt als Eingabe ein Beispiel und entscheidet, ob das Beispiel echt ist (d.h., aus dem gegebenen Trainingsdatensatz stammt) oder vom Generator erzeugt wurde.\n",
    "\n",
    "4. **Lernprozess**: Der Lernprozess bei GANs geschieht abwechselnd auf wenigen Beispielen. Die Funktionen $\\Gamma$ und $\\Delta$ werden durch Backpropagation und Gradient Descent auf der Kostenfunktion $L_{\\Delta}(R,S)$ bzw. $L_{\\Gamma}(S')$ minimiert.\n",
    "\n",
    "5. **Aktualisierungsschritte**: Nach der einmaligen Aktualisierung von $$\\Delta$$ wird im nächsten Lernschritt der Generator aktualisiert. Das Ziel des Generators ist es, den Diskriminator zu täuschen. Die beiden Aktualisierungsschritte von Diskriminator und Generator werden abwechselnd durchgeführt, bis eine Konvergenz festgestellt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4. Beispiel <a name=\"5_2_4\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"up\"></a>**`[Go Up!^](#up)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
