{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2d00ab-738b-46ee-8792-941c0332bc32",
   "metadata": {},
   "source": [
    "# Cheatsheet\n",
    ">## <ins>Table of contents</ins> <a name=\"up\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    ">* [**K2. Überwachtes Lernen**](#2)\n",
    "    * [**2.1. Lineare Regression**](#2.1.)\n",
    "    * [**2.2. logistische Regression**](#2.2.)\n",
    "    * [**2.3. SVM**](#2.3.)\n",
    "    * [**2.4. Nächste Nachbaren klassifikation**](#2.4.)\n",
    "    * [**2.5. Bayes klassifikator**](#2.5.)\n",
    "    * [**2.6. Entscheidungsbäume**](#2.6.)\n",
    "\n",
    ">* [**K3. Unüberwachtes Lernen**](#3)\n",
    "    * [**3.1. K-Means-Clustering**](#3.1.)\n",
    "    * [**3.2 Hierarchisches Clustering**](#3.2.)\n",
    "    * [**3.3 Anomalieerkennung**](#3.3.)\n",
    "    * [**3.4. Lineare Regression**](#3.4.)\n",
    "    * [**3.5 Hauptkomponentenanalyse**](#3.5.)\n",
    "\n",
    ">* [**K4. Reinforcement Learning**](#4)\n",
    "    * [**4.1. Markov-Entscheidungsprozess**](#4.1.)\n",
    "    * [**4.2. Passives-Reinforcement-Learning**](#4.2.)\n",
    "    * [**4.3. Aktives-Reinforcement-Learning**](#4.3.)\n",
    "\n",
    ">* [**K5. Deep Learning**](#5)\n",
    "    * [**5.1. Neuronale Netzwerke**](#5.1.)\n",
    "    * [**5.2. CNN**](#5.2.)\n",
    "    * [**5.3. RNN**](#5.3.)\n",
    "    * [**5.4. Lernen von Repräsentation**](#5.4.)\n",
    "\n",
    "\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e81202-6464-4815-8e22-7a7c44149407",
   "metadata": {},
   "source": [
    "# 2 Überwachtes Lernen <a name=2><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bea975-c801-440d-bc50-cab55291db0a",
   "metadata": {},
   "source": [
    "## 2.1. Lineare Regression <a name=2.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137527c9-be80-4b3e-971c-49a4da408a7b",
   "metadata": {},
   "source": [
    "#### Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314fc45-a185-450c-8d88-034851addb9f",
   "metadata": {},
   "source": [
    "- simpleste Form des machinellen Lernens.\n",
    "- Wird als statistische MEthdoe betrachtet.\n",
    "\n",
    "**Problem der linearen Regression:** die optimale Anpassung einer Gerade an einer gegebene Menge von Punkten. \n",
    "\n",
    "Hier besonders $\\longrightarrow$ Anwendung der linearen Regression ür die Funktionsapproximation, d.h. der Vorhersage des Funktionswerts einer Instanz gegeben gewisser Merkmalsausprägungen der Instanzen.\n",
    "\n",
    "<ins>die Aufgabe des zu erlernenden Modells</ins> ist die Vorhersage des Funktionswertes **$y \\in \\mathbb{R}$** zu einem beliebigen Datenpunkt $x \\in \\mathbb{R}^n$. Wir nehmen dazu an, dass die zu suchende Funktion ähnlich zu der Funktion ist, die einen gegebenen Trainingsdatensatz **D** generiert hat. \n",
    "\n",
    "Bei der linearen Regression nehmen wir zusa¨tzlich an, dass der Zusammenhang zwischen x und y (die Zielvariable) **linear** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb587b6c-cf99-4be4-92c9-e354d43aa898",
   "metadata": {},
   "source": [
    "- Ein Datenpunkt $x = (x_1, ...., x_n)^T$ ist ein Punkt $x \\in \\mathbb{R}^n$, wobei n ist die Dimension, $i = 1, ..., n$ ist ein Merkmal/feature und $x_i$ ist die Ausprägung des Merkmals i.\n",
    "- Ein Tupel $(x,y)$ ist ein Beispiel und die Beispielsmenge $D = \\{ (x^1,y^1), .... , (x^m,y^m)\\}$ ist ine Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de1d40-15b6-4dd9-844b-713f2a753b36",
   "metadata": {},
   "source": [
    "Ein lineares Modell $h_{\\theta}$ ist definiert als: $$h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n$$\n",
    "\n",
    "wobei $\\theta = \\theta_0, ..., \\theta_n$ sind die Parameter des Modells $h_{\\theta}$.\n",
    "\n",
    "D.h. wir müssen nun konkrete Werte für die Parameter $\\theta$ zu finden, so dass $h_{\\theta}(x^i) \\approx y^i$. Das kann als ein **Optimierungsproblem** modelliert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d0c3c-1720-4fcd-a090-64992b391ad2",
   "metadata": {},
   "source": [
    "Um das Optimierungsproblem modellieren zu können wählt man zunächst ein geeignetes **Abstandsmaß** (oder Fehlermaß \n",
    "oder Kostenfunktion), das bewertet, wie nah eine Funktion an die Beispiele D angepasst is $\\longrightarrow$  der** quadratische Fehle**.\n",
    "\n",
    "> **Definition 3.** Der quadratische Fehler $L(D,f)$\n",
    ">\n",
    "> Sei D ein Datensatz und $ f : \\mathbb{R}^n → \\mathbb{R} $ eine beliebige Funktion. \n",
    "Der quadratische Fehler L von f bzgl. D ist definiert durch\n",
    "$$L(D, f) = \\sum_{i=1}^m (f(x^{(i)})−y^{(i)})^2$$\n",
    "Ist $f = h_θ$ eine lineare Funktion $$ hθ $$ mit Parametern θ, so ist dies äquivalent zu\n",
    "$$L(D, f) = \\lVert X_D θ - y_D \\rVert ^2$$\n",
    "wobei $\\lVert . \\rVert$ die Euklidische Norm ist.r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fafcdc-d5b4-46c8-bf3d-574306087712",
   "metadata": {},
   "source": [
    "- Damit $h_θ$ die Beispiele in $D$ bestmöglich approximiert, suchen wir Parameter $θ$, die den quadratischen Fehler $L$ bzgl. $D$ **minimieren**, d h., wir suchen eine Lösung für das folgende Optimierungsproblem:\n",
    "$$min_θ L(D,θ) = min_θ \\lVert X_D θ - y_D \\rVert ^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eff6da-6eb0-49e5-8f17-89cb141b5c22",
   "metadata": {},
   "source": [
    "- Für lineare Regression ist das obige Optimierungsproblem stets **eindeutig lösbar**, d.h., <ins>ein lokales Minimum ist stets das globale Minimum</ins>.\n",
    "\n",
    "- Eine geeignite Methode ist **Gradient Descent**, besonders bei <ins>großen Trainingsdatensätzen</ins> oder <ins>viele MErkmale</ins>.\n",
    "\n",
    "- Gerade bei **großen** Werten für m und n ist die Verwendung von **numerischen Optimierungsmethoden** (wie Gradient Descent) zu bevorzugen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0ea8b-c068-4630-9353-34c9bbbcae51",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c7595-4b24-4d2b-8d82-0a5a3be37bfc",
   "metadata": {},
   "source": [
    "\n",
    "Die Evaluation ist die Analyse und Feststellung, wie gut eine bestimmte Methode ein spezifisches Problem löst --> und somit die beste Methode wählen.\n",
    "\n",
    "**Schritte der Evaluation:**\n",
    "→ Aufteilung der Daten in:\n",
    "- einen **Trainingsdatensatz**, der verwendet wird, um das Modell zu trainieren.\n",
    "- und einen **Testdatensatz** der dazu dient, die Leistung des Modells auf neuen, zuvor ungesehenen Daten zu bewerten. Dies gibt uns eine Vorstellung davon, wie gut das gelernte Modell auf zuvor ungesehenen Daten generalisiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349e7f2-3924-4643-b545-d88ea21f7906",
   "metadata": {},
   "source": [
    "Den **Evaluationsmaß**, den wir hier verwenden ist das **Bestimmtheitsmaß**, auch bekannt als **R<sup>2</sup>-Wert**\n",
    "- Es ist eine normalisierte Variante des quadratischen Fehlers.\n",
    "- gibt an, welcher Anteil der Varianz in den abhängigen Variablen durch das Modell erklärt wird.\n",
    "\n",
    "Sei $D = {(x^1, y^1),...,(x^m, y^m)}$ ein Datensatz und $f : \\mathbb{R}^n → \\mathbb{R}$ eine beliebige Funktion. Das **Bestimmtheitsmaß R<sup>2</sup>-Wert** von f bzgl. D ist definiert durch\n",
    "$$ R^2(D, f) = (1− \\frac{L(D,f)}{\\sum_{i=1}^m (y^{(i)}− \\tilde{y})^2}) = (1− \\frac{\\sum_{i=1}^m (f(x^{(i)})− y^{(i)})^2}{\\sum_{i=1}^m (y^{(i)}− \\tilde{y})^2})$$\n",
    "\n",
    "wobei der Mittelwert von $y^i$ ist:\n",
    "$$ \\tilde{y} = \\frac{1}{m} \\sum_{i=1}^m y^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831f0e4-fbe6-4ef9-a87a-a972aa342b62",
   "metadata": {},
   "source": [
    "- Der Wert $R^2(D,f)$ kann maximal 1 betragen.\n",
    "- Je kleiner der Wert $R^2(D,f)$, desto schlechter die Vorhersagequalität von f bezüglich D ist.\n",
    "- **$R^2$-Wert = 1** $\\longrightarrow$  das Modell erklärt die Daten perfekt, d.h. $f(x^i) = y^i$ \n",
    "- **$R^2$-Wert = 0** $\\longrightarrow$ das Modell erklärt die Daten nicht besser als ein einfaches Modell, das nur den Durchschnitt der Daten verwendet D.h. ein naives Modell $f_{naive}$, dass stets den Mittelwert $\\tilde{y}$ vorhersagen würde, hätten wir $R^2(D,f_{naive}) = 0$.\n",
    "-  bei Überanpassung ist der **$R^2$-Wert** für die **Trainingsdaten** **$R^2(D_{train})$-Wert** relativ hoch, da das Modell die Trainingsdaten sehr genau lernt, während **$R^2(D_{test})$** ist **niedrig** $\\longrightarrow$ Abstand zwischen **$R^2(D_{train})$** und **$R^2(D_{test})$** ist **groß**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575e86c-05a1-4f1b-9147-6602bb1e4714",
   "metadata": {},
   "source": [
    "- Dieses Problem der variierenden Abstände zwischen Bestimmtheit der Trainings- und Testdaten zu adressieren, benutzt man oft die sogenannte **Kreuzvalidierung (engl. cross validation)**.\n",
    "\n",
    "- Die grundlegende Idee der Kreuzvalidierung besteht darin, die ursprünglichen Daten in ungefähr gleichgroße zwei Teile zu teilen: einen Trainingsdatensatz und einen Validierungsdatensatz. Das Modell wird auf dem Trainingsdatensatz trainiert und dann auf dem Validierungsdatensatz getestet. Dieser Prozess wird mehrmals wiederholt, wobei verschiedene Teile der Daten als Trainings- und Validierungsdatensatz verwendet werden. Am Ende wird der Durchschnitt der Modellleistung über alle Durchläufe berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff99e3f-52f7-427d-b33e-42ff6a89fc7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Nichtlineare Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb108d7-23cf-4523-b3fb-37b068aeba49",
   "metadata": {},
   "source": [
    "- Lineare Regression ist durch die Linearitätsannahme in ihrer Anwendbarkeit eingeschränkt.\n",
    "\n",
    "- Die Einbeziehung nichtlinearer Zusammenhänge zwischen Merkmalen und der Zielvariablen kann bei der linearen\n",
    "Regression realisiert werden, indem in einem Vorbereitungsschritt die Beispiele um zuä¨tzliche (nichtlineare) Merk\u0002male erännzt werden, die aus den schon existierenden Merkmalen berechnet werde $\\longrightarrow$ Polynomiale Regression.\n",
    "\n",
    "Polynomiale Regression kann verwendet werden, um komplexere, nichtlineare Beziehungen zwischen Variablen zu modellieren, die nicht durch lineare Regression erfasst werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484070b-7484-4f1f-85e6-a345e3b05211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Über und Unteranpassung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5920bad-cb49-47c5-85db-d13aff0611c4",
   "metadata": {},
   "source": [
    "**Warum nimmt man statt eines linearen Modells nicht direkt ein maximal komplexes Modell , das damit auch beliebig genau an den Trainingsdatensatz angepasst werden kann?**\n",
    "\n",
    "Es gibt mehrere Gründe:\n",
    "* Zuna¨chst ergeben sich dadurch **ressourcenspezifische Probleme**, da das Lernen unter Umständen signifikant mehr Zeit benötigt.\n",
    "* **Überanpassung** (engl. overfitting), tritt auf, wenn ein Modell die Trainingsdaten zu gut lernt und dabei auch das Rauschen in den Daten erfasst. Dies führt dazu, dass das Modell auf den Trainingsdaten sehr gut, aber auf den Testdaten schlecht abschneidet. d. h., das gelernte Modell ist aufgrund seiner Komplexität so stark an die Trainingsdaten angepasst, dass es nicht mehr gut auf ungesehene Daten generalisiert.\n",
    "* **Unteranpassung** (engl. Underfitting) tritt auf, wenn ein Modell nicht genügend Muster aus den Daten lernt. Dies führt dazu, dass das Modell sowohl auf den Trainingsdaten als auch auf den Testdaten schlecht abschneidet. In anderen Worten: ein zu einfaches, nicht-ausdrucksstarkes Modell kann sowohl die Trainings- als auch die Testdaten nicht ausreichend gut modellieren, was zu schlechten Vorhersagen führt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca88f0-2eee-4a2d-8b04-abd3947acb64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Die Verzerrung-Varianz-Dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21dd9b-082a-40e9-8326-efbfc69da234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- **Verzerrungsfehler (Bias Error)**: Dieser Fehler entsteht, wenn ein Modell zu einfache Annahmen über die Datenstruktur trifft. Ein Modell mit hohem Bias neigt dazu, die Daten zu \"unterschätzen\", was bedeutet, dass es die Komplexität der Daten nicht vollständig erfasst. Dies führt zu einer schlechten Leistung sowohl auf den Trainings- als auch auf den Testdaten, ein Phänomen, das als \"Unteranpassung\" (Underfitting) bezeichnet wird.\n",
    "\n",
    "- **Varianzfehler (Variance Error)**: Dieser Fehler entsteht, wenn ein Modell zu komplexe Annahmen über die Datenstruktur trifft. Ein Modell mit hoher Varianz \"überinterpretiert\" die Daten, indem es auch das Rauschen oder die zufälligen Schwankungen in den Trainingsdaten lernt. Dies führt zu einer guten Leistung auf den Trainingsdaten, aber zu einer schlechten Leistung auf den Testdaten, ein Phänomen, das als \"Überanpassung\" (Overfitting) bezeichnet wird.\n",
    "\n",
    "Das Ziel ist es, ein Gleichgewicht zwischen **Verzerrung** und **Varianz** zu finden, um ein Modell zu erhalten, das weder unterangepasst noch überangepasst ist. Es hilft, die Verläufe der Kostenfunktionswerte (oder des Bestimmtheitsmaßes) bei Trainings- und Testdaten mit steigender Modellkomplexität zu betrachten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193c97b-5fb3-4383-9980-31bbb1d91ab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Bei Trainingsdaten:**\n",
    "- nimmt die Bestimmtheit eines Modells mit steigender Komplexität auf den Trainingsdaten zu.\n",
    "- **Das bedeutet -->** je ausdrucksstärker das Modell ist (d.h., je mehr es in der Lage ist, komplexe Muster in den Daten zu erfassen), desto besser wird es an die Trainingsdaten angepasst.\n",
    "\n",
    "**Bei Testdaten** ist der Verlauf etwas komplexer:\n",
    "- Weil ein komplexeres Modell in der Lage ist, die zugrunde liegenden Muster in den Daten besser zu erfassen, nimmt die Bestimmtheit zunächst zu: solange das Modell unteranpasst ist, können weder Trainings- noch Testdaten gut modelliert werden, aber je näher man an das ”korrekte“ Modell kommt, desto besser werden insbesondere auch die Vorhersagen auf den Testdaten.\n",
    "- Steigt die Modellkomplexität aber weiter, kann das Modell beginnen, das Rauschen in den Trainingsdaten zu lernen, so wird das Modell überangepasst und die Vorhersagequalität auf den Testdaten sinkt wieder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0df669-ac82-44f1-b1a0-248d27e03966",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Aber was ist den die optimale Modellkomplexität?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a50c1-812c-42f6-b731-bb8e8cec0449",
   "metadata": {},
   "source": [
    "Im Grunde liegt die optimale Modellkomplexität <ins>am Scheitelpunkt der Kurve der Testdaten.</ins> An diesem Punkt ist die Bestimmtheit (ein Maß für die Anpassungsgüte des Modells) sowohl bei den Trainings- als auch bei den Testdaten relativ hoch, was darauf hindeutet, dass das Modell gut auf neue, unbekannte Daten generalisiert.\n",
    "\n",
    ">Modelle, deren Komplexität links von diesem Punkt liegt, sind unterangepasst.\n",
    "\n",
    ">Modelle, die rechts von diesem Punkt liegen, überangepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ff47b-5991-49be-9e9f-a5fe90bab2a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Regularisierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62653a-36e2-4ef2-8bf7-930e73397f6f",
   "metadata": {},
   "source": [
    "Regularisierung ist eine Technik, die verwendet wird, um das Verzerrung-Varianz-Dilemma zu lösen bzw. um Überanpassung zu verhindern, indem eine Strafterm zur Verlustfunktion hinzugefügt wird, um:\n",
    "- die Komplexität des Modells zu begrenzen\n",
    "- und somit Overfitting zu verhindern\n",
    "\n",
    "$\\longrightarrow$ das Modell optimieren.\n",
    "\n",
    "Es gibt verschiedene Arten von Regularisierungstechniken wie z.B.:\n",
    "- L1-Regularisierung (Lasso),\n",
    "- L2-Regularisierung (Ridge)\n",
    "- und Elastic Net, die eine Kombination aus L1 und L2 ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdba2a6-93c0-4543-bcc9-c2a0ffe0d5a5",
   "metadata": {},
   "source": [
    "Die mit *R* und *λ* **regularisierte Kostenfunktion** ist $$L_{R,λ} (D, f) = L(D, f) + λR(f)$$\n",
    "\n",
    "Es besteht aus zwei Teilen:\n",
    "- **dem ursprünglichen Verlust L(D,f)**: misst, wie gut das Modell die Trainingsdaten anpasst.\n",
    "- **dem Regularisierungsterm λR(f)**: verhindert, dass das Modell zu komplex wird und overfittet.\n",
    "\n",
    "Die Funktion **R(f)** ist der **Regularisierer**, misst die Komplexität des Modells f, dabei bestimmt der **Regularisierungsparameter λ** das Ausmaß der Regularisierung.\n",
    "\n",
    "λ muss > 0 sein.\n",
    "\n",
    "Ein höherer Wert von **Der Regularisierungsparameter λ** bedeutet mehr Regularisierung und ein einfacheres Modell, während ein niedrigerer Wert von **λ** weniger Regularisierung und ein komplexeres Modell bedeutet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0d1bc-352a-4853-81ae-57ffe0dca82f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Ridge-Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750b9a6-f478-4523-b7d3-a101caf84a5b",
   "metadata": {},
   "source": [
    "Die lineare Regression mit Kostenfunktion **L<sub>T</sub>** nennt man allgemein auch **Ridge-Regression** (engl. ridge regression). \n",
    "Die regularisierte Kostenfunktion\n",
    "$$L_T(D,\\theta) = \\lVert X D\\theta - y D\\rVert ^2 + \\lambda \\sum_{i=1}^{n} \\theta_i^2 $$\n",
    "besteht aus der Kostenfunktion $$ L(D,θ)=∥XDθ−yD∥^2 $$ und dem **Tikhonov-Regularisierer** $$ R_T​(θ_1​, … ,θ_n​) = \\sum_{i=1}^{n} \\theta_i^2 $$ der **Tikhonov-Regularisierer** ist eine Technik zur Vermeidung von Überanpassung, indem es eine Strafe für große Werte der Parameter **θ<sub>i</sub>** eingeführt wird.\n",
    "\n",
    "Der Parameter **λ** bestimmt, wie stark die Regularisierung ist. Ein größerer Wert von **λ** führt zu stärkerer Regularisierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82665368-db9f-4ddc-a99b-65428653a9b1",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2. Logistische Regression <a name=2.2.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8436ee-4638-407b-b47f-e5094a1afc98",
   "metadata": {},
   "source": [
    "### Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9c785-8723-45ee-bf8f-9fe6f1f50b0b",
   "metadata": {},
   "source": [
    "- Ist ein Klaasifikationsproblem.\n",
    "- **Prinzip :**\n",
    "    - Ähnlich zur lineare Regression.\n",
    "    - Wir haben ein Trainingsdatensatz mit einer gegebene Menge von Punkten als Eingabe und wir müssen eine Funktion $f$ erlernen, wobei $f(x^i) = y^i$, um die optimale Anpassung einer Gerade an der Punktemenge zu ermöglichen.\n",
    "    - **Aber!** der Wertebereich der Zielvariablen $y^i$ ist <ins>diskret</ins>, üblicherweise sogar <ins>endlich</isn>, und oft auch <isn>binär ($y^i ∈ \\{0,1\\}$)</isn>.\n",
    "- **Ziel der Klassifikation** ist es einen Datenpunkt einer bestimmten Klasse zuzuweisen.\n",
    "\n",
    "-  Die logistischen Regression ist ein Modell zur <ins>binären Klassifikation</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe2191-2d47-4abe-be28-a2aad80d7e86",
   "metadata": {},
   "source": [
    "\n",
    "1. **Klassifikationsprobleme**:\n",
    "   - Die Ausgabevariable besteht aus diskreten Kategorien oder Klassen.\n",
    "   - Die Vorhersage zielt darauf ab, die Klasse oder Kategorie zu bestimmen, zu der eine neue Beobachtung gehört.\n",
    "   - Die Klassen haben in der Regel keine (eindeutige) Ordnung. Zum Beispiel können Klassen wie \"Auto\", \"Flugzeug\" und \"Schiff\" sein, die keine natürliche Reihenfolge haben.\n",
    "   - Ein klassisches Beispiel ist die binäre Klassifikation, bei der die Beobachtungen in zwei Kategorien unterteilt werden, wie z.B. \"positiv\" und \"negativ\".\n",
    "\n",
    "2. **Regressionsprobleme**:\n",
    "   - Die Ausgabevariable ist kontinuierlich und nimmt einen beliebigen Wert innerhalb eines bestimmten Bereichs an.\n",
    "   - Die Vorhersage zielt darauf ab, den numerischen Wert der Ausgabevariable für eine neue Beobachtung vorherzusagen.\n",
    "   - Die Werte haben eine natürliche Ordnung. Zum Beispiel könnten sie reale Zahlen wie Größen, Gewichte, Preise usw. sein.\n",
    "   - Ein klassisches Beispiel ist die Vorhersage des Preises eines Hauses basierend auf seinen Eigenschaften wie GrößeOrdnung haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835a986-bc2e-4f43-af3f-716254947033",
   "metadata": {},
   "source": [
    "Es gibt 2 Arten von Klassifikationsproblemen:\n",
    "- **Binäre** Klassifizierung\n",
    "- **Mehrklassen**-Klassifizierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48908e-e494-42e1-aecd-6d61390e24e5",
   "metadata": {},
   "source": [
    "#### Sigmoid Funktion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1268e0-7e77-4a26-8e9a-1527f9692588",
   "metadata": {},
   "source": [
    "Das Modell der logistischen Regression verwendet die **Sigmoid-Funktion** (oder Logit-Funktion), die eine kontinuierliche Eingabe nimmt und sie in einen Ausgabewert zwischen 0 und 1 umwandelt, diese wird dann mit dem **Schwellenwert 0,5** verglichen. Dieser Ausgabewert kann als die Wahrscheinlichkeit interpretiert werden, dass eine gegebene Eingabe zu einer bestimmten Klasse gehört.\n",
    "\n",
    " \n",
    "Sei $θ ∈ \\mathbb{R}^{n+1}$. Die Sigmoid-Funktion $h_{logit}^θ$ auf $f : \\mathbb{R}^n \\rightarrow \\{0,1\\}$ ist ein (binärer) **Klassifikator**, dann ist die Funktion $h_{\\text{logit}}^{\\theta} : \\mathbb{R}^{n} \\rightarrow (0,1)$ mit\n",
    "$$\n",
    "h_{\\text{logit}}^{\\theta}(x) = \\frac{1}{1+e^{-(\\theta_{0}+\\theta_{1}x_{1}+...+\\theta_{n}x_{n})}}\n",
    "$$\n",
    "\n",
    "D.h. folgendes passiert:\n",
    "1. wir setzen einen linearen Modell $h_{\\theta}$ in die Funktion $g(z) = \\frac{1}{1+ e^{-z}}$\n",
    "2. dann wir vergleichen das Ergebnis von $g(z)$ mit dem SChwellenwert 0.5 für eine beliebige Funktion $clf_f$ definiert als: $$\n",
    "clf_f(x) = \n",
    "\\begin{cases} \n",
    "1 & \\text{falls } f(x) \\geq 0.5, \\\\\n",
    "0 & \\text{falls } f(x) < 0.5.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7afd0b-36c6-448e-b9c0-f116e86a2963",
   "metadata": {},
   "source": [
    "#### Die logistische Kostenfunktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a426b02-aca7-4261-98aa-0ec8e9aa9dd0",
   "metadata": {},
   "source": [
    "$$\n",
    "L_{\\text{logit}}(D, f) = -\\sum_{i=1}^{m} y(i) \\ln f(x(i)) + (1-y(i)) \\ln(1- f(x(i)))\n",
    "$$\n",
    "\n",
    "Wir suchen ein Parameter θ, so dass $h^{logit}_{\\theta}$ optimal an den Trainingsdatensatz D angepasst ist, d.h. wir suchen eine Lösung für das folgende Optimierungsproblem:\n",
    "$$ min_θ L_{logit}(D,h^θ_{logit}) \\tag(1)$$\n",
    "\n",
    "- Das Optimierungsproblem (1) ist **konvex**, d. h., es verfügt über einer eindeutige Lösung.\n",
    "- Mithilfe numerischer Methoden wie Gradient Descent kann es auch effizient gelöst werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1bc1b-bdb9-4b8c-a220-7432b42c4cad",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f88e59-ebee-4255-a7f5-babc12cc548c",
   "metadata": {},
   "source": [
    "\n",
    "**Schritte der Evaluation:**\n",
    "→ Aufteilung der Daten in:\n",
    "- einen **Trainingsdatensatz**, der verwendet wird, um das Modell für den Klassifikator clf zu trainieren.\n",
    "- und einen **Testdatensatz** der dazu dient, die Leistung des Modells auf neuen, zuvor ungesehenen Daten zu bewerten. Dies gibt uns eine Vorstellung davon, wie gut das gelernte Modell auf zuvor ungesehenen Daten generalisiert.\n",
    "\n",
    "**Evaluationsmaß**\n",
    "- <ins>Die Genauigkeit (accuracy)</ins>:\n",
    "    - Verhältnis der **richtig klassifizierten Instanzen** (sowohl positiv als auch negativ) zur Gesamtzahl der **Instanzen**. Eine gute Maßzahl für die Gesamtgenauigkeit des Klassifikators.\n",
    "    - **Nachteil**: Es kann bei ungleicher Klassenrepräsentation eine falsche Einschätzung\n",
    "der Qualität eines Klassifikators liefern.\n",
    "\n",
    "Deshalb $\\longrightarrow$ **Konfusionsmatrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185445b-aa1f-40e4-ac93-47fd1072c560",
   "metadata": {},
   "source": [
    "#### Konfusionsmatrix (engl. confusion matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d0dde-3103-4d95-97d9-e331f617ec6e",
   "metadata": {},
   "source": [
    "Die Konfusionsmatrix ist ein nützliches Werkzeug, um die Leistung eines Klassifikators zu bewerten, da sie nicht nur die Gesamtgenauigkeit, sondern auch andere Metriken wie <ins>Sensitivität (auch als Recall oder True Positive Rate bekannt), Spezifität, Präzision und F1-Score</ins> berücksichtigt.\n",
    "- insbesondere hilfreich in Szenarien <ins>mit ungleicher Klassenverteilung</ins>. \n",
    "\n",
    "Die Konfusionsmatrix für ein binäres Klassifikationsproblem sieht folgendermaßen aus:\n",
    "\n",
    "| | Vorhersage: Positiv clf=1 | Vorhersage: Negativ clf=0 |\n",
    "|---|---|---|\n",
    "| **Tatsächlich: Positiv** y=1 | True Positive TP(D,clf) | False Negative FN(D,clf) |\n",
    "| **Tatsächlich: Negativ** y=0 | False Positive FP(D,clf) | True Negative TN(D,clf) |\n",
    "\n",
    "\n",
    "wobei:\n",
    "- True Positives (TP): $$TP(D, clf) = |\\{i | y(i) = 1, clf(x(i)) = 1\\}|$$\n",
    "- True Negatives (TN): $$TN(D, clf) = |\\{i | y(i) = 0, clf(x(i)) = 0\\}|$$\n",
    "- False Positives (FP): $$FP(D, clf) = |\\{i | y(i) = 0, clf(x(i)) = 1\\}|$$\n",
    "- False Negatives (FN): $$FN(D, clf) = |\\{i | y(i) = 1, clf(x(i)) = 0\\}|$$\n",
    "\n",
    "in python these values have th following order:\n",
    "| |  |  |\n",
    "|---|---|---|\n",
    "|  | True Negatives **TN** | False Positives **FP** |\n",
    "|  | False Negatives **FN** | True Positives **TP** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d3f90-fe51-4b90-875d-6e04deb097ed",
   "metadata": {},
   "source": [
    "Mit diesen Werten können wir dann verschiedene Metriken berechnen:\n",
    "\n",
    "\n",
    "| Metrik        | Definition  |  Formel  | \n",
    "|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|\n",
    "| **Genauigkeit (Accuracy)**   | Verhältnis der **richtig klassifizierten Instanzen** (sowohl positiv als auch negativ) zur Gesamtzahl der **Instanzen**. Eine gute Maßzahl für die Gesamtgenauigkeit des Klassifikators.                     | $$\\frac{TP + TN}{TP + TN + FP + FN}$$ |\n",
    "| **Sensitivität (Recall)** | Verhältnis der **richtig positiven Vorhersagen** zur Gesamtzahl der **tatsächlich positiven Instanzen**. Es ist eine gute Kennzahl, wenn die Kosten eines falsch negativen Ergebnisses hoch sind.                   | $$rec(D, clf)  = \\frac{TP}{TP + FN}$$|\n",
    "| **Präzision**     | Verhältnis der **richtig positiven Vorhersagen** zur Gesamtzahl der **positiven Vorhersagen**. Es ist eine gute Kennzahl, wenn die Kosten eines falsch positiven Ergebnisses hoch sind.                    | $$prec(D, clf)  = \\frac{TP}{TP + FP}$$ |\n",
    "| **F1-Maß**| Harmonisches Mittel aus Präzision und Recall. Üblicherweise als geeignetes Maß für die Gesamtqualität eines Klassifikators betrachtet.                                                                                                      | $$F1(D, clf)  = 2 \\cdot \\frac{Präzision \\cdot Recall}{Präzision + Recall}$$ |\n",
    "\n",
    "Eine weitere Metrik die nicht in der Konfusionsmatrix berücksichtigt wird ist die **Spezifität**: Spezifität ist das Verhältnis der korrekt als negativ identifizierten Instanzen zur Gesamtzahl der tatsächlich negativen Instanzen. Mit anderen Worten, die Spezifität misst, wie gut der Klassifikator in der Lage ist, nicht positive Instanzen korrekt zu klassifizieren. $$\\frac{TN}{TN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b9fd2-9158-4809-af24-55eefc8e45e4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3. SVM <a name=2.3.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13c7b9-4bfc-46f2-b037-0ea285e537dc",
   "metadata": {},
   "source": [
    "- **Support Vector Machine (SVM)** ist ein häufig verwendete Methode zur Klassifikation.\n",
    "- Die Kernidee von SVMs ist die Bestimmung einer Hyperebene im Merkmalsraum, die die Beispiele der verschiedenen Klassen voneinander trenn>\n",
    "- Im 2-dimensionalen Raum sind Hyperebenen einfache Geraden.\n",
    "- Bei der logistischen Regression werden die Klassifikationsgrenzen nur **implizit** berechnet und der Lernalgorithmus basiert auf der Minimierung der logistischen Kostenfun on.\n",
    "- Im Gegensatz dazu wird bei der SVM die Klassifikationsgrenze **explizit** gelernt.\n",
    "- Bei binärer Klassifikation wird die Hyperebene gesucht, die die beiden Klassen voneinander trennt und dabei den größtmöglichen Abstand zu den Beispielen der beiden Klassen hat.\n",
    "\n",
    "Die **Hyperebene** definiert durch die Gleichung: $$h^{SVM}_{\\theta,b} : \\theta^T x - b = 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a4c3c-220b-41fa-9e07-28294e004c96",
   "metadata": {},
   "source": [
    "Die Klassifikationsfunktion $clf_{\\theta,b}(x)$ ist also wie folgt definiert:\n",
    "\n",
    "$$\n",
    "clf_{\\theta,b}(x) = \\begin{cases}\n",
    "   1 &\\text{falls } \\theta^T x - b ≥ 0 \\\\\n",
    "   0 &\\text{falls } \\theta^T x - b < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Wie zuvor besteht die Lernaufgabe nun darin, die Parameter θ und b so zu ermitteln, dass $h^{SVM}_{\\theta,b}$ (bzw. $clf_{\\theta,b}$) einen gegebenen Datensatz gut erklärt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd421f4e-1c43-480a-88bd-d3e8d905ad8b",
   "metadata": {},
   "source": [
    "### linear-separierbare Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244ff97-c74f-476d-8617-404a99841220",
   "metadata": {},
   "source": [
    "\n",
    "- Wir nehmen zunächst immer an dass die Klassen **linear separierbar** sind, d.h. Es gibt eine Hyperebene, die die Klassen voneinander trennen kann (also **kein Beispiel fehlklassifiziert wird**).\n",
    "- Wenn bei einem binären Klassifikationsproblem die beiden Klassen vollständig durch eine Hyperebene getrennt werden können (d. h. wenn kein Beispiel falsch klassifiziert wird), sind die gegebenen Daten linear separierbar.\n",
    "\n",
    "##### **Hard-Margin** SVM für linear separierbare Daten\n",
    "\n",
    "Die optimalen Parameter $\\theta$ und $b$ werden durch die Lösung des gegebenen Minimierungsproblems bestimmt:\n",
    "$$\\| \\theta \\|$$\n",
    " $$\\text{so dass} \\quad y(\\theta^T x - b) \\geq 1 \\quad \\text{für alle} \\quad (x,1) \\in D \\tag{3}$$ \n",
    "\n",
    ">Bei einer Hard-margin-SVM wird $y(\\theta^T x - b) \\geq 1$ für alle (x,y)∈ D **strikt** gefordert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e0d02-955f-4319-ab12-ac08b536b535",
   "metadata": {},
   "source": [
    "Die optimal angepasste Hyperebene $h_0$ ist definiert durch:\n",
    "\n",
    "$$h_0 = h_{\\text{SVM}}^{\\theta,b} : \\theta^T x - b = 0$$\n",
    "\n",
    "Weiterhin dargestellt sind zwei zu $h_0$ parallele Hyperebenen $h_1$ und $h_{-1}$, die definiert sind durch:\n",
    "\n",
    "$$h_1 : \\theta^T x - b = 1$$\n",
    "$$h_{-1} : \\theta^T x - b = -1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0806b84-7d75-4320-bd7e-45724295e793",
   "metadata": {},
   "source": [
    "**Wichtig**\n",
    "- der Abstand von $h_0$ zum Ursprung ist genau $\\frac{b}{\\|\\theta\\|}$\n",
    "- der Abstand von $h_1$ und $h_{-1}$ zu $h_0$  ist genau $\\frac{1}{\\|\\theta\\|}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53448f55-0041-44d2-9216-649efeacfac2",
   "metadata": {},
   "source": [
    "Ein **Stützvektor** ist ein Datenpunkt, der genau auf den Hyperebenen $h_1$ und $h_{-1}$ liegt und die Lösung des Optimierungsproblems in einer Support Vector Machine bestimmt. \n",
    "bzw. Die Stützvektoren sind Datenpunkte, die auf Hyperebenen liegen, die parallel zur optimal separierenden Hyperebene liegen.\n",
    "\n",
    "Der **Normalenvektor** ist der Parameter $\\theta$ und ist ein Vektor, der senkrecht auf den Hyperebenen $h_0$, $h_1$ und $h_{-1}$ steht und deren Orientierung bestimmt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc232ed0-8d21-40c8-a9dc-1bca86f62f48",
   "metadata": {},
   "source": [
    "### Nicht-linear-separierbare Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae3284-8b60-49a8-8820-53e83c5300dd",
   "metadata": {},
   "source": [
    "##### Die Hinge Kostenfunktion:\n",
    "\n",
    "$$\n",
    "L_{\\text{hinge}}(D, f) = \\sum_{i=1}^{m} \\max\\{0, 1 - y^{(i)}f(x^{(i)})\\}\n",
    "$$\n",
    "\n",
    "Versucht man, eine lineare hard-margin-SVM auf nicht linear separierbaren Daten zu trainieren, besitzt das zugehörige Optimierungsproblem keine zulässige Lösung und die SVM bleibt undefiniert.\n",
    "\n",
    "$\\longrightarrow$ Wir wenden die Hinge-Kostenfunktion auf lineare SVMs an, indem wir sie in die Zielfunktion des Optimierungs\u0002problems (3) aufnehmen (und dafür die harten Nebenbedingungen weglassen) und fügen ein Regularisierungsparameter $C$ ein.\n",
    "\n",
    "##### **Soft-Margin** SVM für Nicht-linear separierbare Daten\n",
    "Für einen gegebenen Datensatz D sind die optimalen Parameter θ und b durch die Lösung des folgenden Minimierungsproblems bestimmt:\n",
    "\n",
    "$$\n",
    "\\min C \\|\\theta\\|^2 + \\frac{1}{m} \\sum_{i=1}^{m} \\max\\{0, 1 - y^{(i)} (\\theta^T x^{(i)} - b)\\}\n",
    "$$\n",
    "wobei Der Term $C \\|\\theta\\|^2$ ist identisch zum Tikhonov-Regularisierer.\n",
    "\n",
    ">Bei einer soft-margin-SVM wird $y(\\theta^T x - b) \\geq 1$\n",
    " für alle (x,y) ∈\n",
    "**\n",
    " nicht stri**kt gefordert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0cc23-cb9b-4dff-b1e0-1126fa75c2fd",
   "metadata": {},
   "source": [
    "### Kernelfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895139e-bf12-49b5-b8f7-a271fae6a676",
   "metadata": {},
   "source": [
    "Bei SVMs können wir einen Trick (den sogenannten **Kernel-Trick**) anwenden <ins>anstelle</ins> der expliziten Merkmalserweiterung.\n",
    "\n",
    "Eine Kernelfunktion $k_{\\phi}$ realisiert das Skalarprodukt im $R^{n'}$:\n",
    "\n",
    "$$\n",
    "k_{\\phi} (x, x') = \\phi(x)^T \\phi(x') = (x^T,x')^2\n",
    "$$\n",
    "wobei $x$ und $x'$ sind verktoren. und $\\phi$ eine beliebgie Funktion ist (Üblicherweise eine Transformation des Merkmalsraums in einen höherdimensionalen Merkmalsraum).\n",
    "\n",
    "Weitere gebräuchliche Kernel-Funktionen wie folgt dargestellt:\n",
    "\n",
    "1. **Homogener polynomieller Kernel zu Grad d > 0:**\n",
    "\n",
    "    Der homogene polynomielle Kernel ist definiert als: $$k_{d, \\text{poly-h}}(x, x') = (x^T x')^d$$\n",
    "   Dieser Kernel eignet sich gut für Daten, die durch eine Polynomfunktion eines bestimmten Grades getrennt werden können. Wenn Ihre Daten auf dem Plot eine klare polynomiale Trennung aufweisen, könnte dies eine gute Wahl sein.\n",
    "\n",
    "3. **Inhomogener polynomieller Kernel zu Grad d > 0 mit r ∈ R:**\n",
    "\n",
    "    Der inhomogene polynomielle Kernel ist definiert als: $$k_{d,r, \\text{poly-i}}(x, x') = (x^T x' + r)^d$$\n",
    "   Dieser Kernel fügt einen Konstanten Term r hinzu, was zu mehr Flexibilität führt. Er kann verwendet werden, wenn die Daten fast durch ein Polynom getrennt werden können, aber eine kleine Verschiebung benötigen.\n",
    "\n",
    "5. **Radiale Basisfunktion mit γ > 0:**\n",
    "\n",
    "    Die radiale Basisfunktion (RBF), auch bekannt als Gaußscher Kernel, ist definiert als: $$k_{\\gamma, \\text{rbf}}(x, x') = e^{-\\gamma \\|x - x'\\|^2}$$\n",
    "   Dieser Kernel ist sehr flexibel und kann komplexe Trennflächen modellieren. Er eignet sich gut für Fälle, in denen die Daten nicht linear oder polynomiell separierbar sind. Wenn Ihre Daten auf dem Plot Cluster bilden oder wenn es keine offensichtliche lineare oder polynomiale Trennung gibt, könnte der RBF-Kernel eine gute Wahl sein.\n",
    "\n",
    "Beachten Sie auch, dass der lineare Kernel ein Spezialfall des homogenen polynomiellen Kernels ist: $k_{\\text{linear}} = k_{1, \\text{poly-h}}$.\n",
    "\n",
    "Der Kernel $k_{\\gamma, \\text{rbf}}$ wird gelegentlich auch Gaußscher Kernel genannt und wird recht oft verwendet, da er in der Lage ist, auch komplexere Klassenunterscheidungen zu modellieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5dbb4-d7d5-41dc-9de9-fbe74d7bb642",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4. KNN <a name=2.4.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56132e-fd0a-4f26-845e-d8dda1f38412",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Grundlagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd80bf-cf88-4a58-a588-35da1c3d0bbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "- benötigt keinen Training, kann direkt auf den testdaten benutzt werden.\n",
    "\n",
    "- Die Grundidee des KNN-Algorithmus (k-nearest neighbour) besteht darin, dass zur Vorhersage der Klasse einfach die\n",
    "vorherrschende Klasse der k ∈ N nächsten Nachbarn (aus dem Trainingsdatensatz) im Merkmalsraum gewählt wird.\n",
    "\n",
    "- Definiere: $$clf_{D,k}(x) = maj(nearest_k(D, x))$$\n",
    "\n",
    "- Mit anderen Worten, nearestk(D, x) bestimmt diejenigen k verschiedenen Klassen derjenigen Beispiele des Daten\u0002satzes D, die sich bezüglich der Euklidischen Distanz am nächsten zu x befinden. Die Funktion maj bestimmt dann diejenige Klasse, die unter diesen k nächsten Nachbarn am häufigsten auftaucht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62acf6f-fb7c-452c-976e-0d57ab8b4731",
   "metadata": {},
   "source": [
    "**wichtig**:\n",
    "- wir nehmen für $nearest_k(D, x)$ immer an dass alle Beispiele des Datensatzes D eine unterschiedliche Distanz zu $k$ haben.\n",
    "- Wenn 2 oder mehr BEsipiele die *gleiche* Distanz zu x (und somit wird sie mit den k nächste nachbran gezählt), werden wir trozdem nur k nächste nachbarn wählen und die restlichen identischen beispiele ignorieren.\n",
    "- Für $maj$ nehmen wir an, dass es immer eine eindeutige Klasse in der Mehrheit gibt. Gibt es mehrere maximal\n",
    "vorhandene Klassen, wählen wir eine Klasse zufällig aus.\n",
    "- Diese Definition ist parametrisierbar:\n",
    "    - die BEstimmung der k nächsten Nachbarn muss nicht unbedingt dmit der Euklidischen Norm berechnet werden. Prinzipiell kann hier eine beliebige Norm verwendet werden.\n",
    "    - die Funktion maj kann durch andere Selektionsfunktionen ausgetauscht werden, beispielsweise eine Funktion, die der Klasse der näheren Nachbarn eine höhere Gewichtung gibt.\n",
    "- Typische Werte für k liegen hier im Bereich 1,...,10, wobei:\n",
    "    - <ins>Klassifikatoren mit kleineren Werten für k zu Überanpassung</ins>\n",
    "    - und <ins>höheren Werten für k zu Unteranpassung neigen</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a09c8-4016-4d7d-9e6f-b73c193ed533",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Nächste-Nachbarn-Regression\n",
    "\n",
    "- KNN kann auch für REgressionsprobleme verwendet werden mit einer einfachen modifikation:\n",
    "    - Anstatt als Klasse eines neuen Beispiels die vorherrschende Klasse der Nachbarschaft zu wählen, wird hier als Zielwert **der Mittelwert der Nachbarschaft** gewählt: $$regr_{D,k}(x) = \\frac{\\sum_{y \\in nearest_k(D,x)}y}{k} = \\frac{1}{k}\\sum_{y \\in nearest_k(D,x)} y$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1b696-22b0-4dfa-b3cf-a4560dd96626",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Merkmalskalierung\n",
    "\n",
    "- **Nachteil von KNN**: (insbesondere bei der Verwendung der Euklidischen Norm) ist eine Empfindlichkeit bzgl. verschiedener Skalen der Merkmale.\n",
    "- Dieses Problem taucht auch bei anderen Machinellen Lernen Verfahren.\n",
    "- Deshalb wichtig: **Normierung der Merkmalsausprägung** in der Datenvorverarbeitungsphase.\n",
    "- Es gibt viele Ansätze. Wir zeigen hier: **z-Transformation** (oder einfach nur **\n",
    "Standardisierun**g) vor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4faca0-0774-463b-b6f0-45743b71e7d0",
   "metadata": {},
   "source": [
    "### Merkmalskalierung\n",
    "\n",
    "- **Nachteil von KNN**: (insbesondere bei der Verwendung der Euklidischen Norm) ist eine Empfindlichkeit bzgl. verschiedener Skalen der Merkmale.\n",
    "- Dieses Problem taucht auch bei anderen Machinellen Lernen Verfahren.\n",
    "- Deshalb wichtig: **Normierung der Merkmalsausprägung** in der Datenvorverarbeitungsphase.\n",
    "- Es gibt viele Ansätze. Wir zeigen hier: **z-Transformation** (oder einfach nur **Standardisierung**) vor.\n",
    "\n",
    "**z-Transformation**:\n",
    "\n",
    "Der z-transformierte Datensatz $\\hat{D}$ ist definiert als:\n",
    "\n",
    "- Für jedes Merkmal \\( j \\) und jede Beobachtung \\( i \\), ist der z-transformierte Merkmalswert $\\hat{x}_{ij}$ gegeben durch:\n",
    "\n",
    "$$\n",
    "\\hat{x}_{ij} = \\frac{x_{ij} - \\tilde{x}_j}{\\sigma_j} \\tag{a}\n",
    "$$\n",
    "\n",
    "wo $\\tilde{x}_j$ der Mittelwert und $\\sigma_j$ die Standardabweichung des Merkmals $j$ ist.\n",
    "\n",
    "- Der z-transformierte Zielwert $\\hat{y}_i$ ist gleich dem ursprünglichen Zielwert $y_i$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = y_i\n",
    "$$\n",
    "Nach der **z-Transformation** ist der Erwartungswert (über dem gegebenen Datensatz) jeder Merkmalsausprägung 0 und die Varianz jeder Merkmalsausprägung 1. \n",
    "\n",
    "D.h.: \n",
    "1. Wir berechnen die Mittelwerte der Merkmale von x, d.h. $\\tilde{x}$\n",
    "2. Wir berechnen die Standardabweichungen $\\sigma$ der Merkmale von x.\n",
    "3. dann verwenden wir die Formel (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f41122-1fa8-4067-a138-52cf90c30a95",
   "metadata": {},
   "source": [
    "## 2.5. Bayes <a name=2.5.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de359ed3-2610-4613-b49d-65042cb0535f",
   "metadata": {},
   "source": [
    "- Diese Methode verwendet ebide Konzepte **Modell** und **Wahrscheinlichkeit**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa3c7a-0ce2-4009-86d8-a6635c96c53b",
   "metadata": {},
   "source": [
    "### Das Maximum-Likelihood-Prinzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5412f4-b227-49ff-813c-a87f109504d4",
   "metadata": {},
   "source": [
    "- Hier heißt ein Modell $h$ auch **hypothese**.\n",
    "- Üblicherweise nimmt man an, dass h aus einem gegebenen Hypothesenraum H entstammt (z.B. der Menge aller linearen Funktionen im Fall der linearen Regression)\n",
    "- Sei P die Wahrscheinlichkeitsverteilung.\n",
    "- Optimale Hyptothese h ist die wahrscheinlichste Hypothese h, gegeben dass wir die Trainingsdaten D beobachtet haben.\n",
    "\n",
    "#### Bayes Theorem\n",
    "\n",
    "$$P(h | D) = \\frac{P(D | h)P(h)}{P(D)} \\tag{1}$$ \n",
    "\n",
    "Hierbei ist:\n",
    "- `P(h | D)`:  die **a posteriori Wahrscheinlichkeit** der Hypothese. beschreibt die Wahrscheinlichkeit von h gegeben der Beobachtung D.\n",
    "    - $P(h | D)$ kann nicht direkt bestimmt werden, aber das Bayes-Theorem kann helfen, den Wert anzunäehren.\n",
    "- `P(h)` die **a priori Wahrscheinlichkeit** der Hypothese h.\n",
    "    - Das bedeutet, es ist die Wahrscheinlichkeit, die wir der Hypothese h zuweisen, bevor wir zusätzliche Daten betrachten.\n",
    "    - Diese Wahrscheinlichkeit kann durch vorhandenes Hintergrundwissen beeinflusst werden, das uns eine Vorstellung davon gibt, wie die Hypothese wahrscheinlich aussieht.\n",
    "    - oft besteht unser vollständiges Hintergrundwissen nur aus dem Datensatz D und wir haben keine weiteren Informationen zum Hypothesenraum H.\n",
    "    -  deshalb --> Wir nehmen eine Gleichverteilung auf H an, d.h. alle Hypothesen sind gleich wahrscheinlich.\n",
    "- `P(D)` ist die Wahrscheinlichkeit, dass der Datensatz D beobachtet wurde,\n",
    "- und `P(D | h)` ist die Wahrscheinlichkeit, D zu beobachten, gegeben dass D von h generiert wurde.\n",
    "    - ist einfacher abzuschätzen als  `P(h | D)`, da sie prinzipiell beschreibt, wie gut h den Datensatz D erklärt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f26254-43c2-4b7a-8ad0-8b572fec269f",
   "metadata": {},
   "source": [
    "#### Maximum-A-Posteriori-Hypothese (MAP-Hypothese) h\\*\n",
    "-  wir suchen eine **Hypothese h\\*, die den Wert P(h | D) bzw. (1) maximiert**.\n",
    "\n",
    "$$\n",
    "h* = \\arg\\max_{h \\in H} P(h | D) $$\n",
    "$$h* =  \\arg\\max_{h \\in H} \\frac{P(D | h)P(h)}{P(D)}$$\n",
    "$$h* =  \\arg\\max_{h \\in H} P(D | h)P(h)\n",
    "\\tag{3}$$\n",
    "\n",
    "  weil der Term P(D) für die Maximierung irrelevant ist.\n",
    "\n",
    "#### Maximum-Likelihood-Hypothese (ML-Hypothese) h\\*\n",
    "\n",
    "  wenn $P(h)$ **gleichverteilt,** ist, dann:\n",
    "  $$h* =  \\arg\\max_{h \\in H} P(D | h)\n",
    "\\tag{4}$$\n",
    "- h\\* heißt hier **Maximum-Likelihood-Hypothese** (ML-Hypothese), da sie nur auf der \n",
    "maximalen Wahrscheinlichkeit, die Daten D bzgl. h zu beobachten, basiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f472a-dd7a-49a4-9b67-7bf3f134795a",
   "metadata": {},
   "source": [
    "### Bayes-Klassifikation und lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036358b-2791-4705-9f32-1e99d6e025f3",
   "metadata": {},
   "source": [
    "##### Das originale linearer Regression\n",
    "- Bei linearer REgression suchen wir eine $\\theta^*$ mit $$\\arg\\min_{\\theta} \\sum{i=0}{m}(\\theta^T x^i - y^i)^2 \\tag{5}$$\n",
    "- Das gelernte Modell $h_{\\theta^*}(x) = θ_0^∗ + θ_1^∗x_1 + ::: + θ_n^∗x_n$ ist eine Gerade die den funktionalen Zusammenhang zwischen den Merkmalen x und der Zielvariablen y modelliert.\n",
    "\n",
    "##### Die linearer Regression aus der Perspektive der Bayes’schen Klassifikation\n",
    "- Wir gehen davon aus, dass unser Datensatz D **verrauscht** ist, d. h., es wird keine Gerade geben auf der alle Trainingsbeispiele liegen.\n",
    "    - d.h. die Werte y unseres Datensatzes haben die Form: $$y^i = \\hat{y}^i + ε^i$$ wobei ε der Fehler und $\\hat{y}$ der wahre Wert von y ist.\n",
    "    - **Was für eine Art Fehler?** Eine durchaus übliche Annahme hier ist, dass die Fehlerwerte im Datensatz **normalverteilt** sind.\n",
    "    - Wir gehen davon aus, dass die Fehlerwerte $ε^i$ den Erwartungswert 0 und eine unbekannte Varianz $σ^2$ haben\n",
    "- Wir nehmen initial an, dass  alle Parameter θ gleich wahrscheinlich sind.\n",
    "\n",
    "> die lineare Regression (unter Benutzung des quadratischen Fehlers als Kostenfunktion) eine Maximum-Likelihood-Hypothese bestimmt\n",
    ">\n",
    "> $\\longrightarrow$ die lineare Regression ist also nach Bayes’schen Grundsätzen plausibel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ce31e-a61c-4892-bb65-bfa400c8c32b",
   "metadata": {},
   "source": [
    "### Normaler vs Naive Bayes-Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fd7da-eba3-4e5d-9494-5bc51f9acc0d",
   "metadata": {},
   "source": [
    "Sei $Z_i$ der Merkmalsraum und $Z = {c_1,..., c_k}$ die Menge der Klassen.\n",
    "\n",
    "**Gegeben ein neuer Datenpunkt x, wählen wir diejenige Klasse c ∈ Z, die aufgrund von D am wahrscheinlichsten ist.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3640fb-4c9c-4635-b579-61663986b132",
   "metadata": {},
   "source": [
    "#### Bayes-Klassifikator $clf^{Bayes}_D$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba166fe8-c15f-474f-9ae8-9ca7e6b8250f",
   "metadata": {},
   "source": [
    "\n",
    "$$ clf^{Bayes}_D(x) = \\arg\\max_{c \\in Z} P(c | x,D)$$\n",
    "\n",
    "wobei\n",
    "\n",
    "$$P(c | x,D) = \\frac{|\\{(x, c) \\in D\\}|}{\\sum_{c' \\in Z} |\\{(x, c') \\in D\\}|}$$\n",
    "\n",
    "Mit anderen Worten, einem neuen Datenpunkt x wird diejenige Klasse c ∈ Z zugewiesen, die am ha¨ufigsten x in\n",
    "D zugewiesen wird.\n",
    "\n",
    "**Probleme :**\n",
    "1. wir müssen für jede zu erwartende Merkmalsausprägung $x^∗$ Beispiele im Trainingsdatensatz D haben, um $x^∗$ überhaupt klassifizieren zu können.\n",
    "2. Ein weiteres Problem (das auch prinzipiell schon beim KNN-Algorithmus aufgetreten ist) besteht darin, dass zur Berechnung von $ clf^{Bayes}_D(x)$ stets der gesamte Datensatz $D$ vorgehalten werden muss. Insbesondere bei großen Datensätzen kann dies signifikant zu einer langen Berechnungszeit beitragen.\n",
    "\n",
    "**Lösung $\\longrightarrow$** von der <ins>allgemeinen Bayes-Klassifikation</ins> zur <ins>Naiven Bayes-Klassifikation</ins> wechseln.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e08a5-b888-4924-9f99-c2f3ef3e3708",
   "metadata": {},
   "source": [
    "**Unterschied zwischem der allgmeinen und naiven Bayes-Klassifikation**:\n",
    "\n",
    "Der Unterschied dabei liegt darin, dass wir bei der Berechnung von `P(c | x,D)` eine Unabhängigkeitsannahme u¨ber die Verteilung der einzelnen Merkmale vornehmen und dabei\n",
    "den wahren Wert `P(c | x,D)` nur abscha¨tzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e15d2-e1d5-4521-87dd-7cf0b0166d59",
   "metadata": {},
   "source": [
    "#### Naives Bayes-Klassifikator $clf^{naive}_D$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3daaf8a-10ea-4ca1-a246-a00b21c41d04",
   "metadata": {},
   "source": [
    "- die Verteilungen der Merkmalsausprägungen sind bedingt unabhängig voneinander.\n",
    "\n",
    "$$clf^{naive}_D(x) = \\arg\\max_{c \\in Z} P(c | D)P(x_1 | c,D)P(x_2 | c,D)...P(x_n | c,D) \\tag{8}$$\n",
    "\n",
    "mit\n",
    "\n",
    "$$P(c | D) = \\frac{|{(z, c) \\in D}|}{|D|}$$\n",
    "\n",
    "$$P(x_i | c,D) = \\frac{|{(z', c) \\in D | z' = (z_1,...,z_n),z_i = x_i}|}{|{(z, c) \\in D}|} \\quad \\text{ für } i = 1,...,n$$\n",
    "\n",
    "Im Unterschied zur Bayes-Klassifikation:\n",
    "- muss nicht der gesamte Trainingsdatensatz fu¨r die Klassifikation vorgehalten werden, es genu¨gt hier, die Werte P(c | D) und P(i | c,D) fu¨r alle Kombinationen von Merkmalen xi und Klassen c ∈ Z zu berechnen und einzig diese vorzuhalten\n",
    "- Der Naive Bayes-Klassifikator kann auch Beispiele klassifizieren, die Merkmalsausprägungen aufweisen, die im Trainingsdatensatz nicht explizit vorgekommen sind.\n",
    "\n",
    "$\\longrightarrow$ Speicherplatzvorteil.\n",
    "\n",
    "Gibt es in dem betrachteten Lernszenario eins oder mehrere kontinuierliche Merkmale, so ist die Maschinerie des \n",
    "Naiven Bayes-Klassifikators prinzipiell in gleicher Weise anwendbar \n",
    "\n",
    "**Aber** anstelle einer Wahrscheinlichksvrteilung, eine Wahrscheinlichksdichte anwenden. d.h. in (8) $P(x_i | c,D)$,  $p(x_i | c,D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f2e00-eef2-493d-b983-c696cb8b6440",
   "metadata": {},
   "source": [
    "## 2.6. Entscheidungsäume <a name=2.6.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f95f81-0fe2-490d-819a-df8e40a55604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Entscheidungsbaummodell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd15698-622d-4830-9b05-422dbe78ccde",
   "metadata": {},
   "source": [
    "- Ein Entscheidungsbaum ist ein **gerichteter** Baum.\n",
    "- Jeder Knoten stellt eine Fallunterscheidung für den Wert eines Merkmals eines gegebenen Datenpunktes dar.\n",
    "- Für jeden Fall gibt es einen eindeutigen Nachfolgerknoten.\n",
    "- Die Blätter des Baumes enthalten die möglichen Klassifikationen des betrachteten Datenpunkts.\n",
    "- Ein Pfad von der Wurzel des Entscheidungsbaums zu einem Blatt stellt eine Reihe von Entscheidungen bzgl. eines Datenpunktes dar, die zu einer Klassifikation führen.\n",
    "- Jede Klasse kann durch mehrere Blattknoten repräsentiert werden.\n",
    "\n",
    "**Definition eines Entscheidungsbaums**\n",
    "- Sei $X = X_1 × ... × X_n$ der Merkmalsraum von $n$ Merkmalen und $Y$ die Menge der Klassen (oder der Zielraum bei Regressionsproblemen).\n",
    "- Ein Entscheidungsbaum $T$ für $X$ und $Y$ ist ein Tupel $T = (V,E,r)$ mit:\n",
    "    1. $(V,E)$ ist ein (abwärts) gerichteter Baum mit Wurzel r.\n",
    "    2. Ein <ins>Blattknoten</ins> $v ∈ V$ heißt auch <ins>Klassifikationsknoten</ins> mit $cl(v) ∈ Y$. Wobei Jede Klasse kann durch mehrere Blattknoten repräsentiert werden.\n",
    "    3. Ein <ins>innerer Knoten</ins> $v ∈ V$ heißt auch <ins>Entscheidungsknoten</ins> mit (sei ${v_1,..., v_k}$ die Menge der Nachfolger von v in T):\n",
    "        - $att(v) ∈ {1,...,n}$ ist das Entscheidungsmerkmal von v und\n",
    "        - $succ(v)$ ist eine Entscheidungsfunktion $succ(v) : X_{att(v)} → {v_1,..., v_k}$.\n",
    "\n",
    "**Klassifikation eines Datenpunkts**\n",
    "- Ist $x = (x1,..., xn)^T ∈ X_1 × ... × X_n$ ein Datenpunkt, so ist die Klassifikation von x bzgl. eines Entscheidungsbaums $T = (V,E,r)$ definiert via : \n",
    "$$clf_T(x, v) = \\begin{cases}\n",
    "   cl(v) &\\text{falls } v \\text{ ein Klassifikationsknoten ist} \\\\\n",
    "   clf_T\\left(x, succ(v)(x_{att(v)})\\right) &\\text{sonst }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Entscheidungsfunktion**\n",
    "- Die Entscheidungsfunktion $succ(v)$ (für engl. successor) eines Entscheidungsknotens $v$ wird üblicherweise als einfacher Vergleich mit einer Konstanten realisiert (wie \"$x_i < 10$\") und $v$ besitzt dann zwei Nachfolger: einen falls der Vergleich positiv ausfällt und einen falls der Vergleich negativ ausfällt.\n",
    "- Für Merkmale mit endlich vielen Ausprägungen erhält $v$ einen Nachfolger für jede dieser Ausprägungen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f85d3a-bd62-45d4-954b-5363b1a378e8",
   "metadata": {},
   "source": [
    "Das Lernen eines Entscheidungsbaumes aus einem Trainingsdatensatz geschieht üblicherweise **nicht** durch Lösen eines Optimierungsproblems, <ins>sondern durch dedizierte prozedurale Algorithmen</ins>.\n",
    "\n",
    "Die beiden bekanntesten Algorithmen dazu sind der **ID3-Algorithmus** und der **C4.5-Algorithmus**.\n",
    "- ID3 und C4.5 beide basieren auf dem **Prinzip der Top-Down induction of decision Trees (TDIDT)**.\n",
    "\n",
    "**Prinzip der Top-Down induction of decision Trees (TDIDT)**\n",
    "- Dieses Prinzip baut einen Entscheidungsbaum auf Grundlage eines gegebenen Trainingsdatensatzes rekursiv von der Wurzel beginnend auf.\n",
    "- Für einen Knoten v und einen Datensatz D, wird dazu zunächst das Entscheidungsmerkmal i für v ausgewählt.\n",
    "- Dabei soll das Merkmal gewählt werden, das den Datensatz D ”am besten“ partitioniert.\n",
    "- Ist das Merkmal i ausgewählt, so erzeugen wir für jede Merkmalsausprägung $z_{i,1},...,z_{i,1}$ einen entsprechenden Nachfolgeknoten $v_1,..., v_{ni}$.\n",
    "- Dann partitionieren wir den Datensatz D entsprechend der Merkmalsausprägungen in Datensätze $D_1,...,D_{ni}$ mit $$D_j = {(x, y) ∈ D | x_i = z_j}$$\n",
    "- Dieses Verfahren wird rekursiv nun für alle Knoten v mit den entsprechenden Datensätzen\n",
    "solange fortgeführt, bis alle Beispiele eines Datensatzes $D_j$ eindeutig als 0 oder 1 klassifiziert sind oder die Beispiele nicht mehr unterschieden werden können (dieser Fall tritt ein, wenn die Beispiele identische Merkmalsausprägungen aber verschiedene Klassen haben).\n",
    "- In beiden Fällen fügen wir an der entsprechenden Stelle einen Klassifikationsknoten ein (im zweiten Fall wählen wir dazu die in D am häufigsten vorkommende Klasse)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54be020-a9a2-4bb5-bdcd-0bf18d141bad",
   "metadata": {},
   "source": [
    "### Der ID3-Algorithmus (Iterative Dichotomiser 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55067ed-6b19-4f0a-baf1-d1774b8d7835",
   "metadata": {},
   "source": [
    "- benutzt TDIDT.\n",
    "- (beachten Sie, dass der zurückgegebene Entscheidungsbaum T = (V,E,r) durch den Wurzelknoten r charakterisiert ist: die Mengen V und E werden nur implizit im Algorithmus gebildet.\n",
    "- **SelectFeature** wählt niemals ein Merkmal aus, dass D nicht in wenigstens zwei Mengen partitioniert.\n",
    "    - So eine Auswahlfunktion heißt **rational**.\n",
    "    - Der Algorithmus TDIDT ist für jede rationale Instanz der Funktion SelectFeature **korrekt**, d. h., die Ausgabe von TDIDT ist stets ein Entscheidungsbaum, der den Datensatz D vollständig korrekt klassifiziert.\n",
    "    - Die Auswahl der Funktion SelectFeature kann aber durchaus Einfluss auf die Größe des gelernten Entscheidungsbaumes haben.\n",
    "    - Das **Ziel** der Funktion SelectFeature ist es, ein Merkmal so auszuwählen, dass der finale Entscheidungsbaum **möglichst klein** ist.\n",
    "\n",
    "> ein <ins>kleiner</ins> Entscheidungsbaum ein einfacheres Modell zur Erklärung der Daten\n",
    "darstellt als ein <ins>größerer</ins> Entscheidungsbaum (gegeben, dass beide Bäume die Daten gleich gut klassifizieren)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2abf5-b791-49e6-a822-833c6dd5a515",
   "metadata": {},
   "source": [
    "- Der ID3-Algorithmus wählt daher das Merkmal i ∈ {1,...,n} aus, das den **höchsten Informationsgewinn** bei der Klassifizierung bietet. Formal wird dies durch die **Entropie** definiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79488f-1a62-4993-8c28-5ba2799c8360",
   "metadata": {},
   "source": [
    "#### Entropie $H (D)$ und die Bedingte Entropie $H(D | i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c8b43-1598-4d84-9618-c8875c3faac8",
   "metadata": {},
   "source": [
    "- Die Intuition hinter der Entropie H(D) ist, dass diese das Maß der Unordnung bzgl. der Klassenverteilung angibt.\n",
    "- Im Kontext von Entscheidungsbaum-Algorithmen wird die Entropie verwendet, um das Merkmal zu bestimmen, das den größten Informationsgewinn liefert. \n",
    "    \n",
    "    - Eine hohe Entropie bedeutet eine hohe Unsicherheit $\\longrightarrow$ es ist **relativ schwierig**, die richtige Klasse bzgl. den Daten D vorherzusagen.\n",
    "    \n",
    "    - während eine niedrige Entropie eine geringe Unsicherheit bedeutet $\\longrightarrow$ es ist **einfacher**, die richtige Klasse bzgl. den Daten D vorherzusagen.\n",
    "    \n",
    "    - **H(D) = 0** gdw. alle Beispiele in D gleich klassifiziert sind, bzw. wenn es nur positive Beispiele bzw. nur negative Beispiele gibt.\n",
    "    \n",
    "    - **H(D) ist maximal** gdw. die Verteilung einer Gleichverteilung entspricht, d.h. Wenn die Anzahl positive und negative Beispiele gelich sind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef2e65-8882-4302-b4a2-89a5482716f9",
   "metadata": {},
   "source": [
    "##### Entropie $H (D)$\n",
    "- Für ein **binäres** Klassifikationsproblem (zwei Klassen 0 und 1) ist die $\\text{Entropie}^2 H (D)$ definiert als:\n",
    "\n",
    "$$\n",
    "H(D) = -\\frac{|{(x, y) \\in D | y = 0}|}{|D|} \\log_{10} \\left(\\frac{|{(x, y) \\in D | y = 0}|}{|D|}\\right) - \\frac{|{(x, y) \\in D | y = 1}|}{|D|} \\log_{10} \\left(\\frac{|{(x, y) \\in D | y = 1}|}{|D|}\\right)\n",
    "$$\n",
    "\n",
    "$$ H(D) = -\\frac{\\text{Positive Beipsiele}}{\\text{alle beispiele}}*log_10\\frac{\\text{Positive Beipsiele}}{\\text{alle beispiele}} - \\frac{\\text{Negative Beipsiele}}{\\text{alle beispiele}}*log_10\\frac{\\text{Negative Beipsiele}}{\\text{alle beispiele}}$$\n",
    "\n",
    "- Für ein **mehrklassiges** Klassifikationsproblem (Klassen $c_1, ..., c_k$) ist die Entropie $H(D)$ definiert als:\n",
    "\n",
    "$$\n",
    "H(D) = -\\sum_{i=1}^{k} \\frac{|{(x, c) \\in D | c = c_i}|}{|D|} \\log_{10} \\left(\\frac{|{(x, c) \\in D | c = c_i}|}{|D|}\\right)\n",
    "$$\n",
    "\n",
    "##### Die Bedingte Entropie $H(D | i)$\n",
    "- die **bedingte Entropie $H(D | i)$** `D` bzgl. `i` ist definiert als:\n",
    "\n",
    "$$H(D | i) = \\sum_{j=1}^{ni} \\frac{{(x, y) ∈ D | xi = zi, j}}{|D|} H({(x, y) ∈ D | xi = zi, j})$$\n",
    "\n",
    "- Die bedingte Entropie `H(D | i)` gibt an, wie gut die einzelnen durch das Merkmal `i` entstandenen Teildatensätze klassifiziert sind.\n",
    "    - Ein **hoher Wert** bedeutet, dass die entstandenen Teildatensätze (gewichtet nach deren Größe) recht ungeordnet sind.\n",
    "    - ein niedriger Wert bedeutet, dass die Klassen durch das Merkmal `i` gut getrennt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60ce21-b8a8-4ef3-8ecf-268c059a4a47",
   "metadata": {},
   "source": [
    "##### Der Informationsgewinn $IG(D, i)$\n",
    "\n",
    "Der Informationsgewinn IG(D,i) von D bzgl. i ist definiert als:\n",
    "\n",
    "$$IG(D,i) = H(D) − H(D | i)$$\n",
    "\n",
    "- Der Informationsgewinn IG(D,i) gibt an, wie sehr die Merkmalsauswahl i die Daten in D nach den Klassen (vor-)sortiert.\n",
    "    - Je höher der Informationsgewinn, desto besser klassifiziert das Merkmal i den Datensatz D.\n",
    "\n",
    "- Beim ID3-Algorithmus wird die Funktion SelectFeature so definiert, dass dasjenige Merkmal ausgewählt, das den höchsten Informationsgewinn verspricht:\n",
    "\n",
    "$$SelectFeature_{ID3}(D) = \\arg\\max_{i∈{1,...,n}} IG(D,i)$$\n",
    "\n",
    "> Beachten Sie, dass wegen $IG(D,i) = H(D)−H(D | i)$ wir bei SelectFeatureID3(D) eigentlich nur H(D | i) **minimieren** müssen, da <ins>der Term H(D) merkmalsunabhängig ist</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6fc32-9a83-465a-b590-d6700383650d",
   "metadata": {},
   "source": [
    "**Nachteile von ID3**:\n",
    "- Der ID3-Algorithmus tendiert bei leicht verrauschten Daten schnell zur Überanpassung, d. h., es wird ein Entscheidungsbaum mit sehr langen Pfaden von der Wurzel bis zu den Blättern gelernt.\n",
    "- Die Auswahlfunktion hat das Problem, dass sie Merkmale mit einer hohen Anzahl an Merkmalsausprägungen bevorzugt. Der gelernte Entscheidungsbaum ist dann überangepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e8f68-ed76-4dae-8ebb-5336ba9bbffc",
   "metadata": {},
   "source": [
    "### Der C4.5-Algorithmus (Iterative Dichotomiser 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48f1f3-0acd-459e-a335-f15e4a16dbc7",
   "metadata": {},
   "source": [
    "- ist ein Weiterentwicklung der ID3-Algo.\n",
    "- Es besteht aus TDIDT + die folgenden Optimierungen:\n",
    "    1. **Nachbearbeitungsschritt**: Der C4.5-Algorithmus enthält einen zusätzlichen Nachbearbeitungsschritt, der den Entscheidungsbaum kürzt. Dies geschieht durch Extraktion der implizit vorhandenen Klassifikationsregeln im Baum, Erkennung und Entfernung von \"wenig relevanten\" Vorbedingungen der Regeln und anschließende Konstruktion eines neuen (kleineren) Entscheidungsbaums.\n",
    "    \n",
    "    2. **Arbeit mit kontinuierlichen Merkmalen**: Der C4.5-Algorithmus kann mit Datensätzen mit kontinuierlichen Merkmalen arbeiten, indem er die entsprechenden Merkmalsräume in zwei Intervalle aufteilt und so jedes kontinuierliche Merkmal in ein Merkmal mit endlich vielen Ausprägungen konvertiert.\n",
    "        - Die Hauptschwierigkeit besteht darin, die Intervallsgrenzen festzulegen. \n",
    "    \n",
    "    3. **Optimierte Version des Informationsgewinns**: Der C4.5-Algorithmus verwendet eine optimierte Version des Informationsgewinns als Auswahlfunktion für Merkmale. Diese Version skaliert den Informationsgewinn, um das Phänomen zu vermeiden, dass Merkmale mit einer hohen Anzahl an Merkmalsausprägungen bevorzugt werden.\n",
    "    \n",
    "    4. **Behandlung von unvollständiger Information** (beispielsweise einzelne fehlende Merkmalsausprägungen der Beispiele).\n",
    "    \n",
    "    5. **Einbeziehung von Gewichtungen der Merkmale.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afad684-f795-495b-bed7-a20303da7bac",
   "metadata": {},
   "source": [
    "### Entscheidungswälder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc0658-c255-4a06-b5ab-da7dbfb39b89",
   "metadata": {},
   "source": [
    "**Ensemble Lernen :**\n",
    "- Bei dieser Methodik werden viele verschiedene Modelle gleichzeitig gelernt und die Resultate bei der Anwendung geeignet aggregiert.\n",
    "- -Kann benutzt werden um Überanpassung zu vermeiden, indem die verschiedenen Modelle nur mit einer Teilmenge der zur Verfügung stehenden Daten trainiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd8334-2aa0-4793-973b-e76f9b3ade07",
   "metadata": {},
   "source": [
    "**Entscheidungswald**\n",
    "- ist ein Ensemble-Lernverfahren.\n",
    "- Ein Entscheidungswald $F$ (engl. random forest) ist eine Menge von Entscheidungsbäumen $F = \\{T_1,...,T_l\\}$. Ist $x$ ein Datenpunkt, so ist die Klassifikation von $x$ bzgl. des Entscheidungswalds $F$ definiert via\n",
    "$$\n",
    "\\text{clf}_F(x) = \n",
    "\\begin{cases} \n",
    "0 & \\text{wenn } |\\{ j | \\text{clf}_{T_j}(x) = 0\\}| > |\\{ j | \\text{clf}_{T_j}(x) = 1\\}| \\\\\n",
    "1 & \\text{sonst}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Jeder Datenpunkt wird von jedem Baum im Wald klassifiziert.\n",
    "- <ins>F klassifiziert x als 0 gdw. eine Mehrheit der Bäume in T den Punkt x als 0 klassifiziert</ins>.\n",
    "- Die endgültige Klassifikation des Waldes ist abhängig von der Art der Klassifikation:\n",
    "    - Bei einem **nicht-binären Klassifikationsproblem** wird die Klasse ausgewählt, die häufiger als jede andere Klasse auftritt.\n",
    "    - Bei Anwendung auf ein **Regressionsproblem** wird der Durchschnittswert aller Vorhersagen bestimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce028e5-2377-48a6-a9b4-0b3f0f0bed33",
   "metadata": {},
   "source": [
    "- Um einen Entscheidungswald aus einem Datensatz zu lernen, verwendet man **l-mal** einen Algorithmus (ID3 oder C4.5) zum Lernen eines Entscheidungsbaums, jedoch jedes Mal auf einem leicht modifizierten Datensatz. Dieser Ansatz wird auch als **Bootstrap Aggregating** oder **Bagging** bezeichnet. Dieser modifizierter Datensatz wird wie folgt erstellt:\n",
    "    1. Wir starten mit einer leeren Menge und wählen ein Element von D zufa¨llig gleichverteilt aus.\n",
    "    2. Dies wiederholen wir bis Dj genau m Elemente enthält (Da dies Ziehen mit Zurücklegen entspricht, ko¨nnen Beispiele aus D in einem Dj mehrfach auftreten oder gar nicht).\n",
    "    3. Mit hoher Wahrscheinlichkeit unterscheiden sich dann die gelernten Bäume $T_1,...,T_l$ voneinander und die Klassifikation mit $clf_F$ ist dadurch robuster.\n",
    "\n",
    "- Beim Entscheidungswald ändert man den obigen Algorithmus noch ein wenig ab: Randomisierung erhöhen.\n",
    "    - Beim Lernen eines einzelnen Entscheidungsbaums (Zeile 7) wird das Merkmal für den aktuellen Entscheidungsknoten nicht aus der gesamten Anzahl verfügbarer Merkmale ausgewählt, sondern aus einer zufällig gewählten Teilmenge. Dies stellt sicher, dass ein eventuell vorhandenes dominantes Merkmal (ein Merkmal mit hohem Informationsgewinn) nicht immer in den gelernten Bäumen in der Wurzel gewählt wird, was der Überanpassung entgegenwirkt.\n",
    "    - **Die Größe dieser Teilmenge**, die bei jeder Wahl eines Merkmals neu bestimmt wird, ist ein **Parameter des Lernverfahrens**, genau wie die Anzahl der Entscheidungsbäume. Oft in der Praxis auftretende Werte sind $\\sqrt{n}$ für die Anzahl zufälliger Merkmale, aus denen ein Entscheidungsmerkmal gewählt wird und $l = 100$ für die Anzahl der Entscheidungwissen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4363a63-93f1-4b65-87e4-c9c504afe6dd",
   "metadata": {},
   "source": [
    "# 3 Unüberwachtes Lernen <a name=3><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1776e-b2f4-4dc4-abb6-3ba7762514c5",
   "metadata": {},
   "source": [
    "- Beim unüberwachten Lernen sind die Klassen oder Funktionswerte der gegebenen Datenpunkte **nicht** bekannt, d.h. es stehen keine annotierten Trainingsdaten zur Verfügung.\n",
    "- Die Aufgabe eines unu¨berwachtem Lernalgorithmus ist es dann, eigenständig Struktur in den Daten zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a44fb-b9c4-42e5-9a7f-2fa73dce4b01",
   "metadata": {},
   "source": [
    "### 3.1. K-Means-Clustering <a name=3.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed2f01-5090-41f4-a3f2-c9b544823c3d",
   "metadata": {},
   "source": [
    "#### Clustering\n",
    "- `Ziel`: Partitionierung der Datenmenge $E = {x^{(1)}, ..., x^{(m)}}$ in Teilmengen $E_1,...,E_k$, so dass die Datenpunkte in jedem $E_i$ zueinander ähnlich sind $(i = 1,..., k)$, wohingegen die Datenpunkte in verschiedenen $E_i$, $E_j$ zueinander unähnlich sind $(i, j = 1,..., k, i ∕= j)$.\n",
    "\n",
    "- Da wir zu den Datenpunkten in E keine Klassifikation haben, besteht also die Hauptaufgabe, eine Menge von Klassen und eine Zuordnung von Klassen zu Datenpunkten zu finden.\n",
    "\n",
    "- Eine wichtige **Anwendung** ders clusterings:\n",
    "    - Marktsegmentierung\n",
    "\n",
    "- Der klassische Algorithmus der Clusteranalyse ist das **K-Means-Clustering**.\n",
    "    - Ähnlich zum KNN-Algorithmus für überwachtes Lernen.\n",
    "    - basiert auf Datensatz E und Anzahl der Cluster k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da24120-7f0d-47b8-9173-5027e66adfa7",
   "metadata": {},
   "source": [
    "#### Naive K-Means-Clustering (Lloyds Algorithmus)\n",
    "\n",
    "- ist eine heuristische Methode, um `E` in `k` Cluster zu unterteilen, sodass die Summe der euklidischen Distanzen von jedem Datenpunkt zu dem Mittelpunkt des ihm zugewiesenen Clusters **minimal** ist.\n",
    "- Der Algorithmus arbeitet iterativ:\n",
    "    1.  **Anfang :** Der Algorithmus startet von einer gegebenen Menge von Clustermittelpunkten (auch **Zentroiden** genannt) ${m_1,...,m_k}$.\n",
    "    2.  **Zuweisung :** Jedem Datenpunkt `x` in `E` wird der Zentroid $m_i$ (i = 1,..., k) zugewiesen, der ihm am nächsten ist (bezüglich der euklidischen Distanz).\n",
    "    3.  **Aktualisierung :** Anschließend aktualisieren wir $m_i$ durch den Mittelwert aller $m_i$ zugewiesenen Datenpunkte (i = 1,..., k).\n",
    "    4. **Iteration :** Diese beiden Schritte 2 und 3 werden wiederholt, **bis die Zentroiden konvergieren** (die Zuordnung der Datenpunkte zu den Zentroiden stabil wird).\n",
    "\n",
    "- **Der Auswahl der initialen Zentroiden und die Anzahl Cluster k** kann sich stark auf das Endergebnis auswirken.\n",
    "    - Üblicherweise wählt man hier zufällig gleichverteilt `k` Elemente aus `E` als initiale Zentroiden aus und führt den Algorithmus wiederholt aus, um das bestmögliche Clustering zu erreichen.\n",
    "    - Man kann Zentroiden auch durch eine bestimmte Methode wie das K-Means++-Verfahren berechnen.\n",
    " \n",
    "**Wichtig!!** Durch die Verwendung der euklidischen Distanz ist der naive K-Means-Algorithmus sehr anfällig für unterschiedlich skalierte Merkmale\n",
    "\n",
    "![](.\\K-means.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af1d4a-939a-4d6a-96b9-c97ecdda70f9",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d1f2e-753e-4789-bb89-2861940fd5ce",
   "metadata": {},
   "source": [
    "Es gibt beim unüberwachten Lernen, und speziell bei Clusteringproblemen, prinzipiell <ins>zwei Evaluationsmöglichkeiten:</ins>\n",
    "\n",
    "1. **Externe Evaluation**: Bei der externen Evaluation wird das Clustering auf einem zusätzlichen Testdatensatz evaluiert, der vollständige Beispiele (einschließlich der Klassenzugehörigkeit der Datenpunkte) enthalten muss. Die Erstellung eines solchen Datensatzes kann aufwändig sein, da der Datensatz meist manuell annotiert werden muss. Wenn jedoch ein solcher Testdatensatz zur Verfügung steht, können dieselben Metriken zur Evaluation eingesetzt werden wie beim überwachten Lernen, z.B. Genauigkeitsmaß, Präzision, Sensitivität und das F1-Maß.\n",
    "\n",
    "2. **Interne Evaluation**: Bei der internen Evaluation eines Clusteringalgorithmus wird das eigentliche Optimierungsziel des Clusterings als Kriterium herangezogen. Beim K-Means-Algorithmus versucht man beispielsweise, Zentroiden $(m_1,...,m_k)$ zu finden, sodass die Distanzen aller Datenpunkte in $E$ minimal zu den ihnen zugewiesenen Zentroiden sind. Dies wird formal durch das **Verzerrungsmaß** (engl. distortion bzw. Inertia) modelliert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f560b6-a926-4d5f-b448-5105a042aa7c",
   "metadata": {},
   "source": [
    "##### Verzerrung (distortion)\n",
    "\n",
    "- Die Verzerrung ist rechnerisch die Summe der quadrierten Distanzen der Datenpunkte zu ihrem nächstgelegenen Clusterzentrum. Formal sieht das wie folgt aus: $$\\text{dist}(\\text{cluster}, E, m_1,...,m_k) = \\sum_{x \\in E} ||x - m_{\\text{cluster}(x)}||$$\n",
    "\n",
    "- Das direkte Lösen des zur Verzerrung zugehörigen Optimierungsproblems, d.h., das Finden von $\\text{cluster}$ und $(m_1,...,m_k)$, so dass $\\text{dist}(\\text{cluster},E,m_1,...,m_k)$ minimal ist, ist **rechnerisch sehr schwer** (genauer: es ist ein **NP-schweres Problem**). Aus diesem Grund versucht der K-Means-Algorithmus auch nur eine **Annäherung an das Optimum** zu erreichen.\n",
    "\n",
    "- Vom Verzerrungswert eines Clusterings alleine lässt sich keine Aussage über die Güte des Clusterings ableiten, da er natürlich <ins>stark von der Skalierung der Merkmale abhängt</ins>. Erst im <ins>Vergleich mit den Verzerrungswerten anderer Clusterings</ins> können Güteunterschiede erkannt werden.\n",
    "    - **je mehr Cluster** ein Clustering besitzt, desto **geringer ist die Verzerrung**.\n",
    "    - Der Extremfall tritt hier ein, wenn ein Clustering k = m Cluster besitzt (d. h., **ein Cluster pro Datenpunkt**). In diesem Fall ist der **Verzerrungswert gleich 0**, das Clustering bringt aber keine richtigen Einblicke in die Struktur der Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca05962-0cc3-4deb-878c-546ad32abe4e",
   "metadata": {},
   "source": [
    "##### Ellenbogenmethode\n",
    "\n",
    "- korrekte Anzahl an Clustern k für einen Datensatz E **nicht bekannt** $\\longrightarrow$ \n",
    "Verzerrungswert nutzen, um die geeignete Zahl der Cluster zu finden; **Ellenbogenmethode**.\n",
    "    1. Dazu berechnet man die Verzerrungswerte für eine Reihe verschiedener Clusterzahlen k und stellt diese Werte in einem Diagramm dar.\n",
    "    2. Die optimale Clusterzahl findet man dann bei dem k, an dessen Stelle die Kurve \"abknickt\".\n",
    "    3. Die Interpretation dazu ist, dass hier höhere Clusterzahlen weniger Information enthalten als die Clusterzahl bis zu diesem Punkt. Natürlich ist dies nur eine sehr grobe Heuristik und der Wert ist auch nicht immer eindeutig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3fc1f-9d42-4676-9c3f-8919d6e3e66b",
   "metadata": {},
   "source": [
    "#### K-Means-Initialisierung\n",
    "\n",
    "**2 Probleme bei dem K--Means-Algorithmus**.1\n",
    "\n",
    "2. **Leere Cluster**: Ein weiteres problematisches Verhalten tritt auf, wenn alle Datenpunkte näher an einem Zentroiden liegen als am anderen, was dazu führt, dass der erste Cluster alle Datenpunkte enthält und der zweite Cluster leer ist. Dies wird durch das Beispiel mit den initialen Zentroiden m1 = (1,1)T und m2 = (0,0)T verdeutli\n",
    "    - **Lösung**:  stets als initiale Zentroiden Datenpunkte aus dem Datensatz auswählen.\n",
    "\n",
    "2. **Lokale Optima**: Der K-Means-Algorithmus ist ein heuristischer Algorithmus, der lokale Optima berechnet und dabei sogar beliebig weit vom globalen Optimum entfernt sein kann. Dies wird durch das Beispiel mit den Datenpunkten und den initialen Zentroiden m1 = (6,1)T und m2 = (6,2)T illustriert. Der Algorithmus weist die beiden unteren Punkte dem Zentroiden m1 und die beiden oberen Punkte dem Zentroiden m2 zu, was zu einem Verzerrungswert von 16 führt, obwohl die optimale Aufteilung einen Verzerrungswert von 2 hätte.\n",
    "\n",
    "    - **Lösung**:\n",
    "     \n",
    "         - **Mehrfache Durchführung mit zufälligen Zentroiden**: Eine Lösung besteht darin, den K-Means-Algorithmus mehrmals mit zufällig verteilten Zentroiden laufen zu lassen und das Clustering auszuwählen, das am häufigsten berechnet wird oder das Clustering mit minimaler Verzerrung. Dies ist auch der in der Praxis gängige Ansat\n",
    "         - **Geschickte Wahl der initialen Zentroiden**: Eine weitere Möglichkeit besteht in einer geschickteren Wahl der initialen Zentroiden, wie es beispielsweise der **K-Means++-Ansatz** verfolgt. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ed55f12-4697-4a1a-b40c-d253ce142558",
   "metadata": {},
   "source": [
    "##### K-Means++\n",
    "- **Grundidee**: Für eine gegebene Anzahl k von Clustern und einen Datensatz E, k Datenpunkte aus E als initiale Zentroiden zu wählen.\n",
    "- Die Zentroiden werden jedoch **nicht zufällig gleichverteilt** ausgewählt, sondern **gewichtet nach der Distanz zu den bisher ausgewählten \n",
    "Zentroide**.\n",
    "    - **!!!!!** Nur der **erste Zentroid $m_1$** gleichverteilt zufällig ausgewählt. \n",
    "- Die ausgewählten Zentroiden werden dann in Zeile 1 von Algorithmus 1 als initiale Definition der Zentroiden benutzt und der eigentliche K-Means-Algorithmus wird anschließend ausgeführt.\n",
    "- Ein beliebiger, noch nicht gewählter \n",
    "Datenpunkt wird dann als ä¨chster Zentroid mit Wahrscheinlichkeit proportional zu dieser Distanz geä¨hl.\n",
    "-  der Verzerrungswert des errechneten Clusterings ist \n",
    "maximal um einen Faktor O(logk) gö¨ßer als de  Verzerrungswert des optimalen Clusterings\n",
    "-  Wir erhalten eine Garantie über die durchschnittliche Güte des Algorithmus..\n",
    "![](.\\K-means++.PNG)tn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0515d5-4ef8-49b7-ab6c-7858e7de4bbd",
   "metadata": {},
   "source": [
    "### 3.2. Hierarchisches Clustering <a name=3.2.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d89aa-f673-4474-b3ed-794d4aa57bb5",
   "metadata": {},
   "source": [
    "#### Clusteranzahl und hierarchisches Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92287f6-9779-4c1e-8da8-f2dbcd5bdd6d",
   "metadata": {},
   "source": [
    "- **Herausforderung in der Clusteranalyse**: Bestimmung der optimalen Anzahl `k` von Clustern für einen gegebenen Datensatz.\n",
    "- **Lösung**:\n",
    "    - heuristische Methode: Ellenbogenmethode\n",
    "\n",
    "- **Aber**  es gibt keine allgemeingültige Definition der \"richtigen\" Anzahl von Clustern. **Abhängig vom Anwendungsfall können für denselben Datensatz verschiedene Clusterzahlen sinnvoll sein**.\n",
    "\n",
    "- die Clusteranalyse ist ein \n",
    "wichtiges**Analysewerkzeug**g.- Hierarchisches Clustering ist eine Methode, die eine Hierarchie von Clustern erzeugt und bietet Einblicke in die Beziehungen zwischen verschieden granularen Clusterings $\\Rightarrow$ hilft bei der Bestimmung der optimalen Clusterzahl für die gegebene Anwendung.\n",
    "\n",
    "- die Ausgabe einer solchen hierarchischen Clusteringmethode gegeben durch ein **Dendrogramm**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f1646-39dd-4f76-b6a1-c30b0cf729cc",
   "metadata": {},
   "source": [
    "##### Dendrogramm\n",
    "\n",
    "Sei $E$ ein Datensatz. Ein Dendrogramm $T$ über $E$ ist ein **gerichteter** Baumdiagramm $T = (V,K,r)$, der die Hierarchie der Cluster in einem Datensatz darstellt, mit Knoten $V$, Kanten $K$ und Wurzel $r \\in V$, sodass gilt:\n",
    "- Für alle $v \\in V$, $v \\subseteq E$.\n",
    "- $r = E$:\n",
    "\n",
    "-  Die Wurzel des Baums repräsentiert den gesamten Datensatz. Die Wurzel enthält das gröbste Clustering, bei dem alle Datenpunkte im gleichen Cluster sind.\n",
    "- Für alle $x \\in E$ ist $\\{x\\}$ ein Blatt von $T$:\n",
    " Jedes Blatt repräsentiert einen einzelnen Datenpunkt. Die Blätter des Dendrogramms enthalten das detaillierteste Clustering.\n",
    "- Jeder innere Knoten $v$ mit Kindern $v_1,..., v_k$ stellt einen Cluster dar, der aus der Vereinigung seiner Untercluster $v_1,..., v_k$ besteht.\n",
    "\n",
    "- Ein Dendrogramm wird üblicherweise mit **Schwellwerten** annotiert, die notwendig sind, um Cluster zu vereinigen.\n",
    "    - Dieses Dendrogramm wird dann als **quantitativ** bezeichnet.\n",
    "    - Diese Schwellwerte sind **algorithmenabhängig**.\n",
    "    - Ein \"**Schnitt**\" durch das Dendrogramm an einem bestimmten Schwellwert ergibt ein konkretes Clustering.\n",
    "\n",
    "- Jede Verzweigung im Dendrogramm repräsentiert eine spezifische Gruppierung der Daten in Cluster.\n",
    "- Quantitative Dendrogramme ermöglichen es, abhängig von der Interpretation der Distanzfunktion, die Plausibilität von Clusterings verschiedener Hierarchiestufen quantitativ **abzuschätzen**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b25203-9eff-4d5d-b975-ee3ab17c2486",
   "metadata": {},
   "source": [
    "##### Methoden des hierarchischen Clusterings:\n",
    "\n",
    "Methoden des hierarchischen Clusterings lassen sich grundsätzlich in zwei Gruppen einteilen:\n",
    "\n",
    "- **agglomerative Verfahren** (bzw. bottom-up Verfahren) beginnen die Konstruktion eines Dendrogramms von den Blättern an.\n",
    "    - Zunächst werden alle Datenpunkte individuell einem Cluster zugewiesen.\n",
    "    - Anschließend werden iterativ diejenigen Cluster miteinander vereinigt, die am ”ähnlichsten“ sind.\n",
    "- **divisive Verfahren** (bzw. top-down Verfahren) beginnen die Konstruktion eines Dendrogramms an der Wurzel. Zunächst werden alle Datenpunkte einem einzigen Cluster zugewiesen. Anschließend wird iterativ der aktuelle Knoten in zwei (oder) mehr Cluster\n",
    "aufgeteilt.\n",
    "\n",
    "Konkrete Clusteringverfahren dieser beiden Gruppen **unterscheiden** sich hauptsächlich durch die benutzte **Ähnlichkeits- bzw. Distanzfunktion**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa266e-0db8-423f-954d-78132ae72f7b",
   "metadata": {},
   "source": [
    "#### Single-Link-Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24d980-cb2a-4b92-9489-350ddf89eebd",
   "metadata": {},
   "source": [
    "- ist ein agglomeratives Clusteringverfahren.\n",
    "- liefert relativ **”langgezogene“ Cluster** und eignet sich daher gut für entsprechend strukturierte Daten.\n",
    "- Es funktioniert wie folgt:\n",
    "    - Initial werden alle Datenpunkte des Datensatzes $E$ in einen separaten Cluster gesetzt.\n",
    "    - Anschließend wird iterativ das Paar von Clustern, das am nächsten liegt, zu einem einzigen Cluster zusammengeführt.\n",
    "    Auf diese Weise entsteht bottom-up ein Dendrogramm.\n",
    "    - Die Menge `X` speichert zu jedem Zeitpunkt die Menge von Clustern, die noch vereinigt werden müssen.\n",
    "    - Am Ende des Algorithmus enthält `X` dann nur noch die Wurzel des konstruierten Baumes (Zeile 10).\n",
    "    - Falls es mehrere Paare von Mengen mit minimalem Abstand in Zeile 7 gibt, wählen wir zufällig ein Paar aus.\n",
    "\n",
    "\n",
    "![Single-Link-Clustering](./KE3_Unueberwachtes_Lernen/3_2_Hierarisches_Clustering/dataset/single-link-clustering.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e8a2c-a146-488a-959e-9a0f00f80bc0",
   "metadata": {},
   "source": [
    "##### Distanzfunktionen $D_{single}$ und $D_{avg}$\n",
    "\n",
    "- Je nach Definition der Distanzfunktion D erhält man ein anderes konkretes Clusteringverfahren.\n",
    "    1. Die **Distanzfunktion $D_{single}$** ist definiert durch:\n",
    "    $$D_{\\text{single}}(E_1,E_2) = \\min_{x_1 \\in E_1, x_2 \\in E_2} ||x_1 - x_2||$$\n",
    "      Der Abstand zwischen zwei Mengen $E_1$ und $E_2$ ist also der **minimale**  (euklidische) Abstand von beliebigen Datenpunkten aus $E_1$ und $E_2$.\n",
    "    \n",
    "    2. Die **Distanzfunktion $D_{avg}$** ist definiert durch: $$D_{\\text{avg}}(E_1,E_2) = \\frac{1}{|E_1||E_2|} \\sum_{x_1 \\in E_1, x_2 \\in E_2} |x_1 - x_2|$$\n",
    "    Die Funktion $D_{\\text{avg}}$ misst den durchschnittlichen Abstand von Datenpunkten in $E_1$ zu Datenpunkten in $E_2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382fb33-c524-426e-8ccd-b732ae55e5df",
   "metadata": {},
   "source": [
    "#### Divisive Analysis clustering (DIANA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a702e-673e-42ba-8ecc-d7fe3507cb53",
   "metadata": {},
   "source": [
    "- ein prototypisches **divisives** Verfahren.\n",
    "- die Ausführung des DIANA-Algorithms weitaus **aufwändiger** als die Berechnung mit einem agglomerativen Clusteringverfahren.\n",
    "- In der Praxis werden deshalb nur sehr selten divisive Verfahren \n",
    "angewendet\n",
    "\n",
    "-**Funktionsweise**e:\n",
    "    1. Man beginnt die Konstruktion eines Dendrogramms an der Wurzel mit einem Cluster, der alle Datenpunkte eines gegebenen Datensatzes $E$ enthält\n",
    "    2. dann teiltman  iterativ solche Blattknoten auf, die noch mehr als einen Datenpunkt enthalten.\n",
    "- Hierbei wird auch eine Distanzfunktion $D$ zur Distanzberechnung von Mengen von Datenpunkten benötigt (wie etwa $D_{\\text{single}}$ oder $D_{\\text{avg}}$).\n",
    "\n",
    "- Die tatsächliche Entscheidung, wie ein Knoten $X$ mit $X| > 1$ in zwei Cluster aufgeteilt wird, erfolgt wie folgt.\n",
    "    1. Zunächst wird der Knoten $\\hat{x}$ aus $X$ gesucht, der am weitesten entfernt von allen anderen Knoten in $X$ is ist.\n",
    "    \n",
    "    2. Dann wird initial $X$ aufgeteilt in einen Cluster $X_1$, der nur $\\hat{x}$ enthält, und einen Cluster $X_2$, d der alle übrigen Datenpunkte aus $X$ enthält.\n",
    "    \n",
    "    3. Anschließend wird der Datenpunkt $x^† \\in X_2$ gesucht, der von allen Punkten aus $X_2$ am ehesten noch zu $X_1$ gehören kann.\n",
    "    \n",
    "    4. Ist $x^†$ darüber hinaus auch näher an $X_1$ als an $X_2$, so verschieben wir $x^†$ von $X_2$ zu $X_1$.\n",
    "    \n",
    "    5. Finden wir keinen Datenpunkt $x \\in X_2$, der näher an $X_1$ als am Rest von $X_2$ liegt, so beenden wir die Konstruktion.\n",
    "    \n",
    "    6. Und setzen $X_1$ und $X_2$ als neue Kinder von $X$ im Baum ein. \n",
    "\n",
    "\n",
    "![DIANA-Clustering](./KE3_Unueberwachtes_Lernen/3_2_Hierarisches_Clustering/dataset/Diana-algo.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f0f83-3381-4210-b585-98c0572b68b0",
   "metadata": {},
   "source": [
    "### 3.3. Assoziationsregellern <a name=3.3.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008091a2-0ee9-40aa-8b1c-00562ee32dd8",
   "metadata": {},
   "source": [
    "- **Ziel**: Strukturen in Daten zu erkennen. Insbesondere werden häufig *zusammen auftretende Mengen von Elementen und Assoziationen zwischen Elementen* gesucht.\n",
    "\n",
    "#### Assoziationsregeln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34959ad6-843b-483b-8f80-18c495f50858",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "- Die **Eingabedaten für Assoziationsregellernen** sind anders strukturiert als bei anderen maschinellen Lernverfahren.\n",
    "- Ein Datensatz besteht aus einer Menge von **Transaktionen**, die jeweils aus einer Menge von Elementen bestehen.\n",
    "\n",
    "##### **(Assoziations-)Regel**\n",
    "\n",
    "- Sei $I$ eine Menge beliebiger Elemente.\n",
    "- Ein Datensatz $F$ ist dann eine Multimenge $F = {t_1,...,t_m}$ (die Transaktionen) mit $t_i ⊆ I$, wobei $i = 1,...,m$.\n",
    "\n",
    "- Eine (Assoziations-)Regel hat die Form $X ⇒ Y$ mit $X,Y ⊆ I$\n",
    "- Es wird \"Wenn X dann auch Y\" gelesen.\n",
    "- Hier heißt $X$ auch Prämisse und $Y$ Konklusion.\n",
    "- **<ins>Das Ziel des Assoziationsregellernens</ins>** ist es, Regeln wie {Brot} ⇒ {Käse} automatisch aus dem Datensatz zu extrahieren.\n",
    "- Wir sind in der Regel nicht nur an allgemeingültigen Regeln interessiert, sondern an Regeln, die **häufig** auftreten.\n",
    "- Um den Aspekt der Häufigkeit zu formalisieren, gibt es eine Reihe von Evaluationsmetriken für Regeln. Die wichtigsten sind der **Support** und die **Konfidenz** (engl. confidence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e015fad-e8d8-42aa-bcc3-c2fc926dca24",
   "metadata": {},
   "source": [
    "\n",
    "##### Support $support_F(X)$\n",
    "\n",
    "- gibt einen Hinweis darauf, wie oft eine Regel angewendet werden kann.\n",
    "\n",
    "Seien $X, Y ⊆ I$:\n",
    "\n",
    "- Der **Support von X** in $F$, bezeichnet als $support_F(X)$, ist der Anteil der Transaktionen in den Daten, bei denen $X$ eine Teilmenge ist, zur Gesamtzahl aller Transaktionen. Bzw. Der Prozentsatz der Transaktionen in den Daten die den Artikel oder die Artikelgruppe enthalten.\n",
    "\n",
    "  Es wird definiert durch:\n",
    "    $$support_F(X) = \\frac{|{t \\in F | X \\subseteq t}|}{|F|}$$\n",
    "\n",
    "  Zum Beispiel ist der Support von ${Zucker, Mehl}$ gleich $\\frac{5}{10}$, was bedeutet, dass Zucker und Mehl zusammen in $50%$ der Transaktionen vorkommen.\n",
    "\n",
    "- Der **Support einer Regel X ⇒ Y** in F, bezeichnet als $support_F(X ⇒ Y)$, ist der Anteil der Transaktionen, bei denen die Regel angewendet werden kann, zur Gesamtzahl aller Transaktionen.\n",
    "\n",
    "  Es wird definiert durch:\n",
    "    $$support_F(X \\Rightarrow Y) = support_F(X \\cup Y)$$\n",
    "\n",
    "##### Konfidenz $conf_F(X \\Rightarrow Y)$\n",
    "\n",
    "- gibt an, wie gut die Regel den Zusammenhang zwischen Prämisse und Konklusion abbildet.\n",
    "\n",
    "Seien $X, Y ⊆ I$:\n",
    "- Die **Konfidenz einer Regel X ⇒ Y** in F, bezeichnet als $conf_F(X ⇒ Y)$, ist der Anteil der Transaktionen, bei denen die Regel angewendet werden kann, zur Anzahl der Transaktionen, bei denen die Prämisse der Regel vorhanden ist. Bzw. Der Prozentsatz der Transaktionen, die A enthalten, die auch B enthalten.\n",
    "  Es wird definiert durch:\n",
    "    $$conf_F(X \\Rightarrow Y) = \\frac{support_F(X \\cup Y)}{support_F(X)}$$\n",
    "\n",
    "  Zum Beispiel ist die Konfidenz von ${Zucker, Mehl} ⇒ {Butter}$ gleich $\\frac{4}{5}$, was bedeutet, dass, wenn Zucker und Mehl gekauft werden, in 80% der Fälle auch Butter gekauft wird.\n",
    "\n",
    ">Beachten Sie:\n",
    ">- dass die Werte von $support_F$ und $conf_F$ stets zwischen 0 und 1 liegen.\n",
    ">\n",
    ">- Beim Assoziationsregellernen ist es das Ziel, Regeln mit **möglichst hohem Support und hoher Konfidenz** zu lernen.\n",
    ">  \n",
    ">- im Allgemeinen der **Support** einen Hinweis darauf gibt, wie oft eine Regel angewendet werden kann, während die **Konfidenz** angibt, wie gut die Regel den Zusammenhang zwischen Prämisse und Konklusion abbildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce8e5d6-c6c6-42a2-852d-31b7e937117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>a</th>\n",
       "      <th>s</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   z  a  s  v  p\n",
       "0  1  1  0  1  1\n",
       "1  1  1  1  1  0\n",
       "2  1  1  0  0  0\n",
       "3  1  0  1  1  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [[1,1,0,1,1],\n",
    "       [1,1,1,1,0],\n",
    "       [1,1,0,0,0],\n",
    "       [1,0,1,1,0]]\n",
    "\n",
    "columns = ['z','a','s','v','p']\n",
    "\n",
    "F = pd.DataFrame(data, columns=columns)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ed09ae-4478-457a-8130-5b477eefa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_all_elements(lst):\n",
    "    result = (F[lst[0]] == 1)\n",
    "    for i in range(1,len(lst)):\n",
    "        result &= (F[lst[i]] == 1)\n",
    "    return result\n",
    "\n",
    "def supportF(list1):\n",
    "    return supportF_regel(list1, [])\n",
    "\n",
    "def supportF_regel(list1, list2):\n",
    "    return intersection_all_elements(list1+list2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07304dce-f799-45a8-ba59-a0454640d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 1.0\n",
      "a = 0.75\n",
      "s = 0.5\n",
      "v = 0.75\n",
      "p = 0.25\n"
     ]
    }
   ],
   "source": [
    "for i in columns:\n",
    "    print(f'{i} = {supportF([i])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4deb5c25-9fb1-4d0e-a29e-30e8b13b3a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(supportF(['z','a']))\n",
    "print(supportF(['z','v']))\n",
    "print(supportF(['v','a']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f635845a-88cc-442c-967e-656c04f6d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(supportF(['z','a', 'v']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76a5b2-f9aa-4b2d-8673-c27f80bf2e32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### A-Priori-Algorithmus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596db2ac-fc46-43cb-8f6e-d3a3c0cddc9d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Der Apriori-Algorithmus ist der klassische Algorithmus zum Lernen von Assoziationsregeln aus Daten.\n",
    "- Neben dem eigentlichen Datensatz bekommt der Algorithmus noch zwei Parameter:\n",
    "    - Der Parameter $minsupp \\in [0,1]$ (minimal support) gibt an, welchen minimalen Wert $support_F(X \\Rightarrow Y)$ eine gelernte Regel $X \\Rightarrow Y$ haben muss,\n",
    "    - der Parameter $minconf \\in [0,1]$ (minimal confidence) gibt an, welchen minimalen Wert $conf_F(X \\Rightarrow Y)$ haben muss.\n",
    "- Die **Ausgabe** des Algorithmus besteht dann aus allen Regeln, die diese beiden Bedingungen erfüllen.\n",
    "- Durch Variation von $minsupp$ und $minconf$ kann die Anzahl gelernter Regeln gesteuert werden.\n",
    "\n",
    "\n",
    "Der Apriori-Algorithmus verfährt in **zwei** Schritten:\n",
    "1. Bestimmung der häufigen Mengen (engl. frequent item sets).\n",
    "3. Berechne solche Regeln $X \\Rightarrow Y$ aus $Z$, sodass $X \\cup Y$ häufig ist und für die $conf_F(X \\Rightarrow Y) \\geq minconf$ gilt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2084a0c-7c5e-4e9e-8fc8-5c792c1bed07",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Schritt 1** ***Bestimmung der häufigen Mengen (engl. frequent item sets)***:\n",
    "    - alle Mengen $Z ⊆ I$ bestimmt, die $support_F(Z) ≥ minsupp$ erfüllen.\n",
    "    -  Zunächst werden alle Mengen $X \\subseteq I$ bestimmt, die $support_F(X) \\geq minsupp$ erfüllen.\n",
    "    -  Notwendigerweise muss dann für alle Regeln $X \\Rightarrow Y$ mit $support_F(X \\Rightarrow Y) \\geq minsupp$ gelten, dass $X \\cup Y = Z$ für solch ein $Z$ gilt.\n",
    "\n",
    "   Um eine stumpfe Auflistung aller Teilmengen und Überprüfung des Supports zu vermeiden, benutzt der Apriori-Algorithmus die folgende Einsicht.\n",
    "\n",
    "   **Proposition 1**\n",
    "    Sei $X \\subseteq I$.\n",
    "  - Wenn $support_F(X) \\geq minsupp$ dann $support_F(X') \\geq minsupp$ für jedes $X'  \\subseteq X$.\n",
    "  - Wenn $support_F(X) < minsupp$ dann $support_F(X') < minsupp$ für jedes $X' \\supseteq X$.\n",
    "\n",
    "    Mit anderen Worten, Teilmengen häufiger Mengen sind häufig und Obermengen nicht-häufiger Mengen sind nicht-häufig.\n",
    "\n",
    "1. **Berechnung der ein-elementigen Mengen**: Der Algorithmus betrachtet zunächst alle ein-elementigen Mengen und berechnet deren Suppor *Nur die Mengen, deren Support größer oder gleich `minsupp` ist, werden weiter berücksichtigt.*\n",
    "2. **Aus diesen Mengen werden Kandidaten für häufige zwei-elementige Mengen gebildet**, indem je zwei verschiedene ein-elementige Mengen vereinigt werden:\n",
    "   - Alle zwei-elementigen Mengen, deren Support nicht größer oder gleich `minsupp` ist, werden aussortierten\n",
    "\n",
    "3. **Aus den häufigen zwei-elementigen Mengen werden Kandidaten für häufige drei-elementige Mengen gebildet**, indem Paare von zwei-elementigen Mengen vereinigt werden, die genau ein Element gemeinsam haben:\n",
    "    - Alle drei-elementigen Mengen, bei denen nicht alle zwei-elementigen Teilmengen häufig sind, werden aussortiert.\n",
    "    - Ebenso werden alle drei-elementigen Mengen aussortiert, deren Support nicht größer oder gleich `minsupp` ist.\n",
    "4. **Weiterführung des Prozesses**: Der Algorithmus fährt entsprechend mit der Berechnung häufiger vier-elementiger Mengen fort bis keine weiteren häufigen Mengen gefunden werden.\n",
    "5. Dieser Prozess wird **iterativ** fortgesetzt, bis keine weiteren häufigen Mengen gefunden werden können.\n",
    "6. Jede Iteration erhöht die Kardinalität der betrachteten Mengen um eins.\n",
    "7. Der Algorithmus endet, wenn keine weiteren häufigen Mengen gefunden werden können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26070354-b49f-46fe-9f34-a7dae07d8bdb",
   "metadata": {},
   "source": [
    "\n",
    "**2. Berechne solche Regeln $X \\Rightarrow Y$ aus $Z$, sodass $X \\cup Y$ häufig ist und für die $conf_F(X \\Rightarrow Y) \\geq minconf$ gilt.**\n",
    "\n",
    "Seien $X$, $Y$, $Y′$ Teilmengen von $I$ mit $Y′ ⊆ Y ⊆ X$. Dann gilt:\n",
    "\n",
    "$$\n",
    "confF((X \\setminus Y′) ⇒ Y′) ≥ confF((X \\setminus Y) ⇒ Y)$$\n",
    "\n",
    "- Mit anderen Worten, die Konfidenz einer Regel X ⇒ Y kann nicht geringer werden, wenn wir ein Element von Y nach X verschieben, d. h., die Prämisse der Regel weiter spezialisieren.\n",
    "- Diese Einsicht nutzen wir, indem wir zunächst alle Regeln mit ein-elementiger Konklusion betrachten, die wir aus einer häufigen Menge X erzeugen können.\n",
    "- Dann werden wie beim Algorithmus FreqItems (siehe Algorithmus 1) größere Kandidaten für Konklusionen generiert und die Regeln entsprechend auf ihre Konfidenz getestet.\n",
    "\n",
    "\n",
    "**Das Problem mit dem Apriori-Algorithmus** besteht darin, dass er eine relativ große Menge an Kandidaten für häufige Mengen generiert, was sowohl die Anzahl der zu betrachtenden Kandidaten als auch den Aufwand zur Berechnung ihres Supports erhöht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87b7ab-15ea-4eac-bf36-0101a79c8ddb",
   "metadata": {},
   "source": [
    "#### Der FP-Growth-Algorithmus (Frequent pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86320780-85ac-4eea-b82d-c5ac770947e6",
   "metadata": {},
   "source": [
    "-  Der **FP-Growth-Algorithmus** ist eine Weiterentwicklung des Apriori-Algorithmus.\n",
    "-  FP steht für \"frequent pattern\", also \"häufige Mengen\".\n",
    "-  berücksichtigt **signifikant weniger Kandidaten** und ist daher **signifikant schneller** als der Apriori-Algorithmus.\n",
    "-  konzentriert sich auf das Teilproblem der **Extraktion häufiger Mengen**, das beim Apriori-Algorithmus durch den Algorithmus FreqItems gelöst wird.\n",
    "-  Die **Bestimmung von Assoziationsregeln** aus den häufigen Mengen funktioniert analog zur Extraktion der häufigen Mengen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0232e4-4507-479c-96be-320ede0ddc10",
   "metadata": {},
   "source": [
    "**Funktionsweise**: Der FP-Growth-Algorithmus besteht aus zwei Hauptteilen:\n",
    "\n",
    "1. **Datensatz und Support**: Gegeben ist ein Datensatz `F` mit Elementen `I` und einem minimalen Support `minsupp`. Ziel ist es, häufige Mengen `X` aus `I` zu bestimmen, für die gilt: `supportF(X) ≥ minsupp`.\n",
    "   - Neben dem relativen minimalen Support `minsupp` ist es hilfreich, den absoluten minimalen Support `minsuppabs` zu betrachten.\n",
    "   - Für einen konkreten Datensatz `F` ist der absolute minimale Support definiert durch `minsuppabs = ⌈minsupp∗|F|⌉`.\n",
    "   - Dies entspricht der Anzahl an Transaktionen von `F`, bei denen eine Menge `M` enthalten sein muss, um als häufig zu gelten.\n",
    "\n",
    "3. **FP-Growth-Algorithmus**: Der FP-Growth-Algorithmus berechnet die häufigen Mengen in zwei Schritten:\n",
    "   - **Erster Schritt**: Der Datensatz `F` wird in eine besondere Datenstruktur, den sogenannten FP-Baum `TF`, gelesen. Der FP-Baum enthält alle für das Extrahieren von häufigen Mengen relevanten Informationen aus `F` und ist in der Regel weitaus kompakter.\n",
    "   - **Zweiter Schritt**: Aus dem FP-Baum `TF` werden die häufigen Mengen extrahiert. Aufgrund der intelligenten Struktur von `TF` ist dies mit weniger Mehraufwand verbunden als beim Apriori-Algorithmus.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f84fa-5b3d-4afe-a6a2-e7809b43186c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FP-Baum\n",
    "\n",
    "- Ein FP-Baum ist eine Repräsentation davon, welche Elemente einen höheren Konfidenz-Wert haben als andere.\n",
    "- In einem FP-Baum können Elemente mehrfach vorkommen.\n",
    "- Ein FP-Baum ist eine kompakte Repräsentation davon, welche Elemente häufig vorkommen und mit welchen anderen häufigen Elementen sie oft auftreten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4873654-665d-4267-8b35-5d0887cd4690",
   "metadata": {},
   "source": [
    "Sei $I$ eine Menge von Elementen. Ein **FP-Baumknoten** $N$ zu $I$ ist eine Datenstruktur $N = (x, f, p)$ mit\n",
    "1. $x \\in I$,\n",
    "2. $f \\in \\mathbb{N}$,\n",
    "3. $p$ ist ein FP-Baumknoten (der Elternknoten von $N$).\n",
    "\n",
    "Ein FP-Baum $T$ zu $I$ ist eine Datenstruktur $T = (N_0,V)$ mit\n",
    "1. $N_0$ ist ein FP-Baumknoten mit $N_0 = (\\text{null},0,\\text{null})$ (die Wurzel des Baumes)\n",
    "2. $V$ ist eine Menge von FP-Baumknoten, so dass für alle $N \\in V$ mit $N = (x, f, p)$ gilt: $p \\in V \\cup \\{N_0\\}$.\n",
    "   - Dabei gibt $p$ den Elternknoten von $N$ an.\n",
    "   - Jeder Knoten $N \\in V$ verfügt über einen eindeutigen Pfad zur Wurzel über seinen Elternknoten. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51846e7-db9f-4dbe-9d07-8fc8076cd29a",
   "metadata": {},
   "source": [
    "1. Ein FP-Baum (TF) wird so aufgebaut, dass die Knoten (außer der Wurzel) die Elemente $x \\in I$ enthalten, die häufig in einem Datensatz F vorkommen können.\n",
    "2. Jeder Knoten N ist ein Tripel $N = (x, f, p)$, wobei:\n",
    "    - $x$ das jeweilige Element ist,\n",
    "    - $f$ die absolute Häufigkeit von $x$ ist (bezogen auf den Teilpfad bis N),\n",
    "    - $p$ auf den Elternknoten verweist.\n",
    "3. Jeder Pfad von der Wurzel bis zu einem Blatt repräsentiert eine Menge von Elementen, die bereits als häufig in F erkannt wurden.\n",
    "4. Um einen FP-Baum aus einem Datensatz F zu erstellen, bestimmen wir zunächst alle häufigen ein-elementigen Mengen $\\{x\\}$ mit $x \\in I$.\n",
    "5. Die Elemente in $I_f = (x_1,..., x_k)$ sind absteigend nach Support geordnet; bei gleichem Support-Wert zweier Elemente wird die Reihenfolge willkürlich, aber fest definiert.\n",
    "6. Für jede Transaktion $t \\in F$ ist $t_f = (x_{t,1},..., x_{t,n})$ die nach $I_f$ geordnete Liste der häufigen Elemente in t.\n",
    "\n",
    "Diese Punkte geben einen Überblick über die Konstruktion und Interpretation eines FP-Baums. Es ist wichtig zu beachten, dass die genaue Interpretation eines FP-Baums klar wird, wenn wir uns den Algorithmus zur Konstruktion von TF genauer anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149a543-058b-441a-b487-4569954a4416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fabafa5-4e28-41f2-8ac3-261e607b9ab9",
   "metadata": {},
   "source": [
    "### 3.4. Anomalieerkennung <a name=3.4.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c300d-cdd3-492c-947d-d686d01cb8b3",
   "metadata": {},
   "source": [
    "- Bei der **Anomalieerkennung** (engl. anomaly detection) geht es um die Erkennung von abnormalen Datenpunkten oder Ausreißern.\n",
    "- Für eine **Menge von Datenpunkten** $E = {x^{(1)},..., x^{(m)}}$ und ein neuer Datenpunkt $x4$, besteht **Die Frage der Anomalieerkennung** darin zu entscheiden, **ob x ähnlich genug zu den Datenpunkten in E ist oder eher abnormal**.\n",
    "  Üblicherweise verfügt man über eine **große Menge an normalen Datenpunkten** und nur relativ **wenig (oder keine) abnormale Datenpunkte**. Aus diesem Grund benutzt man für Anomalieerkennung üblicherweise **Unüberwachte Lernverfahren**, bei denen nur die Menge E an normalen Datenpunkten gegeben ist.\n",
    "\n",
    ">- Falls wir auch Daten zu **abnormalen** Datenpunkten haben (nicht nur normale Daten), dann wird dieses Problem als ein **Überwachtes Lernproblem** betrachtet.\n",
    "\n",
    "Eine einfache Methode der Anomalieerkennung ist **die Dichteabschätzung einer Normalverteilung**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b2abe-10c3-41b3-b5dd-2158eb640126",
   "metadata": {},
   "source": [
    "#### Die Dichteschätzung einer Normalverteilung\n",
    "\n",
    "- Die Dichteschätzung einer Normalverteilung ist ein **statistischer** Ansatz, der auf der Annahme basiert, dass die **Daten, die wir analysieren, normalverteilt** sind.\n",
    "- Der Ansatz hat zwei Verbindungen zu zur Bayes-Klassifikation:\n",
    "    1. die Dichteabschätzung ist eine **Maximum-Likelihood-Methode**, da das gelernte Modell <ins>auf den Prinzipien der Maximum-Likelihood-Hypothese basiert </ins>.\n",
    "    2. Der Ansatz der Dichteabschätzung löst das angesprochene Problem der Bayes-Klassifikation mit kontinuierlichen Merkmalen, da die dort gesuchte Dichte $p(x_i | c,D)$ damit bestimmt werden kann.\n",
    "\n",
    "\n",
    "- Um das Problem der Anomalieerkennung zu lösen, bilden wir ein wahrscheinlichkeitstheoretisches Modell $p^E$ auf den Datenpunkten.\n",
    "- Die Funktion $p_E(x)$ gibt an, <ins>wie ähnlich ein gegebener Datenpunkt $x$ zu den Datenpunkten in $E$ ist</ins>. \n",
    "    - Ein **hoher** Wert von $p_E(x)$ deutet darauf hin, dass **$x$ sehr ähnlich** zu den meisten Datenpunkten in $E$ ist,\n",
    "    - Ein **niedriger** Wert darauf hindeut, dass **$x$ ist eine Anomalie**.\n",
    "- Die **tatsächliche Klassifikation eines Datenpunktes** $x$ als normal oder abnormal geschieht dann durch einen **Schwellenwert $\\varepsilon$** im Bereich $[0,1]$:\n",
    "    - Wenn $p_E(x) < \\varepsilon$, dann wird $x$ als abnormal klassifiziert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb19e8c-ed08-43ca-be21-9d73b7c4c37b",
   "metadata": {},
   "source": [
    "Die Bestimmung von $p_E$ basiert auf zwei zentralen Annahmen:\n",
    "\n",
    "1. Die Merkmale von $x = (x_1,..., x_n)$ sind **unabhängig voneinander**, d. h., wir können $p_E(x)$ schreiben als\n",
    "\n",
    "$$p_E(x) = p_{E_1}(x_1) \\cdot \\ldots \\cdot p_{E_n}(x_n)$$\n",
    "\n",
    "   mit Wahrscheinlichkeitsdichten $p_{E_1},..., p_{E_n}$ für die Merkmale $x_1,..., x_n$.\n",
    "\n",
    "2. Die Merkmalsausprägungen eines jeden Merkmals $x_i$, $i = 1,...,n$ sind **normalverteilt**, d. h., es gilt\n",
    "\n",
    "$$p_{E_i}(x_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_i}} e^{-\\frac{(x_i-\\mu_i)^2}{2\\sigma^2_i}}$$\n",
    "\n",
    "   für \"passende\" $\\mu_i,\\sigma^2_i \\in \\mathbb{R}$.\n",
    "\n",
    " In diesen Ausdrücken steht `n` für die Anzahl der Merkmale, $x_i$ für den `i`-ten Merkmalswert, $p_{E_i}$ für die Wahrscheinlichkeitsdichte des `i`-ten Merkmals, $µ_i$ für den Mittelwert des `i`-ten Merkmals und $σ²_i$ für die Varianz des `i`-ten Merkmals. \n",
    "\n",
    "> Die beiden obigen Annahmen sind für einen gegebenen Datensatz E eines bestimmten Problems **nicht immer korrekt**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69766d-e812-4040-97ab-fda2aee72fd8",
   "metadata": {},
   "source": [
    "##### **Das Lernproblem**\n",
    "\n",
    "Das Lernproblem besteht daraus, **passende Werte für $µ1,...,µn$ und $σ2_1 ,...,σ2n$ zu finden**.\n",
    "\n",
    "Hier sind die grundlegenden Schritte der Dichteschätzung einer Normalverteilung:\n",
    "\n",
    "1. **Mittelwert und Standardabweichung berechnen**: Zunächst benutzen wir die Maximum-Likelihood-Methode und nehmen an, dass µi genau die **empirischen Mittelwerte** und $σ^2_i$ genau die **empirischen Varianzen** aus dem Datensatz E sind. D.h.:\n",
    "   - Der Mittelwert (µ): der Durchschnittswert der Daten, und\n",
    "   - die Standardabweichung (σ): misst die Streuung der Daten um den Mittelwert.\n",
    "\n",
    "3. **Normalverteilungsfunktion anwenden**: Dann wenden wir die Normalverteilungsfunktion auf jeden Datenpunkt an. Die Normalverteilungsfunktion ist definiert als:\n",
    "\n",
    "    $$p_i^E(x_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_i}} e^{-\\frac{(x_i-\\mu_i)^2}{2\\sigma^2_i}}$$\n",
    "\n",
    "    Dabei ist:\n",
    "    - $p_i^E(x_i)$ die Wahrscheinlichkeitsdichte für den Wert $x$,\n",
    "    - $e$ die Basis des natürlichen Logarithmus,\n",
    "    - $\\mu$ der Mittelwert der Daten $$\\mu_i = \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}_i$$\n",
    "    - $\\sigma$ die Standardabweichung der Daten: $$\\sigma^2_i = \\frac{1}{m} \\sum_{i=1}^{m} (x^{(i)}_i - \\mu_i)^2$$\n",
    "\n",
    "4. **Anomalien identifizieren**: Schließlich identifizieren wir Anomalien als Datenpunkte, deren Wahrscheinlichkeitsdichte unter einem bestimmten Schwellenwert liegt. Dieser Schwellenwert wird oft so gewählt, dass er einen kleinen Prozentsatz (z.B. 1%) der Datenpunkte als anomale betrachtet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a876a-0f58-41e1-9f43-86c4f9249023",
   "metadata": {},
   "source": [
    "### 3.5. Hauptkomponentenanalyse <a name=3.5.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360c395-1668-4c68-91bc-9d564f183b4d",
   "metadata": {},
   "source": [
    "- In der Praxis **treten oft Merkmale mit korrelierenden Ausprägungen auf**, die sich negativ auf den Lernprozess auswirken können.\n",
    "- Beispiele:\n",
    "    - Dopplung eines Merkmals bzw. n-fache eines Merkmals.\n",
    "    - Merkmalen, die nicht perfekt korrelieren, wie beispielsweise Größe und Gewicht einer Person.\n",
    "    - Ein Merkmal ist eine ungefähre Kombination von mehr als einem anderen Merkmal dargestellt werden kann. In solchen Fällen kann es sinnvoll sein, die Daten mit weniger Merkmalen zu beschreiben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d5982-2561-4fcd-b259-84225d04690d",
   "metadata": {},
   "source": [
    "#### Hauptkomponentenanalyse (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660507a3-6b99-4b1f-bb30-733dd5906c6f",
   "metadata": {},
   "source": [
    "- Eine Methode zur Lösung von Problemen, **die mit korrelierenden Merkmalen zusammenhängen.**\n",
    "- ist eine Methode zur **Dimensionsreduktion**.\n",
    "- Sie transformiert einen Datensatz in $\\mathbb{R}^n$ in einen Datensatz in $\\mathbb{R}^{n'}$ mit $n' < n$, wobei möglichst wenig Information verloren geht.\n",
    "- PCA kann als **Vorverarbeitungsschritt** für überwachtes oder unüberwachtes Lernen verwendet werden, oder einfach nur **um einen Datensatz zu komprimieren**.\n",
    "- PCA selbst kann auch <ins>**als eine Methode des unüberwachten Lernens**</ins> verstanden werden, da sie nach **Mustern im Datensatz sucht**.\n",
    "- Die allgemeine Methodik der PCA ist mathematisch **recht komplex**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fa22b-4238-4159-814f-a90f98fd3153",
   "metadata": {},
   "source": [
    "##### Standardisierung\n",
    "- Um PCA anwenden zu können, ist die **Standardisierung** der Daten **notwendig**. \n",
    "- Durch die Standardisierung wird **sichergestellt, dass jedes Merkmal den gleichen Einfluss auf die PCA hat, unabhängig von seiner Skala oder den Einheiten**, in denen es gemessen wird.\n",
    "- Die `z-Transformation` (aus Abschnitt 2.4.2) ist eine gängige Methode zur Standardisierung von Daten. Sie transformiert die Daten so, dass sie **einen Mittelwert von 0** und eine **Standardabweichung von 1** haben. \n",
    "\n",
    "\n",
    "##### Reduktion eines Datensatzes vom $\\mathbb{R}^2$ zum $\\mathbb{R}^1$\n",
    "\n",
    "- Falls PCA **auf ein Problem des überwachten Lernens angewendet** werden soll (wie im obigen Beispiel), so können wir die **Klassen der Beispiele ignorieren**, da die Dimensionsreduktion einzig auf den Datenpunkten realisiert wird.\n",
    "- Angenommen, wir haben einen Datensatz $E = \\{x^{(1)}, ..., x^{(m)}\\}$ mit $x^{(i)} \\in \\mathbb{R}^2$, $i = 1,...,m$.\n",
    "    1. PCA versucht, einen 1-dimensionalen Unterraum (eine Gerade) in $\\mathbb{R}^2$ zu finden, sodass die quadrierten Distanzen aller Punkte in E zu ihren jeweiligen Projektionen auf diesen Unterraum **minimal** sind.\n",
    "    2. Formal löst PCA das folgende Optimierungsproblem:\n",
    "\n",
    "$$v^* = \\arg\\min_{v \\in \\mathbb{R}^2, ||v|| = 1} \\sum_{x \\in E} ||x - (x^T v)v||^2 \\tag{1}$$\n",
    "- Der Vektor $v^*$ **charakterisiert den gesuchten 1-dimensionalen Unterraum als alle Vielfachen von $v^*$**, d.h., die gesuchte Gerade besteht aus allen Punkten $w \\in \\mathbb{R}^2$ mit $w = xv^*$ für $x \\in \\mathbb{R}$. \n",
    "- Der Ausdruck $||x - (x^T v)v||$ ist der Abstand des Punktes x zu der von v aufgespannten Geraden. \n",
    "- Die zusätzliche Bedingung $||v|| = 1$ fordert, **dass v genau Länge 1** hat. Diese Bedingung dient nur **der Normierung**. \n",
    "- Das Problem ist im Allgemeinen  **<ins>nicht</ins> eindeutig lösbar**, in diesem Fall ist $v^*$ eine beliebige minimale Lösung. \n",
    "- Der Vektor $v^*$ wird dann **als (erste) Hauptkomponente von E** bezeichnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e1962-5a43-434a-8e7d-92ecd61fe982",
   "metadata": {},
   "source": [
    "- Wenn $v^*$ bestimmt ist, können wir  den Datensatz $E$ komprimieren, indem wir für jeden Datenpunkt $x \\in E$ anstatt der beiden Koordinaten $x = (x_1, x_2)^T \\in \\mathbb{R}^2$ **nur die Koordinate $z \\in \\mathbb{R}$ speichern**, sodass $zv^*$ die Projektion von $x$ auf die durch $v^*$ aufgespannte Gerade ist.\n",
    "- Wir erhalten damit einen komprimierten Datensatz $E_{\\text{compressed}}$.\n",
    "- **Das daraus entstehende Modell** (also beispielsweise ein Klassifikator `clf`) ist damit **allerdings nur auf 1-dimensionalen Datenpunkten definiert** (also `clf` : $\\mathbb{R}^1 \\rightarrow C$, wobei $C$ die Menge der Klassen ist).\n",
    "- Um Datenpunkte $x \\in \\mathbb{R}^2$ des ursprünglichen Problems mit `clf` zu klassifizieren, müssen wir für diese die entsprechende Projektion auf der von $v^*$ aufgespannten Gerade und damit deren Koordinate bzgl. $v^*$ bestimmen. Diese ist gegeben durch $$z = x^T v^*$$ und damit können wir via `clf(x^T v^*)` auch Datenpunkte $x \\in \\mathbb{R}^2$ des ursprünglichen Problems klassifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ad27b-55a4-4147-91b7-e20dced4b3bd",
   "metadata": {},
   "source": [
    "#### Hauptkomponentenanalyse und lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6def309-3cee-426d-9839-6b13af4da59d",
   "metadata": {},
   "source": [
    "- die lineare Regression:\n",
    "    - **minimiert die Summe der quadrierten \"vertikalen Abstände\"** zu der gesuchten Geraden.\n",
    "    - da geht es um **Funktionsapproximation**.\n",
    "- die PCA :\n",
    "    - **minimiert die tatsächlichen (quadrierten) Abstände zu der Geraden**, d.h., die kürzeste Verbindung zur Geraden (beachten Sie, dass diese Anschauung nur im 2-dimensionalen gültig ist).\n",
    "    - da geht es um **Dimensionsreduktion**.\n",
    "- Für typische 2-dimensionale Probleme sind die Lösungen dieser beiden Optimierungsprobleme **nicht identisch**, oft aber auch recht ähnlich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97206d05-5862-4128-9b5e-bd8d43d7f093",
   "metadata": {},
   "source": [
    "#### Allgemeine Hauptkomponentenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33861c-17ed-4acf-bf8d-931e021fbe8d",
   "metadata": {},
   "source": [
    "- betrachten wir das Problem, einen Datensatz $E$ mit $x^{(i)} \\in \\mathbb{R}^n$ auf einen Datensatz $E_{\\text{compressed}}$ mit $z^{(i)} \\in \\mathbb{R}^{n'}$ zu komprimieren, für $n' < n$.\n",
    "- Wir gehen davon aus, dass der Datensatz $E$ standardisiert ist, d.h., dass der Mittelwert aller Merkmalsausprägungen 0 ist.\n",
    "\n",
    "- $\\longrightarrow$ wir **suchen einen $n'$-dimensionalen Unterraum von $\\mathbb{R}^n$, sodass die Summe der quadrierten Abstände von jedem Punkt $x \\in E$ zu seiner Projektion $\\hat{x}$ auf diesem Unterraum minimal ist**.\n",
    "- Einen $n'$-dimensionalen Unterraum kann man charakterisieren **durch $n'$ paarweise orthogonale Einheitsvektoren** $v^*_1,..., v^*_{n'} \\in \\mathbb{R}^n$ (diese bilden dann eine orthonormale Basis, kurz ONB, dieses Unterraums).\n",
    "- Das zugehörige Optimierungsproblem ist damit gegeben durch\n",
    "$$(v^*_1,..., v^*_{n'}) = \\arg\\min_{v_1,...,v_{n'} \\text{ ist ONB}} \\sum_{x \\in E} ||x - (x^T v_1)v_1 - ... - (x^T v_{n'})v_{n'}||^2 \\tag{2}$$\n",
    "**wobei \"v_1,..., v_{n'} ist ONB** heißt, dass $||v_1|| = ... = ||v_{n'}|| = 1$ und $v_i^T v_j = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141bc938-528d-45b4-ac19-cf4e85d32b7e",
   "metadata": {},
   "source": [
    "- **das Problem (1) ein Spezialfall des Problems (2)**.\n",
    "- Ist $(v^*_1,..., v^*_{n'})$ eine Lösung von (2), so ist der gesuchte $n'$-dimensionale Unterraum durch die Menge aller Linearkombinationen von $v^*_1,..., v^*_{n'}$ gegeben.\n",
    "- Die neuen Koordinaten eines Punktes $x \\in \\mathbb{R}^n$ sind dann definiert durch $z \\in \\mathbb{R}^{n'}$ mit $$z = (x^T v^*_1,..., x^T v^*_{n'})$$\n",
    "- Die Vektoren $v^*_1,..., v^*_{n'}$ heißen dann die ersten $n'$ Hauptkomponenten von $E$.\n",
    "- Eine Berechnung von $(v^*_1,..., v^*_{n'})$ durch **explizite Lösung des Optimierungsproblems (2) ist recht aufwändig**.\n",
    "- Es existiert allerdings eine recht elegante algebraische Charakterisierung der Hauptkomponenten durch die Eigenvektoren der Kovarianzmatrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e90c1-9ce5-4015-9847-d6633476f91b",
   "metadata": {},
   "source": [
    "##### Kovarianzmatrix $Cov(E)$\n",
    "Sei $E = \\{x^{(1)}, ..., x^{(m)}\\}$ ein standardisierter Datensatz. Die Kovarianzmatrix $\\text{Cov}(E) \\in \\mathbb{R}^{n \\times n}$ von $E$ ist definiert durch\n",
    "\n",
    "$$\\text{Cov}(E) = \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)} (x^{(i)})^T$$\n",
    "\n",
    "- Die Kovarianzmatrix $\\text{Cov}(E)$ ist **stets symmetrisch und positiv definit**, d.h., es existieren genau $n$ reale Eigenwerte $\\lambda_1,...,\\lambda_n$ (potentiell treten Eigenwerte mehrfach auf) von $\\text{Cov}(E)$ mit $\\lambda_1 \\leq \\lambda_2 \\leq ... \\leq \\lambda_n$\n",
    "\n",
    "Seien nun $w_1,...,w_n$ passende Eigenvektoren mit $||w_1|| = ... = ||w_n|| = 1$, d.h.,\n",
    "\n",
    "$$\\text{Cov}(E)w_i = \\lambda_i w_i$$\n",
    "\n",
    "für alle $i = 1,...,n$. Dann lässt sich zeigen, dass genau diese Eigenvektoren die Hauptkomponenten von $E$ sind:\n",
    "\n",
    "**Theorem 1.** $(w_1,...,w_{n'})$ ist für jedes $n' < n$ Lösung von (2).\n",
    "\n",
    "Das obige Theorem (das wir hier nicht beweisen werden) charakterisiert somit die Hauptkomponenten von $E$ als die (zu den zugehörigen Eigenwerten aufsteigend sortierten) Eigenvektoren von $\\text{Cov}(E)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fc7ad-990d-4aed-9449-a0419ddc6878",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b051ae9-ecf6-4e17-8491-d93ef41022a4",
   "metadata": {},
   "source": [
    "- **Die Frage** bei der Verwendung von PCA ist, **wie weit man die Dimensionalität des Ursprungsraumes reduzieren kann, ohne für die eigentliche Lernaufgabe relevante Informationen zu verlieren (oder ob man überhaupt die Dimensionalität reduzieren sollte)**.\n",
    "- **Die direkteste Lösung**: die Evaluationsmaße der eigentlichen Lernaufgabe für verschiedene Varianten der Dimensionsreduktion zu Rate zu ziehen. Dieser Ansatz ist jedoch **aufwändig**, da wir zum einen Datensätze verschiedener Dimensionalität generieren müssen und zum anderen für jeden dieser Datensätze ein Modell lernen und evaluieren müssen.\n",
    "- **Die übliche Lösung**: den Verlust an Varianz bei einer Dimensionsreduktion zu messen und anschließend die Dimensionalität wählen, bei der der Verlust an Varianz \"nicht zu hoch\" ist (hier sparen wir uns also das erneute Lernen eines Modells):\n",
    "    - Intuitiv beschreibt die Varianz eines Datensatzes $E$ wie weit \"verstreut\" die Datenpunkte $E$ im Raum liegen.\n",
    "    - Für einen standardisierten Datensatz $E = \\{x^{(1)}, ..., x^{(m)}\\}$ ist die Varianz $\\text{var}(E)$ definiert als $$\\text{var}(E) = \\frac{1}{m} \\sum_{i=1}^{m} ||x||^2$$\n",
    "    - und ist $E_{\\text{compressed}}$ eine komprimierte Variante von $E$, so ist $$\\text{retVar}(E_{\\text{compressed}},E) = \\frac{\\text{var}(E_{\\text{compressed}})}{\\text{var}(E)}$$ der Anteil der Varianz von $E$, der in $E_{\\text{compressed}}$ noch erhalten bleibt.\n",
    "    - beachten Sie, dass stets $\\text{var}(E_{\\text{compressed}}) \\leq \\text{var}(E)$ gilt; $\\text{retVar}$ steht hier für retained variance.\n",
    "    - Üblicherweise wählt man $n'$ so klein wie möglich, sodass $$\\text{retVar}(E_{\\text{compressed}},E) \\geq \\alpha$$ für einen Schwellwert $\\alpha \\in [0,1]$ gilt.\n",
    "    - Typische Werte für $\\alpha$ liegen dabei im Bereich [0.9,0.99].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b07b75-c1a7-4ea1-bb81-d8312a370c2e",
   "metadata": {},
   "source": [
    "# 4 Reinforcement Learning <a name=4><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ea3ee-d81b-4047-abaf-367635490730",
   "metadata": {},
   "source": [
    "- unterscheidet sich von den überwachtes und unüberwachtes Lernen  insbesondere durch die **Situierung des Lernalgorithmus**.\n",
    "- Reinforcement Learning (RL) ist eine Methode des maschinellen Lernens, bei der **ein Agent eingebettet in einer Umgebung agiert** und durch **Belohnungen lernt**, optimale **Aktionen auszuführen**.\n",
    "- **Ziel**: Das Ziel eines Reinforcement Learning-Algorithmus ist \n",
    "es, eine Strategie zu  Zielaufgabeg zu ermitteln, sodass die Belohnung**maximiert** wird.\n",
    "\n",
    "Es gibt zwei Arten von RL-Verfahren:\n",
    "1. **Offline-Lernverfahren**: Der Lernalgorithmus hat ein **genaues bzw. korrektes  Modell der Umgebung, der Aktionen und der Belohnungen**.\n",
    "2. **Online-Lernverfahren**: Der Lernalgorithmus hat **kein Vorwissen** und führt **iterativ**  verschiedene Aktionen aus, um zu lernen, welche Strategien erfolgversprechend sind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e298d11-28c8-4530-8336-f85dd5cd6184",
   "metadata": {},
   "source": [
    "### 4.1. Markov-Entscheidungsprozess <a name=4.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db74cc-af73-4080-a5dc-ef0fa47bb3c9",
   "metadata": {},
   "source": [
    "- Eine wichtige Komponente für Reinforcement learning: die **Modellierung der Dynamik der Umgebung**, in der ein Agent eingebettet ist.\n",
    "\n",
    "#### Modellierung der Umgebung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c9350-ffc2-4423-b5e1-5aab692fb160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b58b91e6-0bb4-4fcc-80e3-0025ce935229",
   "metadata": {},
   "source": [
    "- Markov-Entscheidungsprozesse als **Mittel zur Formalisierung \n",
    "dynamischer Prozess**e benutzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573a51d-2889-43e1-bf72-d9dc7c82438c",
   "metadata": {},
   "source": [
    "##### Der Markov-Entscheidungsprozess \n",
    "\n",
    "- Ein MDP ist ein **mathematisches** Modell, das die Umgebung eines lernenden Agenten beschreibt. \n",
    "- Es besteht aus einem <ins>Zustandsraum</ins>, einem <ins>Aktionsraum</ins>, einer <ins>Übergangswahrscheinlichkeitsfunktion</ins>, einer <ins>Belohnungsfunktion</ins>, einem <ins>Startzustand</ins> und einer <ins>Menge von Endzuständen</ins>.\n",
    "\n",
    "> Ein Markov-Entscheidungsprozess (engl. Markov decision process, MDP) D ist ein Tupel $D = (S,A,P,R,s_0,S_t)$ mit folgenden Eigenschaften:\n",
    "> 1. $S$ ist eine Menge aller möglichen Zustände (der Zustandsraum)\n",
    "> 2. $A$ ist eine Menge von Aktionen (der Aktionsraum)\n",
    "> 3. $P : (S \\setminus S_t) \\times A \\times S \\rightarrow [0,1]$ ist eine Funktion (die Übergangswahrscheinlichkeitsfunktion) mit $\\sum_{s' \\in S} P(s,a,s') = 1$ für alle $s \\in S$, $a \\in A$.\n",
    "> 4. $R : (S \\setminus S_t) \\times A \\times S \\rightarrow \\mathbb{R}$ ist eine beliebige reellwertige Funktion (die Belohnungsfunktion, engl. reward function).\n",
    "> 5. $s_0 \\in S$ ist der Startzustand.\n",
    "> 6. $S_t \\subseteq S$ ist die Menge der Zielzustände.\n",
    "\n",
    "$S$ ist eine Menge aller möglichen Zustände inn der sich der Agent befinden kann. In einem Zusatnd $s \\in S$ kann der Agent eine deer Aktionen in $A$ ausführen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062dfbef-ef23-447e-b47c-ebb9d45466e4",
   "metadata": {},
   "source": [
    "- In allgemeinen MDPs ist das Resultat einer Aktion **nicht** immer **deterministisch** bestimmt.\n",
    "- Die *Übergangswahrscheinlichkeitsfunktion* $P(s,a,s')$ gibt die Wahrscheinlichkeit an, dass eine bestimmte Aktion $a$ in einem bestimmten Zustand $s$ zu einem bestimmten neuen Zustand $s'$ führt.\n",
    "- Die *Belohnungsfunktion* $R(s,a,s')$ gibt an, welche Belohnung (oder Strafe, wenn negativ) der Agent erhält, wenn er eine bestimmte Aktion $a$ in einem bestimmten Zustand $s$ ausführt und zu einem bestimmten neuen Zustand $s'$ wechselt. \n",
    "- Der Agent startet im Zustand $s^0$ und D terminiert, sobald der Agent ein Zustand $\\in S^t$.\n",
    "\n",
    "##### Strategie $\\pi$\n",
    "- ist eine Funktion $\\pi : S \\setminus S_t \\rightarrow A$.\n",
    "- Ein Agent besitzt eine Strategie, über die die Zielzustände bestimmt werden.\n",
    "- Um den Agenten in einem MDP zu steuern, besitzt dieser eine **Strategie** (engl. policy), die (im einfachsten Fall) für jeden Zustand die auszuwählende Aktion bestimmt.\n",
    "\n",
    "- **Eine konstante Strategie**:\n",
    "    - ist eine Funktion, die jedem Zustand eine bestimmte Aktion zuweist.\n",
    "    - Sie ist **deterministisch**, d.h., sie gibt für jeden Zustand genau eine Aktion vor. \n",
    "\n",
    "- **probabilistische Strategien**: weisen jedem Zustand eine **Wahrscheinlichkeitsverteilung** über die möglichen Aktionen zu.\n",
    "    - nützlich, wenn es Unsicherheit oder Zufälligkeit in der Umgebung gibt.\n",
    "\n",
    "- Die **Aufgabe eines Offline-Lernverfahrens** besteht darin, <ins>eine optimale Strategie `π*` für ein gegebenes festes MDP zu erlernen</ins>. \n",
    "\n",
    "Eine **optimale Strategie** ist diejenige, die die **akkumulierte erwartete Belohnung maximiert**, die der Agent durch die Anwendung der Strategie erhält. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ea555-8c78-4edb-980d-f9a136ca5878",
   "metadata": {},
   "source": [
    "##### Episode e\n",
    "\n",
    "- Eine Episode `e` in $D$ ist eine (potenziell unendliche) **Folge von Zuständen und Aktionen** $e = (s_0, a_1, s_1, a_2, s_2, ...)$ die mit dem Anfangszustand `s0` beginnt und die Aktionen `a1, a2, ...` ausführt, wobei der Agent in den Zuständen `s1, s2, ...` landet.\n",
    "- Die Wahrscheinlichkeit $P(e)$ ist definiert durch >$$P(e) = \\prod_{i>0} P(s_{i-1},a_i,s_i)$$\n",
    "\n",
    "- Eine Episode ist **initial**, wenn sie mit dem Anfangszustand $s_0$ beginnt bzw. wenn $s_0 = s^0$ gilt.\n",
    "- und sie ist **terminierend**, wenn sie mit einem Zustand $s_n$ endet, der zu den Endzuständen $S^t$ gehört d.h. $s_n \\in S^t$ .\n",
    "\n",
    "> Der unendliche Fall tritt beispielsweise für den Roboter aus unserem Staubsaugerbeispiel auf, wenn dieser permanent nur die move-Aktion ausführt oder wenn eine move-Aktion permanent fehlschlägt (wobei für solch eine Episode die Wahrscheinlichkeit gegen 0 geht).\n",
    "\n",
    "##### Nutzen eienr Episode $U^\\gamma_D(e)$\n",
    "\n",
    "- Jede Episode akkumuliert gewisse Belohnungen und die Summe aller Belohnungen nennen wir **Nutzen der Episode** (engl. utility oder auch return):\n",
    "    - Für $\\gamma \\in [0,1]$ heißt $U^\\gamma_D(e)$ definiert via $$U^\\gamma_D(e) = \\sum_{i>0} \\gamma^{i-1}R(s_{i-1},a_i,s_i)$$ der **mit $\\gamma$ diskontierte Nutzen von $e$ in $D$**.\n",
    "    - jede Belohnung wird mit einem **Discountfaktor** `γ` gewichtet wird.\n",
    "    - Dieser Diskontfaktor liegt im Bereich von 0 bis 1 und bestimmt, wie stark zukünftige Belohnungen im Vergleich zu sofortigen Belohnungen bewertet werden. \n",
    "    - Bei **kleinen γ** werden Strategien bevorzugt, die schnell hohe Belohnungen erhalten,\n",
    "    - während bei **größeren γ** nahe 1 spätere Belohnungen wichtiger werden.\n",
    "\n",
    "> **Wert von γ**\n",
    ">\n",
    "> Üblicherweise wählt man für `γ` einen Wert echt kleiner als 1 (< 1), der aber immer noch recht nahe an 1 ist (beispielsweise 0.9 oder 0.99). Für Werte echt kleiner als 1 ist es auch gewährleistet, dass $U^γ_D(e)$ stets endlich ist, selbst bei unendlichen langen Episoden mit positiver Wahrscheinlichkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e387f7ec-0692-4d02-9ae2-04df2c560cb0",
   "metadata": {},
   "source": [
    "##### Nutzen einer Strategie $U^\\gamma_D(π)$\n",
    "\n",
    "- Der Nutzen $U^\\gamma_D(\\pi)$ von $\\pi$ in $D$ ist definiert durch $$U^\\gamma_D(\\pi) = E_{\\pi \\sim_0 e} \\left[ U^\\gamma_D(e) \\right] = \\sum_{\\pi \\sim_0 e} P(e)U^\\gamma_D(e)$$\n",
    "- der Nutzen $U^\\gamma_D(\\pi)$ von $\\pi$ in $D$ ist **der durchschnittliche Nutzen aller aus $\\pi$ generierten initialen Episoden**, gewichtet nach deren Wahrscheinlichkeit.\n",
    "\n",
    "- $\\pi \\sim e$ ist eine aus $\\pi$ generierten Episode.\n",
    "- $\\pi \\sim_0 e$ wenn e initial ist.\n",
    "\n",
    "- Eine Strategie $\\pi^*$ ist nun optimal, wenn sie den Nutzen maximiert: $$\\pi^* = \\arg\\max_\\pi U^\\gamma_D(\\pi)$$\n",
    "\n",
    "- Um eine optimale Strategie zu bestimmen gibt es mehrere Ansätze methoden:\n",
    "    - Eine <ins>naive Methode</ins> besteht darin, für alle möglichen Strategien ihren Nutzen zu berechnen und eine Strategie mit maximalem Nutzen auszuwählen. **unpraktisch**.\n",
    "    - **Iterative Entwicklung der Zustandsnutzen**\n",
    "    - **Iterative Strategieentwicklung**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910c6d1-e908-4e8b-9a54-d57a329577cb",
   "metadata": {},
   "source": [
    "#### Iterative Entwicklung der Zustandsnutzen (VI)\n",
    "- benutzt eine Charakterisierung von optimalen Strategien durch den **Nutzen von Zuständen**.\n",
    "-\n",
    "\n",
    "##### Nutzen eines Zustands bezüglich $\\pi$ $U^\\gamma_D(s | π)$\n",
    "\n",
    "- Der Nutzen $U^\\gamma_D(s | \\pi)$ von $s$ bezüglich $\\pi$ in $D$ ist definiert durch:$$U^\\gamma_D(s | \\pi) = E_{\\pi\\sim e=(s,a_1,s_1,...)}\\left[U^\\gamma_D(e)\\right] = \\sum_{\\pi\\sim e=(s,a_1,s_1,...)} P(e)U^\\gamma_D(e)$$\n",
    "- Wenn $\\pi^*$ optimal ist, schreiben wir statt $U^\\gamma_D(s | \\pi^*)$ nur $U^\\gamma_D(s)$, was dann der optimale erwartete Nutzen von $s$ ist:\n",
    "    - Das bedeutet, dass es keine Strategie gibt, die einen höheren erwarteten Nutzen für Zustand s liefert als π*.\n",
    "- Wenn der Nutzen $U^\\gamma_D(s)$ für alle Zustände $s$ gegeben ist, kann eine optimale Strategie $\\pi^*$ einfach durch die folgende Formel bestimmt werden:\n",
    "\n",
    "$$\\pi^*(s) = \\arg\\max_{a \\in A} \\sum_{s' \\in S} P(s,a,s') \\left[R(s,a,s') + \\gamma U^\\gamma_D(s')\\right] \\tag{1}$$\n",
    "\n",
    "-   Mit anderen Worten, $\\pi^*$ wählt in jedem Zustand $s$ die Aktion aus, die im Erwartungswert in einen Zustand mit hohem Nutzen führt.\n",
    "-   Der VI-Ansatz versucht, die **Werte $U^\\gamma_D(s)$ iterativ zu bestimmen**, um daraus eine optimale Strategie ableiten zu können. Dafür ist die Bellman Gleichung nützlich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ba8f5-d266-442e-9f14-a2ada24df7ff",
   "metadata": {},
   "source": [
    "##### Nutzen eines Zustands $\\pi$ $U^\\gamma_D(s)$\n",
    "\n",
    "$$U^\\gamma_D(s) = \\max_{a \\in A} \\sum_{s' \\in S} P(s,a,s') \\left[R(s,a,s') + \\gamma U^\\gamma_D(s')\\right] \\tag{2}$$\n",
    "- Zusammenhang zwischen den Zustandswerten.\n",
    "- Mit anderen Worten, der Nutzen von $s$ ist gleich der **Summe des erwarteten Nutzens der direkten Belohnung und des erwarteten Nutzens des Folgezustands**, gegeben, dass der Agent die beste Aktion ausführt.\n",
    "- Gleichungen der Form (2) nennen wir **Bellman-Gleichungen** und sie bilden einen wichtigen Bestandteil für die Entwicklung von Algorithmen.\n",
    "\n",
    "- Die Bestimmung der Werte $U^\\gamma_D(s)$ für alle $s \\in S$ (und damit die Bestimmung einer optimalen Strategie) kann nun als **Gleichungssystem mit $|S|$ Gleichungen der Form (2) und $|S|$ Unbekannten** (den Werten $U^\\gamma_D(s)$ für alle $s \\in S$) dargestellt werden.\n",
    "- Dieses Gleichungssystem ist allerdings **nicht-linear** (aufgrund des max-Operators) und ermöglicht keine direkte analytische Lösung.\n",
    "- $\\longrightarrow$ Nutzung iterativer Techniken.\n",
    "- $\\longrightarrow$ Verwendung der **Bellmann update als Update-Regel**:\n",
    "##### Der Bellmann-Update $u_{i+1}(s)$\n",
    "\n",
    "Definiere Startnutzen $u_0(s) := 0$ und setze für $i \\geq 0$:\n",
    "$$u_{i+1}(s) := \\max_{a \\in A} \\sum_{s' \\in S} P(s,a,s') \\left[R(s,a,s') + \\gamma u_i(s')\\right] \\tag{3}$$\n",
    "\n",
    "- es kann gezeigt werden, dass die Folge der $u_i$ gegen die Nutzen der Zustände **konvergiert** mit dem folgenden Theorem:\n",
    "> **Theorem 1.** Für alle s ∈ S, $lim_{i→∞} u_i(s) = U^γ_\n",
    "D(s$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79efa3b-ecdb-4906-be74-485f62e2b47e",
   "metadata": {},
   "source": [
    "##### VI-Algorithmus\n",
    "- ein approximatives Verfahren $\\longrightarrow$ **gewährleistet nicht**, dass die berechnete Strategie optimal ist.\n",
    "- aktualisiert iterativ die Zustandsnutzenwerte und leitet anschließend eine Strategie ab.\n",
    "- Mit dem **Parameter N** wird die **Anzahl der Iterationen** (und damit die Genauigkeit des Ergebnisses)  **gesteuert**.\n",
    "\n",
    "![](./VI.PNG)\n",
    "\n",
    "- Der VI-Ansatz **bestimmt die Strategie π∗  im letzten Schritt** des Algorithmus. \n",
    "- **Problem**: Es kann vorkommen, dass die Nutzenwerte $u_i$ zu genau berechnet wurden \n",
    "und die Strategie prinzipiell fü¨her schon als optimale Strategie erkannt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c71cd-863b-43b5-8b04-ba648f3570be",
   "metadata": {},
   "source": [
    "#### Iterative Strategieentwicklung (PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71b40d-8b40-4a5f-9626-8ebc7549ccc6",
   "metadata": {},
   "source": [
    "\n",
    "- berechnet zusätzlich zur Berechnung der Nutzen der Zustände direkt auch die Strategie.\n",
    "- Der Algorithmus verfährt **iterativ** in **zwei** Schritten:\n",
    "  1. der **Strategieevaluation** (engl. policy evaluation): Ausgehend von einer beliebigen Strategie $π_0$ werden die Nutzen der Zustände bzgl. dieser Strategie ausgewertet.\n",
    "  2. **Strategieverbesserung** (engl. policy improvement).  Die neuen Nutzenwerte werden benutzt, um eine neue Strategie zu berechnen.\n",
    "- Für die Berechnung der Nutzenwerte Zustände bezüglich $\\pi$ verwenden wir: $$U_\\gamma D(s | \\pi) = \\sum_{s' \\in S} P(s,\\pi(s),s') \\left[ R(s,\\pi(s),s')+\\gamma U_\\gamma D(s' | \\pi) \\right] \\quad \\tag{4}$$\n",
    "    - Die Bellmann-Gleichung (4) beschreibt wieder ein Gleichungssystem mit |S| Gleichungen und |S| Unbekannten.\n",
    "    - **Unterscheid zu (2)**: Gleichungssystem ist **linear**, kann also mit Methoden der linearen Programmierung effizient gelöst werden.\n",
    "    - skaliert bei großen Zustandsräumen **wenig gut**.\n",
    "- Weitere iterative Berechnung: Definiere Startnutzen $u_0(s,\\pi) := 0$ und setze für $i \\geq 0$\n",
    "\n",
    "$$u_{i+1}(s,\\pi) := \\sum_{s' \\in S} P(s,\\pi(s),s') \\left[ R(s,\\pi(s),s')+ \\gamma u_i(s',\\pi) \\right] \\quad (5)$$\n",
    "\n",
    "Es kann auch wieder gezeigt werden, dass die Folge der $u_i$ gegen die Nutzen der Zustände **konvergiert**.\n",
    "\n",
    "> **Theorem 2.** Für alle $s \\in S$ und eine beliebige Strategie $\\pi$, $\\lim_{i \\to \\infty} u_i(s,\\pi) = U_\\gamma D(s | \\pi)$.\n",
    " \n",
    "- Haben wir für eine Strategie $\\pi_i$ die Werte $U_\\gamma D(s | \\pi_i)$ berechnet, können wir nun eine neue Strategie $\\pi_{i+1}$ bestimmen durch\n",
    "\n",
    "$$\\pi_{i+1}(s) = \\arg\\max_{a \\in A} \\sum_{s' \\in S} P(s,a,s') \\left[ R(s,a,s')+ \\gamma U_\\gamma D(s' | \\pi_i) \\right] \\quad (6)$$\n",
    "\n",
    "- die Bestimmung der Strategie $\\pi'$ erfolgt unter Verwendung der Nutzenwerte der Zustände bzgl. einer anderen Strategie ($\\pi$). \n",
    "\n",
    "**Theorem 3.** Sei $\\pi_0$ eine beliebige Strategie und $\\pi_i$ für $i > 0$ wie in (6) definiert. Dann ist $\\lim_{i \\to \\infty} \\pi_i = \\pi_*$ wohldefiniert und optimal.\n",
    "heißt: Es gilt, dass diese iterative Berechnung schlussendlich **immer zur optimalen Strategie führt**.#\n",
    "\n",
    "![](./PI.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dcb8d-de87-45bc-acd2-fbe81483dc52",
   "metadata": {},
   "source": [
    "### 4.2. Passives-Reinforcement-Learning <a name=4.2.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62db6dd-521e-4b9e-80c6-38baef027407",
   "metadata": {},
   "source": [
    "- In den meisten realistischen Anwendungsszenarien ist die Existenz eines korrekten (wenn auch probabilistischen) Modells der Umgebung in Form eines Markov-Entscheidungsprozesses **häufig nicht gegeben**.\n",
    "- Bei der adaptiven dynamischen Programmierung verwenden wir den rekursiven Zusammenhang zwischen den Nutzen der Zustände bzgl. einer Strategie.\n",
    "- Beim Temporal Difference Learning wird beim Update-Schritt kein Modell der Umgebung explizit mit einbezogen.\n",
    "- Eine π-induzierte Beobachtung o=(s,a,s′,r) sagt, dass im Zustand s, nach Ausführung der Aktion a=π(s) der Agent in den Zustand s′\n",
    " gewechselt ist und eine Belohnung r erfahren hat.\n",
    "\n",
    "- Methoden des passiven Reinforcement Learnings erlernen ausschließlich die Nutzenwerte der Zustände.\n",
    "\n",
    "- **falsch** Methoden des passiven Reinforcement Learnings berechnen nach und nach eine eigene Strategie.\n",
    "\n",
    "- Die Updateregel des Temporal Difference Learnings bei einer neuen Beobachtung $o = (s, \\pi(s), s',r)$ ist gegeben durch $$u^\\gamma (s\\mid \\pi) := u^\\gamma (s\\mid \\pi) + \\alpha (r + \\gamma u^\\gamma (s'\\mid \\pi) - u^\\gamma(s\\mid \\pi))$$ wobei $\\alpha$ der Lernparameter und $\\gamma$ der Discountfaktor ist.\n",
    "\n",
    "- **falsche aussage** Es ist für typische Anwendungsfälle meist notwendig, den Nutzen aller Zustände (und damit die optimalen Aktionen für diese Zustände) zu bestimmen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1b35c-d593-4419-8347-3bd1fc570389",
   "metadata": {},
   "source": [
    "### 4.3. Aktives-Reinforcement-Learning <a name=4.3.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847ed31-5110-47f8-b26e-a190d77379cd",
   "metadata": {},
   "source": [
    "- Bei der ϵ-greedy-Strategie wird mit Wahrscheinlichkeit ϵ in einem Zustand s eine zufällige Aktion ausgewählt und mit Wahrscheinlichkeit 1-ϵ\n",
    " wird die Strategie π(s) ausgeführt.\n",
    "\n",
    "- Bei einer Meta-Strategie wird eine initiale Strategie π gegeben, von der jedoch ab und zu abgewichen wird.\n",
    "\n",
    "- Q-Learning wird als modellfreier Ansatz bezeichnet.\n",
    "\n",
    "- Die meisten Methoden des aktiven Reinforcement Learnings benutzen eine Meta-Strategie, um das exploration vs. exploitation-Dilemma zu adressieren.\n",
    "\n",
    "- Q-Learning ist ein Ansatz für das aktive Reinforcement Learning, der den meisten modernen Ansätzen zum Reinforcement Learning unterliegt.\n",
    "\n",
    "- Q-Learning ist ein Temporal Difference Learning-Ansatz für das aktive Reinforcement Learning.\n",
    "\n",
    "- Bei der ϵ-greedy-Strategie ist ϵ∈[0,1] ein Parameter, der angibt wie häufig die exploration der exploitation vorgezogen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd85c0-08b9-40a9-a1a5-79c016518a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bdf7d-8d50-4a61-acf2-6e5898f542da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f50a32-14a2-4a9c-99cb-41932d29862c",
   "metadata": {},
   "source": [
    "---\n",
    "# 5 Deep Learning <a name=5><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f648c7-fddf-41db-af83-871504909690",
   "metadata": {},
   "source": [
    "### 5.1. künstliche neuronale netzwerke <a name=5.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f6b8d-ca31-4ab1-bab7-6f6dad007fb0",
   "metadata": {},
   "source": [
    "- Im eigentlichen Rückwärtspropagationsschritt des Backpropagation-Algorithmus wird der am Ausgabeneuron beobachtete Fehler in der Vorhersage von der Ausgabeschicht durch das Netzwerk zurückgegeben.\n",
    "\n",
    "- Der Aktivierungswert $a_r$ zu einer Eingabe x  und einem Neuron $r = (w, act)$ berechnet sich wie folgt: $$a_r = act(w_0 + w_1 x_1 + \\ldots + w_n x_n)$$\n",
    "\n",
    "- Üblicherweise ist die Aktivierungsfunktion der Neuronen in der Ausgabeschicht **anders** als die der Neuronen in den versteckten Schichten.\n",
    "\n",
    "- Jedes Neuron eines neuronalen Netzwerkes **muss nicht** die gleiche Aktivierungsfunktion haben.\n",
    "\n",
    "- Künstliche neuronale Netze können für überwachtes und unüberwachtes Lernen undfür Reinforcement Learning benutzt werden.\n",
    "\n",
    "- Besitzen alle Neuronen eines neuronalen Netzwerks als Aktivierungsfunktion die ReLU-Funktion, kann gezeigt werden, dass das gesamte Netzwerk **keine** lineare Funktion repräsentiert.\n",
    "\n",
    "- Bei der Angabe der Anzahl Schichten eines neuronalen Netzwerks wird die Eingabeschicht üblicherweise nicht mitgezählt.\n",
    "\n",
    "- Der Backpropagation-Algorithmus ist ein Algorithmus, der die partiellen Ableitungen, die für das Gradient Descent-Verfahren benötigt werden, in geschickter Weise berechnet.\n",
    "\n",
    "- Eine zusätzliche Eingabe $x_0$, die nicht Teil des eigentlichen Eingabe-Vektors $x = (x_1, \\ldots, x_n) \\in \\mathbb{R}^n$ ist, wird Bias-Eingabe genannt.\n",
    "\n",
    "- Jede Schicht in einem neuronalen Netzwerk **hat eine unterschiedliche Anzahl** von Neuronen enthalten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31437f09-ebbf-4e90-a56b-a98e9f81035c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '0.25' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.3\u001B[39m\n\u001B[0;32m      6\u001B[0m x2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.25\u001B[39m\n\u001B[1;32m----> 7\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43mx2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m a0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m\n\u001B[0;32m     10\u001B[0m w0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.7\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot interpret '0.25' as a data type"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x0 = 0.1\n",
    "x1 = 0.3\n",
    "x2 = 0.25\n",
    "x = np.array(x1,x2)\n",
    "a0 = 0.1\n",
    "\n",
    "w0 = 0.7\n",
    "w1 = 0.8\n",
    "w2 = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b1180b-ef9d-4ad2-8dba-16966ea39dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hlogt(x):\n",
    "    return round(1/(1+np.exp(-x)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527169a5-2d23-4cd1-adf7-20560ba21d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5616"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = x0 + w0*x1\n",
    "a1 = a0 + w1 * hlogt(z1)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ecc197-96f7-4554-b9d1-e4e71783669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1349"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a1 + w2 * hlogt(a1)\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435feb34-fe29-4bbb-8fd5-2e8d3742b68b",
   "metadata": {},
   "source": [
    "### 5.2. Convolutional Neural Networks <a name=5.2.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f2a76-21cd-45a6-bbff-3a99a9d8728b",
   "metadata": {},
   "source": [
    "- Die Parameter der Kernelfunktionen in einem CNN (also die jeweiligen Matrixeinträge) werden während des Lernens angepasst.\n",
    "\n",
    "- Die (kontinuierliche) Faltungsoperation ist im einfachsten Fall eine mathematische Operation, die zwei reellwertige Funktionen als Eingabe nimmt und eine reellwertige Funktion als Ausgabe liefert.\n",
    "\n",
    "- Die Faltungsoperation kann in der Bildverarbeitung zum Entfernen von Rauschen verwendet werden.\n",
    "- Durch Pooling-Methoden wird die Eingabematrix künstlich verkleinert.\n",
    "- Eine Faltungsschicht in einem CNN besteht üblicherweise aus einer **Menge** Kernelfunktionen, die auf das gesamte Bild angewendet wird.\n",
    "- Die Verwendung der ReLU-Funktion ist bei CNNs weit verbreitet.\n",
    "- Die diskrete Faltungsoperation für zweiwertige Funktionen (also Funktionen $I,K: \\mathbb{Z} \\times \\mathbb{Z} \\to \\mathbb{R}$ ) ist gegeben durch (I * K) (n_1,n_2) = \\sum_{m_1=-\\infty}^\\infty\\sum_{m_2=-\\infty}^\\infty I(m_1,m_2)K(n_1-m_1,n_2-m_2).\n",
    "\n",
    "- Ein Vorteil von CNNs gegenüber traditionellen neuronalen Netzwerken besteht darin, dass weniger Parameter gelernt werden müssen, da ein CNN üblicherweise nicht vollvernetzt ist.\n",
    "- Die grundlegende Konzeption von CNNs basiert unter anderem auf der Annahme, dass Merkmale nichtlokal (also nicht immer an der gleichen Stelle) sind.\n",
    "- Convolutional Neural Networks finden Anwendung für Daten, die in einer Gitterstruktur angeordnet sind bzw. bei denen einzelne Merkmale in einer räumlichen oder zeitlichen Beziehung zueinander stehen.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb8722-6f82-47a1-a923-a72d1366e288",
   "metadata": {},
   "source": [
    "### 5.3. RNN <a name=5.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b0767-016c-47ef-b8b7-bc5fd1e7df87",
   "metadata": {},
   "source": [
    "- Sowohl Sprach- als auch Schrifterkennung sind wichtige Anwendungsgebiete für RNNs.\n",
    "\n",
    "- Im Bereich der automatischen Bildbeschriftung werden oft RNNs mit CNNs kombiniert.\n",
    "\n",
    "- Bei einem LSTM stellt der Zellzustand s das \"Langzeitgedächtnis\" dar.\n",
    "\n",
    "- Eine Grundidee von RNNs ist, dass die versteckten Schichten eine Art \"Gedächtnis\" für die Verarbeitung einer Sequenz repräsentieren.\n",
    "\n",
    "- Beim One-Hot-Encoding sind alle Einträge eines Vektors 0, bis auf einen Eintrag, der 1  ist und durch seine Stelle z. B. eine bestimmte Klassenzugehörigkeit repräsentiert.\n",
    "\n",
    "- Ein Problem bei RNNs besteht darin, dass der Einfluss von sehr weit zurückliegenden versteckten Zuständen sehr **gering** ist, was die Verarbeitung längerer Sequenzen erschwert.\n",
    "\n",
    "- Bei rekurrenten neuronalen Netzwerken wird der Backpropagation-Algorithmus angewandt.\n",
    "\n",
    "- die automatische Detektion von Objekten in Bilddaten ist **keine** Anwendung für RNNs.\n",
    "\n",
    "- Die bei RNNs angewandte Variante der Backpropagation wird auch backpropagation through time genannt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df485f3-6e46-4c86-9452-28009fadc40a",
   "metadata": {},
   "source": [
    "##### Berechnungsgraphen \n",
    "Im Allgemeinen gilt für eine Eingabe $x = (x^{(1)}, \\ldots, x^{(m)})$:\n",
    "\n",
    "$$\n",
    "h(i) = \\text{act}(Ux^{(i)} + Wh^{(i-1)}) \\quad \\text{(1)}\n",
    "$$ <a name=hi><a>\n",
    "\n",
    "$$\n",
    "o(i) = \\text{act}(Vh^{(i)}) \\quad \\text{(2)}\n",
    "$$<a name=oi><a>\n",
    "\n",
    "für $i = 1, \\ldots, m$. Zu beachten ist, dass diese Netzwerkarchitektur mit Eingaben beliebiger Länge umgehen kann, aber eine fixe Anzahl an Parametern besitzt (in den Matrizen $U$, $V$, $W$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda19404-0a03-4c6c-b27b-c2d4602fbeab",
   "metadata": {},
   "source": [
    "Gegeben sei das abgebildete einfache RNN, wobei\n",
    "\n",
    "$$\\sum = \\{\\text{ist,nichts,niemand}\\} = \\{(1,0,0)^T,(0,1,0)^T,(0,0,1)^T\\}$$\n",
    "$$U= ((0, 0.9, 0.9), (0.5, 0.1, 0), (0.5, 0, 0.1))$$\n",
    "$$W = ((0, 0.45, 0.45), (0.25, 0.05, 0), (0.25, 0, 0.05))$$\n",
    "$$V = ((0.5, 0, 0), (0, 0.5, 0), (0, 0, 0.5))$$\n",
    "$$h_0 = (0,1,1)^T$$\n",
    "\n",
    "und die Aktivierungsfunktion $h^{relu}$ ist. Berechnen Sie die hidden states und die Ausgabe für die Eingabe $x = \\text{'Niemand ist'} = ((0,0,1)^T,(1,0,0)^T)$. \n",
    "(Antwortformat '(1,2,3.456)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04919f-d436-4682-8ff6-3929da2c6e77",
   "metadata": {},
   "source": [
    "##### Long short-term memory-Netzwerke \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bce749-40b6-4918-998d-004268a7c519",
   "metadata": {},
   "source": [
    "$$f^{(i)} = h^{logit} (U^f x^{(i)} + W^f h^{(i−1)})$$\n",
    "- Der Vektor $f^{(i)}$ soll steuern, was aus dem Langzeitgedächtnis `s` vergessen werden soll (auch als **forget gate** bezeichnet).\n",
    "\n",
    "$$g^{(i)} = h^{logit} (U^g x^{(i)} + W^g h^{(i−1)})$$\n",
    "$$k^{(i)} = h^{tanh} (U^k x^{(i)} + W^k h^{(i−1)})$$\n",
    "- Der Vektor $g^{(i)}$ (**input gate**) steuert, welche Informationen aus $k^{(i)}$ in das Langzeitgedächtnis aufgenommen werden sollen.\n",
    "$$q^{(i)} = h^{logit} (U^o x^{(i)} + W^o h^{(i−1)})$$\n",
    "- Der Vektor $q^{(i)}$ (**output gate**) steuert, welche Information in die Ausgabe und den nächsten versteckten Zustand $h^{(i)}$ einfließt.\n",
    "\n",
    "- Die Kernidee hinter LSTMs liegt in der Definition des Zellzustands: $$s^{(i)} = f^{(i)} \\cdot s^{(i-1)} + g^{(i)} \\cdot k^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1a5f7-320d-44b2-8f95-46b2df8ed6bf",
   "metadata": {},
   "source": [
    "### 5.4. Lernen von Repräsentationen <a name=5.4.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef4995-0a7d-434d-bfa5-350c9d712e4a",
   "metadata": {},
   "source": [
    "- Eine Variante des denoising Autoencoders (DAE) ist der sparse Autoencoder (SAE).\n",
    "\n",
    "- **falsche aussage** Beim Training eines Autoencoders besteht das Ziel darin, dass die final vom Generator erzeugten Beispiele nicht mehr vom Diskriminator von echten Bildern aus dem Trainingsdatensatz unterschieden werden können.\n",
    "\n",
    "- **falsche aussage** Die Eingabe des Diskriminators eines GANs besteht aus einem Beispiel, für das entschieden werden soll, ob es echt oder synthetisch (also vom Generator produziert) ist.\n",
    "\n",
    "- Bei der Verwendung eines DAEs wird dem gegebenen Trainingsdatensatz zunächst ein Rauschen hinzugefügt.\n",
    "\n",
    "- Bei der Verwendung eines DAEs wird den Gewichten des Kodierers **kein** Rauschen hinzugefügt.\n",
    "\n",
    "- Ein sparse Autoencoder (SAE) ist overcomplete.\n",
    "\n",
    "- Ein Ziel des Forschungsgebietes der Explainable Artificial Intelligence liegt darin, interpretier- und erklärbare Modelle des maschinellen Lernens zu entwickeln.\n",
    "\n",
    "- Ein Autoencoder besteht aus drei Komponenten: dem dekodierer, dem kodierer und dem Flaschenhals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2154340-b964-405c-8d9d-da17e9a405af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
