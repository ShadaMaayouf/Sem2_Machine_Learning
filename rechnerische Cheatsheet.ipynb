{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd5d136-be08-4dfc-8ad9-5a5fa1c85e54",
   "metadata": {},
   "source": [
    "# Cheatsheet (rechnerisch)\n",
    ">## <ins>Table of contents</ins> <a name=\"up\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    ">* [**K2. Überwachtes Lernen**](#2)\n",
    "    * [**2.1. Lineare Regression**](#2.1.)\n",
    "    * [**2.2. Lineare Regression**](#2.2.)\n",
    "    * [**2.3. Lineare Regression**](#2.3.)\n",
    "    * [**2.4. Lineare Regression**](#2.4.)\n",
    ">* [**K3. Motivation und Grundlagen**](#3)\n",
    ">* [**K4. Motivation und Grundlagen**](#4)\n",
    ">* [**K5. Motivation und Grundlagen**](#5)\n",
    "    * [**5.1. RNN**](#5.1.)\n",
    "       * [**5.1. RNN**](#5.1.)\n",
    "    * [**5.3. RNN**](#5.3.)\n",
    "       * [**spaltenweise Konkatenation zweier Matrizen**](#5.3.1.)\n",
    "       * [**One-Hot-Codierung**](#5.3.2.)\n",
    "       * [**Berechnungsgraphen**](#5.3.3.)\n",
    "\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d9e4dc-1af2-4d72-ad51-c8a914ff7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3038ba3-8aa5-48c9-88a4-77ac81bf803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datensatz visualisieren\n",
    "def visualise_datensatz(x,y):\n",
    "    # Erstellen Sie das Diagramm\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x,y)\n",
    "    plt.title('Visualisierung des Datensatzes')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "visualise_datensatz(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bea975-c801-440d-bc50-cab55291db0a",
   "metadata": {},
   "source": [
    "## 2 Überwachtes Lernen <a name=2><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd419998-6f71-48c8-ae57-3b3d2898cf1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1. Lineare Regression <a name=2.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67badb-52bf-47a3-b739-baef372d46d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. 2D modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e970972b-a302-467c-9585-6b2d2a03f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ihre Daten\n",
    "D = [\n",
    "    ((153.3), 47.1),\n",
    "    ((158.9), 46.8),\n",
    "    ((160.8), 49.3),\n",
    "    ((179.6), 53.2),\n",
    "    ((156.6), 47.7),\n",
    "    ((165.1), 49.0),\n",
    "    ((165.9), 50.6),\n",
    "    ((156.7), 47.1),\n",
    "    ((167.8), 51.7),\n",
    "    ((160.8), 47.8)\n",
    "]\n",
    "\n",
    "theta = (-4, 1/3)\n",
    "lambda_ = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c70093-ad2b-43fd-84d2-6da776b3bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der quadratische Fehler für D und theta ist 21.349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def h(theta, x):\n",
    "    return theta[0] + theta[1]*x\n",
    "\n",
    "def mse(D, h, theta):\n",
    "    return sum((h(theta, x) - y)**2 for (x, y) in D)\n",
    "\n",
    "L = mse(D, h, theta)\n",
    "print(f'Der quadratische Fehler für D und theta ist {round(L,3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1db9d-a588-4370-9c71-92be4e61211f",
   "metadata": {},
   "source": [
    "R²-Wert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d89c183-18bf-4f25-a943-297aab603b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²-Wert: 0.501\n"
     ]
    }
   ],
   "source": [
    "def r2_wert(L, D):\n",
    "    y_values = [y for (_, y) in D]\n",
    "    mean_y = sum(y_values) / len(y_values)  \n",
    "    squared_diff = sum((y - mean_y) ** 2 for y in y_values)\n",
    "    return 1 - L/squared_diff\n",
    "\n",
    "print(f'R²-Wert: {round(r2_wert(L, D),3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729bef95-be7f-44a8-8a67-a6a2a3af8ee3",
   "metadata": {},
   "source": [
    "tikhonov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458a1ed6-f5a7-4a12-9be0-b010f6ca20e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratischer Fehler mit Tikhonov-Regularisierung: 21.360\n"
     ]
    }
   ],
   "source": [
    "def tikhonov(L, lambda_, theta):\n",
    "    RT = sum(i**2 for i in theta[1:])\n",
    "    return L + lambda_ * RT\n",
    "\n",
    "print(f\"Quadratischer Fehler mit Tikhonov-Regularisierung: {tikhonov(L, lambda_, theta):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44453af6-b82b-465c-8168-cc709a335932",
   "metadata": {},
   "source": [
    "Polynomische Merkmale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3dbe0d-91cf-4e73-b8bb-68e82785120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die polynomielle Merkmalserweiterung von D mit Maximalgrad 2 ist:\n",
      " {(674, 40, 454276, 26960, 1600): 998, (100, 19, 10000, 1900, 361): 71, (348, 1, 121104, 348, 1): 1} \n",
      "\n",
      "Die polynomielle Merkmalserweiterung von D mit Maximalgrad 3 ist:\n",
      " {(674, 40, 454276, 26960, 1600, 306182024, 18171040, 26962, 64000): 998, (100, 19, 10000, 1900, 361, 1000000, 190000, 1902, 6859): 71, (348, 1, 121104, 348, 1, 42144192, 121104, 350, 1): 1} \n",
      "\n",
      "[1, 674, 40, 454276, 26960, 1600]\n",
      "[1, 100, 19, 10000, 1900, 361]\n",
      "[1, 348, 1, 121104, 348, 1]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "D = [((674,40),998),((100,19),71),((348,1),1)]\n",
    "\n",
    "def poly_2(D):\n",
    "    D_poly = {}\n",
    "\n",
    "    for features, target in D:\n",
    "        x1, x2 = features\n",
    "        D_poly[((x1, x2, x1**2, x1*x2, x2**2))] = target\n",
    "    \n",
    "    print(\"Die polynomielle Merkmalserweiterung von D mit Maximalgrad 2 ist:\\n\",D_poly,\"\\n\")\n",
    "\n",
    "def poly_3(D):\n",
    "    D_poly = {}\n",
    "\n",
    "    for features, target in D:\n",
    "        x1, x2 = features\n",
    "        D_poly[((x1, x2, x1**2, x1*x2, x2**2, x1**3, x1**2*x2, x1*x2^2, x2**3))] = target\n",
    "    \n",
    "    print(\"Die polynomielle Merkmalserweiterung von D mit Maximalgrad 3 ist:\\n\",D_poly,\"\\n\")\n",
    "\n",
    "poly_2(D)\n",
    "poly_3(D)\n",
    "\n",
    "# Trennen Sie die Merkmale und die Zielwerte\n",
    "features = np.array([x for (x, y) in D])\n",
    "targets = np.array([y for (x, y) in D])\n",
    "\n",
    "# Erstellen Sie das PolynomialFeatures-Objekt mit Grad 2\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# Wenden Sie die Transformation auf Ihre Daten an\n",
    "features_poly = poly.fit_transform(features)\n",
    "\n",
    "# Jetzt enthält 'features_poly' die polynomiale Merkmalserweiterung von 'features'\n",
    "\n",
    "# Anwendung der math.floor oder math.ceil Funktion auf jede Zahl in jeder Liste\n",
    "correctly_rounded_data = [[math.floor(number + 0.5) if number >= 0 else math.ceil(number - 0.5) for number in sublist] for sublist in features_poly]\n",
    "\n",
    "# Ausgabe der korrekt gerundeten Daten\n",
    "for sublist in correctly_rounded_data:\n",
    "    print(sublist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f8598-f883-4f1c-a6d1-440f29f95967",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. 3D modell\n",
    "\n",
    "quadratische Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32f147ae-50e0-4002-a1c5-e1738386585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der quadratische Fehler für D und theta ist 40.24\n"
     ]
    }
   ],
   "source": [
    "D = [((182,23),172),((180,12),168),((162,26),153)]\n",
    "theta = (-15, 1, 0.4)\n",
    "lambda_ = 0.1\n",
    "\n",
    "def h(theta, x):\n",
    "    return theta[0] + sum(t*x_i for t, x_i in zip(theta[1:], x))\n",
    "\n",
    "def mse(D, h, theta):\n",
    "    return sum((h(theta, x) - y)**2 for (x, y) in D)\n",
    "L = mse(D, h, theta)\n",
    "print(f'Der quadratische Fehler für D und theta ist {round(L,3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adacc09-8ea6-4671-80fb-a6d64f283d0b",
   "metadata": {},
   "source": [
    "R²-Wert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f97dc54-f10c-4452-bc6a-dce5caa100d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²-Wert: 0.799\n"
     ]
    }
   ],
   "source": [
    "def r2_wert(L, D):\n",
    "    y_values = [y for (_, y) in D]\n",
    "    mean_y = sum(y_values) / len(y_values)  \n",
    "    squared_diff = sum((y - mean_y) ** 2 for y in y_values)\n",
    "    return 1 - L/squared_diff\n",
    "\n",
    "print(f'R²-Wert: {round(r2_wert(L, D),3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e3b78-5c3f-4df7-96ce-c23ffbf92c37",
   "metadata": {},
   "source": [
    "tikhonov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c69fab9c-d96b-4b13-afb3-9e59c13605e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratischer Fehler mit Tikhonov-Regularisierung: 40.356\n"
     ]
    }
   ],
   "source": [
    "def tikhonov(L, lambda_, theta):\n",
    "    RT = sum(i**2 for i in theta[1:])\n",
    "    return L + lambda_ * RT\n",
    "\n",
    "print(f\"Quadratischer Fehler mit Tikhonov-Regularisierung: {tikhonov(L, lambda_, theta):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59070600-2324-45e5-9e69-f007f4efca74",
   "metadata": {},
   "source": [
    "Polynomische Merkmale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29038a48-ff41-4084-b5de-dc625cf2f886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die polynomielle Merkmalserweiterung von D mit Maximalgrad 2 ist:\n",
      " {(674, 40, 454276, 26960, 1600): 998, (100, 19, 10000, 1900, 361): 71, (348, 1, 121104, 348, 1): 1} \n",
      "\n",
      "Die polynomielle Merkmalserweiterung von D mit Maximalgrad 3 ist:\n",
      " {(674, 40, 454276, 26960, 1600, 306182024, 18171040, 26962, 64000): 998, (100, 19, 10000, 1900, 361, 1000000, 190000, 1902, 6859): 71, (348, 1, 121104, 348, 1, 42144192, 121104, 350, 1): 1} \n",
      "\n",
      "[1, 674, 40, 454276, 26960, 1600]\n",
      "[1, 100, 19, 10000, 1900, 361]\n",
      "[1, 348, 1, 121104, 348, 1]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "D = [((674,40),998),((100,19),71),((348,1),1)]\n",
    "\n",
    "def poly_2(D):\n",
    "    D_poly = {}\n",
    "\n",
    "    for features, target in D:\n",
    "        x1, x2 = features\n",
    "        D_poly[((x1, x2, x1**2, x1*x2, x2**2))] = target\n",
    "    \n",
    "    print(\"Die polynomielle Merkmalserweiterung von D mit Maximalgrad 2 ist:\\n\",D_poly,\"\\n\")\n",
    "\n",
    "def poly_3(D):\n",
    "    D_poly = {}\n",
    "\n",
    "    for features, target in D:\n",
    "        x1, x2 = features\n",
    "        D_poly[((x1, x2, x1**2, x1*x2, x2**2, x1**3, x1**2*x2, x1*x2^2, x2**3))] = target\n",
    "    \n",
    "    print(\"Die polynomielle Merkmalserweiterung von D mit Maximalgrad 3 ist:\\n\",D_poly,\"\\n\")\n",
    "\n",
    "poly_2(D)\n",
    "poly_3(D)\n",
    "\n",
    "# Trennen Sie die Merkmale und die Zielwerte\n",
    "features = np.array([x for (x, y) in D])\n",
    "targets = np.array([y for (x, y) in D])\n",
    "\n",
    "# Erstellen Sie das PolynomialFeatures-Objekt mit Grad 2\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# Wenden Sie die Transformation auf Ihre Daten an\n",
    "features_poly = poly.fit_transform(features)\n",
    "\n",
    "# Jetzt enthält 'features_poly' die polynomiale Merkmalserweiterung von 'features'\n",
    "\n",
    "# Anwendung der math.floor oder math.ceil Funktion auf jede Zahl in jeder Liste\n",
    "correctly_rounded_data = [[math.floor(number + 0.5) if number >= 0 else math.ceil(number - 0.5) for number in sublist] for sublist in features_poly]\n",
    "\n",
    "# Ausgabe der korrekt gerundeten Daten\n",
    "for sublist in correctly_rounded_data:\n",
    "    print(sublist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957903a-daa5-45c2-b554-30e07186e14b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2. logistische Regression <a name=2.2.><a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5c2203c-6d1b-4d27-90a1-c64d2c6761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66af76f-ec98-456f-8eea-d81fc1ec1048",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. 2D modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38c6b7a2-3ee2-472c-b5c3-b3538e0ae7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ihre Daten\n",
    "D = [\n",
    "    ((5), 0),\n",
    "    ((14), 1),\n",
    "    ((10), 1),\n",
    "    ((7), 1),\n",
    "    ((2), 0),\n",
    "    ((1), 0),\n",
    "    ((9), 1),\n",
    "    ((8), 0),\n",
    "    ((3), 0),\n",
    "    ((13), 1)\n",
    "]\n",
    "theta = (-5.559, 0.771)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a0b7684-6068-4392-8431-988f371d35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15394356385485433\n",
      "0.9947014002271793\n",
      "0.8957621861330917\n",
      "0.45958834166338\n",
      "0.01768839152299949\n",
      "0.008260298092663241\n",
      "0.7989910002494707\n",
      "0.6477126548282953\n",
      "0.03747088801638696\n",
      "0.9886149068701869\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sigmoid(theta, x):\n",
    "    return 1 / (1 + np.exp(-h(theta, x)))\n",
    "\n",
    "def h(theta, x):\n",
    "    return theta[0] + theta[1]*x\n",
    "\n",
    "for (x,y) in D:\n",
    "    print(sigmoid(theta, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "828c26c8-d201-4cd5-a304-7dfbb4c8d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_logit(D, sigmoid, theta):\n",
    "    \n",
    "    m = len(D)  # Anzahl der Beobachtungen im Datensatz\n",
    "    total_cost = 0.0\n",
    "\n",
    "    for x, y in D:\n",
    "        prediction = sigmoid(theta, x)\n",
    "        cost = y * np.log(prediction) + (1 - y) * np.log(1 - prediction)\n",
    "        print(cost)\n",
    "        total_cost += cost\n",
    "\n",
    "    return -total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9abb60b7-c54d-4262-b095-2307a03e7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1671692122094611\n",
      "-0.005312687136834237\n",
      "-0.11008031849877639\n",
      "-0.7774240995969333\n",
      "-0.01784670072174623\n",
      "-0.00829460340028144\n",
      "-0.22440559704717059\n",
      "-1.0433081148827035\n",
      "-0.038190967060864556\n",
      "-0.011450399454817836\n",
      "Die logostische Kostenfunktion für D und theta ist 2.403\n"
     ]
    }
   ],
   "source": [
    "L = L_logit(D, sigmoid, theta)\n",
    "print(f'Die logostische Kostenfunktion für D und theta ist {round(L,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b7dcc-730e-467b-94c6-cbd7e368a142",
   "metadata": {},
   "source": [
    "Der Klassifikationsmatrix $clf_f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "342f81ef-0181-4629-885c-b3c9cb285e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_actual:  [0, 1, 1, 1, 0, 0, 1, 0, 0, 1]\n",
      "y_predicted:  [0, 1, 1, 0, 0, 0, 1, 1, 0, 1]\n",
      "\n",
      "Genauigkeit: 0.800\n",
      "Präzesion: 0.800\n",
      "Sensitivität (Recall): 0.800\n",
      "F1-Maß: 0.800\n",
      "\n",
      "Konfusionsmatrix: \n",
      " [[4 1]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "D = [\n",
    "    ((5), 0),\n",
    "    ((14), 1),\n",
    "    ((10), 1),\n",
    "    ((7), 1),\n",
    "    ((2), 0),\n",
    "    ((1), 0),\n",
    "    ((9), 1),\n",
    "    ((8), 0),\n",
    "    ((3), 0),\n",
    "    ((13), 1)\n",
    "]\n",
    "\n",
    "# Beispiel-Klassifikator c\n",
    "def clf_logit(x):\n",
    "    if x >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def clf(x):\n",
    "    if x == (0.33, 5) or x == (0.36,6) or x == (0.18,6):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def create_confusion_matrix(D, clf):\n",
    "    # Extrahiere die tatsächlichen Klassenlabels aus dem Datensatz D\n",
    "    y_actual = [y for _, y in D]\n",
    "    print('y_actual: ', y_actual)\n",
    "    # Erstelle eine Liste der vorhergesagten Klassenlabels basierend auf dem Klassifikator c\n",
    "    y_predicted = [clf(x) for x, _ in D] #[clf_logit(sigmoid(theta,x)) for x, _ in D]\n",
    "    print('y_predicted: ', y_predicted)\n",
    "\n",
    "    # Berechne die Konfusionsmatrix\n",
    "    c_matrix = metrics.confusion_matrix(y_actual, y_predicted)\n",
    "\n",
    "    print(f\"\\nGenauigkeit: {accuracy_score(y_actual, y_predicted):.3f}\")\n",
    "    print(f\"Präzesion: {precision_score(y_actual, y_predicted, zero_division=0):.3f}\")\n",
    "    print(f\"Sensitivität (Recall): {recall_score(y_actual, y_predicted, zero_division=0):.3f}\")\n",
    "    print(f\"F1-Maß: {f1_score(y_actual, y_predicted, zero_division=0):.3f}\")\n",
    "\n",
    "    return c_matrix\n",
    "\n",
    "print(\"\\nKonfusionsmatrix: \\n\", create_confusion_matrix(D, clf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266bbaf-82d9-4081-b75a-8516d9bf0595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. 3D modell\n",
    "\n",
    "Die logistische Kostenfunktion $L^{logit}(h^{logit}_{\\theta}, D)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4c42924-ebc2-4a9e-bad3-06f3a155ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ihre Daten\n",
    "D = [\n",
    "    ((56,44),1),((50,37),0),((47,53),1),((18,40),0)\n",
    "]\n",
    "theta = (45, -0.5, -0.5)\n",
    "lambda_ = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d1e1cac-472f-46ca-ba68-38954b9c3ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066928509242848554\n",
      "0.8175744761936437\n",
      "0.0066928509242848554\n",
      "0.9999998874648379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sigmoid(theta, x):\n",
    "    return 1 / (1 + np.exp(-h(theta, x)))\n",
    "\n",
    "def h(theta, x):\n",
    "    return theta[0] + sum(t*x_i for t, x_i in zip(theta[1:], x))\n",
    "\n",
    "for (x,y) in D:\n",
    "    print(sigmoid(theta, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44284b1f-ed22-439b-9a66-8669d8aa5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_logit(D, sigmoid, theta):\n",
    "    \n",
    "    m = len(D)  # Anzahl der Beobachtungen im Datensatz\n",
    "    total_cost = 0.0\n",
    "\n",
    "    for x, y in D:\n",
    "        prediction = sigmoid(theta, x)\n",
    "        cost = y * np.log(prediction) + (1 - y) * np.log(1 - prediction)\n",
    "        print(cost)\n",
    "        total_cost += cost\n",
    "\n",
    "    return -total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc43a5ba-5e14-4bc8-b3c2-fb8fc914e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.006715348489118\n",
      "-1.7014132779827524\n",
      "-5.006715348489118\n",
      "-16.000000112332735\n",
      "Der quadratische Fehler für D und theta ist 27.715\n"
     ]
    }
   ],
   "source": [
    "L = L_logit(D, sigmoid, theta)\n",
    "print(f'Die logostische Kostenfunktion für D und theta ist {round(L,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799460d3-9a5d-4f51-86e9-a38a0d04be88",
   "metadata": {},
   "source": [
    "Der Klassifikationsmatrix $clf_f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42f47e19-b5ef-4954-8216-c403afea4d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_actual:  [1, 1, 0, 0, 0]\n",
      "y_predicted:  [1, 0, 1, 0, 1]\n",
      "\n",
      "Genauigkeit: 0.400\n",
      "Präzesion: 0.333\n",
      "Sensitivität (Recall): 0.500\n",
      "F1-Maß: 0.400\n",
      "\n",
      "Konfusionsmatrix: \n",
      " [[1 2]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "D = [\n",
    "    ((0.33,5),1),((0.31,4),1),((0.36,6),0),((0.05,29),0),((0.18,6),0)\n",
    "]\n",
    "\n",
    "# Beispiel-Klassifikator c\n",
    "def clf(x):\n",
    "    if x == (0.33, 5) or x == (0.36,6) or x == (0.18,6):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def create_confusion_matrix(D, clf):\n",
    "    # Extrahiere die tatsächlichen Klassenlabels aus dem Datensatz D\n",
    "    y_actual = [y for _, y in D]\n",
    "    print('y_actual: ', y_actual)\n",
    "    # Erstelle eine Liste der vorhergesagten Klassenlabels basierend auf dem Klassifikator c\n",
    "    y_predicted = [clf(x) for x, _ in D]\n",
    "    print('y_predicted: ', y_predicted)\n",
    "\n",
    "    # Berechne die Konfusionsmatrix\n",
    "    c_matrix = metrics.confusion_matrix(y_actual, y_predicted)\n",
    "\n",
    "    print(f\"\\nGenauigkeit: {accuracy_score(y_actual, y_predicted):.3f}\")\n",
    "    print(f\"Präzesion: {precision_score(y_actual, y_predicted, zero_division=0):.3f}\")\n",
    "    print(f\"Sensitivität (Recall): {recall_score(y_actual, y_predicted, zero_division=0):.3f}\")\n",
    "    print(f\"F1-Maß: {f1_score(y_actual, y_predicted, zero_division=0):.3f}\")\n",
    "\n",
    "    return c_matrix\n",
    "\n",
    "print(\"\\nKonfusionsmatrix: \\n\", create_confusion_matrix(D, clf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3855de-a5f2-4ff0-8138-1947d8efd31b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.3. SVM <a name=2.3.><a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ae47c4-26ca-4ad8-82aa-b38bd8fbf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ihre Daten\n",
    "D = [\n",
    "    ((1,2),-1),((1.5,0.5),-1),((1.5,3.5),1),((3.5,1),1),((3.5,3),1)\n",
    "]\n",
    "theta = (20/17, 16/17)\n",
    "b =  69/17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172b662-3b04-4cd9-ae77-9beaf5139982",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Abstand von $h_1$ und $h_{-1}$ zu $h_0$  ist genau $\\frac{1}{\\|\\theta\\|}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e849e3a-f862-4190-a746-c356609533bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Abstand von h_1 und h_{-1} zu h_0 ist: 0.664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def abstand_zu_h0(theta):\n",
    "    return 1 / np.linalg.norm(theta)\n",
    "\n",
    "abstand_zu_h0 = abstand_zu_h0(theta)\n",
    "print(\"Der Abstand von h_1 und h_{-1} zu h_0 ist:\", round(abstand_zu_h0,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991739b1-6d09-45e4-bb26-334466b120e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Stützvektoren sind: [((1, 2), -1), ((1.5, 3.5), 1), ((3.5, 1), 1)]\n"
     ]
    }
   ],
   "source": [
    "def h0(theta, x, b):\n",
    "    return np.dot(theta, x) - b\n",
    "\n",
    "support_vectors = []\n",
    "\n",
    "for (x,y), target in D:\n",
    "    distance = h0(theta, (x,y), b)\n",
    "    if np.isclose(distance, 1) or np.isclose(distance, -1):\n",
    "        support_vectors.append(((x, y), target))\n",
    "\n",
    "print(\"Die Stützvektoren sind:\", support_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017968f-2347-49cb-b3aa-010d21740d87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Hinge-Kostenfunktion $L^{hinge}(D,f)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e488dc9d-5602-48e1-ab98-f1fafaf08058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Hinge-Kostenfunktion L_hinge(D, f) ist 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datensatz D\n",
    "D = [((1,3),-1),((4,3),1),((5,3.5),-1),((7,2.5),-1)]\n",
    "\n",
    "def f(x1, x2):\n",
    "    return np.cos((x1 + x2 - 3) * np.pi)\n",
    "\n",
    "def L_hinge(D, f):\n",
    "    cost = 0\n",
    "    for x, y in D:\n",
    "        cost += max(0, 1 - y * f(*x))\n",
    "    return cost\n",
    "##\n",
    "\n",
    "# Berechnen Sie die Hinge-Kostenfunktion\n",
    "cost = L_hinge(D, f)\n",
    "print(f\"Die Hinge-Kostenfunktion L_hinge(D, f) ist {round(cost, 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba2546-6ce8-4be3-af07-7e1b689180c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Kernelfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8093b5b-3406-4efe-95bc-f610e6593039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def phi(x):\n",
    "    \"\"\"\n",
    "    Eine Transformation φ : R² → R³.\n",
    "    In diesem Beispiel realisiert φ eine polynomielle Merkmalserweiterung.\n",
    "    \"\"\"\n",
    "    return np.array([x[0]**2, np.sqrt(2)*x[0]*x[1], x[1]**2])\n",
    "\n",
    "# Homogener polynomieller Kernel zu Grad 2\n",
    "def kernel(x, x_prime):\n",
    "    \"\"\"\n",
    "    Eine Kernelfunktion kφ, die das Skalarprodukt im R³ realisiert.\n",
    "    kφ (x, x′) = φ(x)ᵀ φ(x′)\n",
    "    \"\"\"\n",
    "    return np.dot(phi(x), phi(x_prime))\n",
    "\n",
    "# Homogener polynomieller Kernel zu Grad d > 0\n",
    "#f+r das lineare Kernel d = 1\n",
    "def poly_kernel_homogeneous(x, x_prime, d):\n",
    "    return np.dot(x, x_prime)**d\n",
    "\n",
    "# Inhomogener polynomieller Kernel zu Grad d > 0 mit r ∈ R\n",
    "def poly_kernel_inhomogeneous(x, x_prime, d, r):\n",
    "    return (np.dot(x, x_prime) + r)**d\n",
    "\n",
    "# Radiale Basisfunktion mit γ > 0 (Gaußscher Kernel)\n",
    "def rbf_kernel(x, x_prime, gamma):\n",
    "    return np.exp(-gamma * np.linalg.norm(x - x_prime)**2)\n",
    "    \n",
    "# Testen Sie die Funktionen mit zwei Vektoren a und b\n",
    "a = np.array([2, 3])\n",
    "b = np.array([4, 5])\n",
    "\n",
    "print(\"Das Skalarprodukt im transformierten Raum ist: \", kernel(a, b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9ecfc-af4b-4f65-8f57-3386b8a69fcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.4. KNN <a name=2.4.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01538c55-7c97-4795-977a-9d19691b6993",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### KNN-algorithmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ec32ab6-c655-48af-afea-de42a731b548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.80344725 5.93043    5.76974869 5.37587202 5.29528092]\n",
      "Der nächste Nachbar von x ist:  ((-6.8, 6), 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def nearestk(D, x_new, k):\n",
    "    # Extrahieren Sie die Punkte aus D\n",
    "    points = np.array([x for x, y in D])\n",
    "    \n",
    "    # Berechnen Sie die euklidische Distanz zwischen x und allen Punkten in D\n",
    "    distances = np.array([distance.euclidean(x_new, point) for point in points])\n",
    "\n",
    "    print(distances)\n",
    "\n",
    "    # Finden Sie den Index des nächsten Nachbarn\n",
    "    nn_index = np.argmin(distances)\n",
    "    \n",
    "    # Der nächste Nachbar\n",
    "    nearest_neighbor = D[nn_index]\n",
    "    \n",
    "    print(\"Der nächste Nachbar von x ist: \", nearest_neighbor)\n",
    "\n",
    "# Testen der Funktion\n",
    "D = [\n",
    "    ((-2, 1), 1),\n",
    "    ((-1.9, 1.4), 1),\n",
    "    ((-2.6, 3.3), 2),\n",
    "    ((-3.9, 4.5), 2),\n",
    "    ((-6.8, 6), 3)\n",
    "]\n",
    "x = np.array([-7.8, 0.8])\n",
    "k = 2\n",
    "\n",
    "nearestk(D, x, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7dc2c-19ca-47e3-b5ca-6a913be5a70b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Anwenden der Z-Transformation auf jedes Merkmal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8d23a3-3e20-4c01-9f82-6bbea5045b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mittelwerte der Merkmale:  [13.7 23.8]\n",
      "Standardabweichungen der Merkmale:  [ 2.1        15.03861696]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datensatz\n",
    "D = [\n",
    "    ((12, 12), 'Hund'),\n",
    "    ((13, 34), 'Hund'),\n",
    "    ((16, 30), 'Wolf'),\n",
    "    ((14, 15), 'Dingo'),\n",
    "    ((15, 39), 'Wolf'),\n",
    "    ((15, 13), 'Dingo'),\n",
    "    ((10, 5), 'Hund'),\n",
    "    ((17, 56), 'Wolf'),\n",
    "    ((14, 11), 'Dingo'),\n",
    "    ((11, 23), 'Hund')\n",
    "]\n",
    "\n",
    "# Trennen Sie die Merkmale und die Ziele\n",
    "features = np.array([item[0] for item in D])\n",
    "targets = np.array([item[1] for item in D])\n",
    "\n",
    "# Berechnen Sie den Mittelwert und die Standardabweichung für jedes Merkmal\n",
    "mean_features = np.mean(features, axis=0)\n",
    "std_features = np.std(features, axis=0)\n",
    "\n",
    "print(\"Mittelwerte der Merkmale: \", mean_features)\n",
    "print(\"Standardabweichungen der Merkmale: \", std_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd31a8d5-d8a8-4c63-8f5b-58b9106a90a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-transformierter Datensatz:  [((-0.8095238095238092, -0.7846466223058651), 'Hund'), ((-0.333333333333333, 0.6782538599593071), 'Hund'), ((1.0952380952380956, 0.4122719540929121), 'Wolf'), ((0.14285714285714318, -0.5851601929060689), 'Dingo'), ((0.6190476190476194, 1.0107312422923007), 'Wolf'), ((0.6190476190476194, -0.7181511458392664), 'Dingo'), ((-1.7619047619047614, -1.2501149575720563), 'Hund'), ((1.5714285714285716, 2.1411543422244796), 'Wolf'), ((0.14285714285714318, -0.8511420987724638), 'Dingo'), ((-1.2857142857142854, -0.05319638117327904), 'Hund')]\n"
     ]
    }
   ],
   "source": [
    "# Anwenden der Z-Transformation auf jedes Merkmal\n",
    "z_transformed_features = (features - mean_features) / std_features\n",
    "\n",
    "# Kombinieren Sie die Z-transformierten Merkmale mit den Zielen, um den Z-transformierten Datensatz zu erhalten\n",
    "z_transformed_D = [(tuple(z_feature), target) for z_feature, target in zip(z_transformed_features, targets)]\n",
    "\n",
    "print(\"Z-transformierter Datensatz: \", z_transformed_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87496ba0-5baf-42b2-8be6-b807ae2297a4",
   "metadata": {},
   "source": [
    "##### Nächste-Nachbarn-Regression\n",
    "$$regr_{D,k}(x) = \\frac{\\sum_{y \\in nearest_k(D,x)}y}{k} = \\frac{1}{k}\\sum_{y \\in nearest_k(D,x)} y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44e1dfec-7cff-4119-84f1-011a0d477ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der nächste Nachbar von x ist:  [((7, 29), 80), ((5, 13), 54)]\n",
      "Der vorhergesagte Wert von y(6) ist:  67.0\n"
     ]
    }
   ],
   "source": [
    "def nearestk_long(D, x, k):\n",
    "    # Extrahieren Sie die Punkte aus D\n",
    "    points = np.array([point for point, category in D])\n",
    "    \n",
    "    # Berechnen Sie die euklidische Distanz zwischen x und allen Punkten in D\n",
    "    dists = np.array([distance.euclidean(x, point) for point in points])\n",
    "    \n",
    "    # Finden Sie die Indizes der k kleinsten Distanzen\n",
    "    idx = np.argpartition(dists, k)[:k]\n",
    "    \n",
    "    # Rückgabe der k nächsten Punkte und ihrer Kategorien\n",
    "    return [D[i] for i in idx]\n",
    "    \n",
    "def NN_reg(D, x_new, k):\n",
    "    knn = nearestk_long(D, x_new, k)\n",
    "    print(\"Der nächste Nachbar von x ist: \", knn)\n",
    "    return sum(y for x,y in knn)/k\n",
    "\n",
    "D = [\n",
    "    ((5,13),54),((7,29),80),((8,-48),48),((10,3),69),((11,-21),59)\n",
    "]\n",
    "\n",
    "# Neuer Datenpunkt\n",
    "x_new = np.array([9, 59])\n",
    "k = 2\n",
    "\n",
    "print(\"Der vorhergesagte Wert von y(6) ist: \", NN_reg(D, x_new, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93785fc7-50bb-46ef-ad68-a8b984aac7b5",
   "metadata": {},
   "source": [
    "### 2.5. Bayes <a name=2.6.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b162b1-3a4f-4a8b-ae07-11b85ecea0cf",
   "metadata": {},
   "source": [
    "##### Naives Bayes klassifikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbd33d6-110c-4735-b151-398047741703",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [(1,0,'c1'),(0,1,'c1'),(1,1,'c2'),(0,0,'c2'),(0,1,'c1')]\n",
    "\n",
    "# Zählen Sie die Anzahl der Instanzen jeder Klasse\n",
    "count_c1 = sum(1 for x in D if x[2] == 'c1')\n",
    "count_c2 = sum(1 for x in D if x[2] == 'c2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0992c82-808a-44f8-913b-28b2d49cecad",
   "metadata": {},
   "source": [
    "$P(c1 ∣ D)$ und $P(c2 ∣ D)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6e31e0-b3f5-4ce0-879b-d2124f97e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c1|D) = 0.6\n",
      "P(c2|D) = 0.4\n"
     ]
    }
   ],
   "source": [
    "# Berechnen Sie die bedingten Wahrscheinlichkeiten\n",
    "P_c1_given_D = count_c1 / len(D)\n",
    "P_c2_given_D = count_c2 / len(D)\n",
    "\n",
    "print(f'P(c1|D) = {P_c1_given_D}')\n",
    "print(f'P(c2|D) = {P_c2_given_D}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de947a7-c575-45c8-acb0-6b7f9c6adcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x1=0|c=c1,D) = 0.6666666666666666\n",
      "P(x1=0|c=c2,D) = 0.5\n",
      "P(x1=1|c=c1,D) = 0.3333333333333333\n",
      "P(x1=1|c=c2,D) = 0.5\n",
      "P(x2=0|c=c1,D) = 0.3333333333333333\n",
      "P(x2=0|c=c2,D) = 0.5\n",
      "P(x2=1|c=c1,D) = 0.6666666666666666\n",
      "P(x2=1|c=c2,D) = 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Zählen Sie die Anzahl der Instanzen jeder Merkmalsausprägung für jede Klasse\n",
    "count_x1_0_c1 = sum(1 for x in D if x[0] == 0 and x[2] == 'c1')\n",
    "count_x1_0_c2 = sum(1 for x in D if x[0] == 0 and x[2] == 'c2')\n",
    "count_x1_1_c1 = sum(1 for x in D if x[0] == 1 and x[2] == 'c1')\n",
    "count_x1_1_c2 = sum(1 for x in D if x[0] == 1 and x[2] == 'c2')\n",
    "\n",
    "count_x2_0_c1 = sum(1 for x in D if x[1] == 0 and x[2] == 'c1')\n",
    "count_x2_0_c2 = sum(1 for x in D if x[1] == 0 and x[2] == 'c2')\n",
    "count_x2_1_c1 = sum(1 for x in D if x[1] == 1 and x[2] == 'c1')\n",
    "count_x2_1_c2 = sum(1 for x in D if x[1] == 1 and x[2] == 'c2')\n",
    "\n",
    "# Berechnen Sie die Wahrscheinlichkeitsverteilungen\n",
    "P_x1_0_given_c1_D = count_x1_0_c1 / count_c1\n",
    "P_x1_0_given_c2_D = count_x1_0_c2 / count_c2\n",
    "P_x1_1_given_c1_D = count_x1_1_c1 / count_c1\n",
    "P_x1_1_given_c2_D = count_x1_1_c2 / count_c2\n",
    "\n",
    "P_x2_0_given_c1_D = count_x2_0_c1 / count_c1\n",
    "P_x2_0_given_c2_D = count_x2_0_c2 / count_c2\n",
    "P_x2_1_given_c1_D = count_x2_1_c1 / count_c1\n",
    "P_x2_1_given_c2_D = count_x2_1_c2 / count_c2\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(f'P(x1=0|c=c1,D) = {P_x1_0_given_c1_D}')\n",
    "print(f'P(x1=0|c=c2,D) = {P_x1_0_given_c2_D}')\n",
    "print(f'P(x1=1|c=c1,D) = {P_x1_1_given_c1_D}')\n",
    "print(f'P(x1=1|c=c2,D) = {P_x1_1_given_c2_D}')\n",
    "\n",
    "print(f'P(x2=0|c=c1,D) = {P_x2_0_given_c1_D}')\n",
    "print(f'P(x2=0|c=c2,D) = {P_x2_0_given_c2_D}')\n",
    "print(f'P(x2=1|c=c1,D) = {P_x2_1_given_c1_D}')\n",
    "print(f'P(x2=1|c=c2,D) = {P_x2_1_given_c2_D}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7cf118-f08c-43a4-8460-d3a03aacefeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf(x1=0,x2=0,D) = c1 with probability 0.13333333333333333\n",
      "clf(x1=0,x2=0,D) = c2 with probability 0.1\n"
     ]
    }
   ],
   "source": [
    "# Definieren Sie den Datenpunkt\n",
    "x = (0, 0)\n",
    "\n",
    "# Berechnen Sie die Wahrscheinlichkeiten für jede Klasse\n",
    "P_c1_given_x_D = P_x1_0_given_c1_D * P_x2_0_given_c1_D * P_c1_given_D\n",
    "P_c2_given_x_D = P_x1_0_given_c2_D * P_x2_0_given_c2_D * P_c2_given_D\n",
    "\n",
    "'''\n",
    "# Normalisieren Sie die Wahrscheinlichkeiten, so dass sie sich zu 1 addieren\n",
    "sum_P = P_c1_given_x_D + P_c2_given_x_D\n",
    "P_c1_given_x_D /= sum_P\n",
    "P_c2_given_x_D /= sum_P\n",
    "'''\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(f'clf(x1=0,x2=0,D) = c1 with probability {P_c1_given_x_D}')\n",
    "print(f'clf(x1=0,x2=0,D) = c2 with probability {round(P_c2_given_x_D,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb8722-6f82-47a1-a923-a72d1366e288",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.3. RNN <a name=5.1.><a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef20847-f681-44dc-b13e-90ebbe01e9db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3.1. spaltenweise Konkatenation zweier Matrizen <a name=5.3.1.><a>\n",
    "\n",
    "Sei $A \\in \\mathbb{R}^{n \\times m}$ und $B \\in \\mathbb{R}^{n \\times m'}$ zwei Matrizen mit gleicher Anzahl an Zeilen, so ist $A \\circ B \\in \\mathbb{R}^{n \\times (m + m')}$ die entsprechende Konkatenation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917a1c0-3a58-4129-ab00-d9cde58459eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen Sie die Matrizen A und B mit Dummy-Zahlen\n",
    "A = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "\n",
    "B = np.array([[10, 11, 12], \n",
    "              [13, 14, 15], \n",
    "              [16, 17, 18]])\n",
    "\n",
    "# Führen Sie die Konkatenation durch\n",
    "AB = np.concatenate((A, B), axis=1)\n",
    "print(AB)\n",
    "\n",
    "# Erstellen Sie die Vektoren v und w mit Dummy-Zahlen\n",
    "v = np.array([1, 2, 3])  # v = (v1, ..., vm)^T\n",
    "w = np.array([4, 5, 6])  # w = (w1, ..., wm')^T\n",
    "\n",
    "# Führen Sie die Konkatenation durch\n",
    "vw = np.concatenate((v, w))\n",
    "print(\"v ◦ w =\", vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe44ddc-6fc8-47a8-9048-bdad3c010d90",
   "metadata": {},
   "source": [
    "Vergewissern Sie sich, dass für die obigen Definition gilt $(A \\circ B)(v \\circ w) = Av + Bw$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bf573-d301-4809-866e-9711d253597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = np.dot(AB,vw)\n",
    "result2 = np.dot(A,v) + np.dot(B,w)\n",
    "print(result1 == result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51772525-0900-4237-bb78-faa53dd26d72",
   "metadata": {},
   "source": [
    "### 5.3.2. One-Hot-Codierung <a name=5.3.2.><a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6195b0-7376-4847-8bd3-254cc55853f2",
   "metadata": {},
   "source": [
    "Sei ein Alphabet gegeben durch\n",
    "\n",
    "Σ={a,e,s,t}\n",
    "\n",
    "1. Bestimmen Sie eine One-Hot-Codierung für Σ\n",
    ". (Anwortformat '(1,2,3,4,5,6)', Vektorlänge ist selbst zu wä\n",
    "2. Wie ist demnach das Wort test\n",
    " codiert \n",
    "\n",
    "(Anwortformat '((1,2,3,4,5,6),(7,8,9))')\n",
    "#### Lösung\n",
    "- a: (1, 0, 0, 0)\n",
    "- e: (0, 1, 0, 0)\n",
    "- s: (0, 0, 1, 0)\n",
    "- t: (0, 0, 0, 1)\n",
    "\n",
    "Unter Verwendung der zuvor definierten One-Hot-Codierung für das Alphabet Σ={a,e,s,t}, wird das Wort \"test\" wie folgt codiert:\n",
    "\n",
    "- t: (0, 0, 0, 1)\n",
    "- e: (0, 1, 0, 0)\n",
    "- s: (0, 0, 1, 0)\n",
    "- t: (0, 0, 0, 1)\n",
    "\n",
    "Daher ist die Codierung des Wortes \"test\" in dem von Ihnen angegebenen Antwortformat:\n",
    "\n",
    "((0, 0, 0, 1), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df485f3-6e46-4c86-9452-28009fadc40a",
   "metadata": {},
   "source": [
    "### 5.3.3. Berechnungsgraphen <a name=5.3.3.><a>\n",
    "Im Allgemeinen gilt für eine Eingabe $x = (x^{(1)}, \\ldots, x^{(m)})$:\n",
    "\n",
    "$$\n",
    "h(i) = \\text{act}(Ux^{(i)} + Wh^{(i-1)}) \\quad \\text{(1)}\n",
    "$$ <a name=hi><a>\n",
    "\n",
    "$$\n",
    "o(i) = \\text{act}(Vh^{(i)}) \\quad \\text{(2)}\n",
    "$$<a name=oi><a>\n",
    "\n",
    "für $i = 1, \\ldots, m$. Zu beachten ist, dass diese Netzwerkarchitektur mit Eingaben beliebiger Länge umgehen kann, aber eine fixe Anzahl an Parametern besitzt (in den Matrizen $U$, $V$, $W$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda19404-0a03-4c6c-b27b-c2d4602fbeab",
   "metadata": {},
   "source": [
    "Gegeben sei das abgebildete einfache RNN, wobei\n",
    "\n",
    "$$\\sum = \\{\\text{ist,nichts,niemand}\\} = \\{(1,0,0)^T,(0,1,0)^T,(0,0,1)^T\\}$$\n",
    "$$U= ((0, 0.9, 0.9), (0.5, 0.1, 0), (0.5, 0, 0.1))$$\n",
    "$$W = ((0, 0.45, 0.45), (0.25, 0.05, 0), (0.25, 0, 0.05))$$\n",
    "$$V = ((0.5, 0, 0), (0, 0.5, 0), (0, 0, 0.5))$$\n",
    "$$h_0 = (0,1,1)^T$$\n",
    "\n",
    "und die Aktivierungsfunktion $h^{relu}$ ist. Berechnen Sie die hidden states und die Ausgabe für die Eingabe $x = \\text{'Niemand ist'} = ((0,0,1)^T,(1,0,0)^T)$. \n",
    "(Antwortformat '(1,2,3.456)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23528f1d-cd8f-4d9b-ba19-82de0847422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hrelu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "U = np.array([[0, 0.9, 0.9], [0.5, 0.1, 0], [0.5, 0, 0.1]])\n",
    "W = np.array([[0, 0.45, 0.45], [0.25, 0.05, 0], [0.25, 0, 0.05]])\n",
    "V = np.array([[0.5, 0, 0], [0, 0.5, 0], [0, 0, 0.5]])\n",
    "h_0 = np.array([0,1,1]).T\n",
    "x = np.array([[0,0,1],[1,0,0]]).T\n",
    "\n",
    "h_1 = hrelu(np.dot(U, x[:,0]) + np.dot(W, h_0))\n",
    "h_2 = hrelu(np.dot(U, x[:,1]) + np.dot(W, h_1))\n",
    "\n",
    "o_1 = hrelu(np.dot(V, h_1))\n",
    "o_2 = hrelu(np.dot(V, h_2))\n",
    "\n",
    "print(\"h_1: \", h_1)\n",
    "print(\"h_2: \", h_2)\n",
    "print(\"o_1: \", o_1)\n",
    "print(\"o_2: \", o_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04919f-d436-4682-8ff6-3929da2c6e77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3.4. Long short-term memory-Netzwerke <a name=5.3.4.><a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bce749-40b6-4918-998d-004268a7c519",
   "metadata": {},
   "source": [
    "$$f^{(i)} = h^{logit} (U^f x^{(i)} + W^f h^{(i−1)})$$\n",
    "- Der Vektor $f^{(i)}$ soll steuern, was aus dem Langzeitgedächtnis `s` vergessen werden soll (auch als **forget gate** bezeichnet).\n",
    "\n",
    "$$g^{(i)} = h^{logit} (U^g x^{(i)} + W^g h^{(i−1)})$$\n",
    "$$k^{(i)} = h^{tanh} (U^k x^{(i)} + W^k h^{(i−1)})$$\n",
    "- Der Vektor $g^{(i)}$ (**input gate**) steuert, welche Informationen aus $k^{(i)}$ in das Langzeitgedächtnis aufgenommen werden sollen.\n",
    "$$q^{(i)} = h^{logit} (U^o x^{(i)} + W^o h^{(i−1)})$$\n",
    "- Der Vektor $q^{(i)}$ (**output gate**) steuert, welche Information in die Ausgabe und den nächsten versteckten Zustand $h^{(i)}$ einfließt.\n",
    "\n",
    "- Die Kernidee hinter LSTMs liegt in der Definition des Zellzustands: $$s^{(i)} = f^{(i)} \\cdot s^{(i-1)} + g^{(i)} \\cdot k^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a88a14-5f08-468d-aba0-11eacee21d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
